<!DOCTYPE html>
<html>
    <head>
        <title>One For All (OFA)</title>
        <meta name="description" content="OFA에 대해 설명합니다.">
        <meta charset="utf-8">
        <link rel="stylesheet" href="init/index.css">
        <link rel="stylesheet" href="init/contents.css">
        <link rel="stylesheet" href="init/index_img/icons/css/fontello.css">

        <link rel="preconnect" href="https://fonts.googleapis.com"> 
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> 
        <link href="https://fonts.googleapis.com/css2?family=Dongle:wght@300&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Gowun+Batang&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic&display=swap" rel="stylesheet">

        <link rel="stylesheet"
            href="init/highlight/styles/github-dark.min.css">
        <script src="init/highlight/highlight.min.js"></script>
        <script>hljs.highlightAll();</script>
        <script src="init/highlight/highlights_line.js"></script>
        <script>initNumber(window, document);</script>
        <script>hljs.initLineNumbersOnLoad();</script>

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        <script src="init/index.js"></script>
        <script src="init/jquery.pjax.js"></script>
        
        <meta name="viewport" content="width=device-width, initial-scale=0.8, max-width=1">

        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-219110982-1"></script>
        <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-219110982-1');
        </script>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7745178886614102"
        crossorigin="anonymous"></script>

        <meta property="og:url" content="https://ljm565.github.io/contents/ofa1.html" />
        <meta property="og:title" content="One For All (OFA)" />
        <meta property="og:type" content="website">
        <meta property="og:description" content="OFA에 대해 설명합니다." />
        <meta property="og:image" content="https://lh3.googleusercontent.com/fife/AKsag4MxSN4XbP4fn6QCdkZiqffw95CRLEZTvmvlTuAJdsfRMRYpGunR8GLXsReDJorOyaz8Nblw1t1_lpjX291Au38LTmoF34qjBK1-ZWCTocm52NfxLko4kFouwrevEPtQBW21b6HYP7q14vuJU4LS1W0vD9rkfYrP-Gn1qWcOmW0UcwrG8xfsS8veDsUA1_f-C9fldtuCwAbpubUcdK8NsoZCpj0czUGa_XqK7IXsR383kMqG5HyPZlCUA5ULrHB0tfjWFUkbhnqrYD4OAhgMbaXYJ7YKivs-4mQfp1eee2o3do_DKBb2myzrQ_s8y7b4rx6kxN21LeErvLsbDl4FCRmKQvp9ByCdTfC0PDWYJXtQjVvRKV2x69raffiZmX4EGaFhXFEbisM0nDSbvP_7pejUVRwoddP5i1g8hIYPQ1Zz2RvUld_Bh_ZrfeloBtoC9dnwhltPN9hrXOXGqv9gMiuEY9UTtmyCN-un4Chy9_w0KdzxKOGIBxkYWGZcpIrIdtANef319p3kcXtpc1vF5fJ1khSc6-rIN2rOO5Dz-YByOgUk3ageiJfczDhKKaxeyVAxq8YWvf7TQ1iPnq79lpkKcAJ8MEako2fLNXTbwzKuDE-8dd4jZ7b9U0TSzjjKpQx44Sd52eNbn3I9G6H34QX7RMpFV0XvRkzEuWRoXlG0tHnAM-iTFwqh9_rej-1PRIg7aX2f4fcONH5wcFVFSj_BqL6ZZXfPTzxlhSm4tbJ5J0eweddtTVrHrrDm2mFHeyEvhf0fHqIVZxUirA7L1hAeezO03D4VoeKD8uLZrxnGs_0D0dh7p7XwlYxgChmMi3FhHvPOaGAHaior_-WcGnFknos72HvwMFXfmPB6mVHByV2wbxKdkPlvMCrbEJ1NOYuVeX9C-2QS8r4QjWKFDXa9fBEEyDBh0kpbvUbAFIA55__AfsNrO8Sv5T8S84iXkbP_SGrAPVTIpDzYj_kRHdRIt1wEyFybEJCJK9BpGzvaqkpQjFhrO31N8O2KnSvZmMa6QpZTV2Nx3iRTHH2ImVTmi0rhmqEXKWfQ-mkj-MjdPzQKKDz3rrDW38n7r4mjSE4DJi8H9o2UP6AzDqkhdctd0t9LchBSyO3mIE2rfSFVqhLG7jEfsXPURQyaw_VCK5AINzqimZ9sWvZI3KpOHwkTuFk04i6Gnjg60avgT7a3Jx_Wpe2Wd1RWoiZSlp3mXaiAdggHc7FiCCRgHZyhz79MnMBgMIdkAyrlhWducBbVa_sePOQqkuL-uoE8AqWY_1KFgVpcY3cLv7HE1ULpy2xKjD2tJ0QM96TnEzP2Ap0WfAvUknvoq1cUhfV0ZMAFJbxH7DwUGmEIBPI1wYhILm400aCApGl20IuZjgLs0appL9tNQUabSM3c8124aVCjnkAlhPKme_uWYCG1jl4CSNeL5vzO_x3iDwqq0mZ0wEt1V1EmHL1pFNb0O01P82fJLJJANeutHZD7wdyGRykBGLgCVy7-5ynCXtRbtvhuO48hDc1cSjoYMV2g8SsyodAlg2-lgGAl1p3Ay24DPQ" />
    </head>   
    <body>
        <div id="modeButton">
            <button type="button" value="dark" onclick="darkMode(this)" onmouseover="hoveringOn(this)" onmouseout="hoveringOff(this)">
                <div class="modeImg"><img id="modeImg" src="init/index_img/moon_off.png"></div>
                <div id="modeState">다크 모드로 보기</div>
            </button>
        </div>

        <div id="container" onclick="reload();">
            <article>
                <script src="init/highlight/highlight.min.js"></script>
                <script>hljs.highlightAll();</script>
                <script src="init/highlight/highlights_line.js"></script>
                <script>initNumber(window, document);</script>
                <script>hljs.initLineNumbersOnLoad();</script>
                <script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
                <script>
                    initMathJax();
                </script>
                <div id="mainHeadWrapper">
                    <div id="mainHead">
                        <h1 class="contentHead">딥러닝 이야기 / One For All (OFA) / 1. One For All (OFA)</h1>
                    </div>
                </div>
                
                <div class="title" style="background-image:url(https://lh3.googleusercontent.com/fife/AKsag4MxSN4XbP4fn6QCdkZiqffw95CRLEZTvmvlTuAJdsfRMRYpGunR8GLXsReDJorOyaz8Nblw1t1_lpjX291Au38LTmoF34qjBK1-ZWCTocm52NfxLko4kFouwrevEPtQBW21b6HYP7q14vuJU4LS1W0vD9rkfYrP-Gn1qWcOmW0UcwrG8xfsS8veDsUA1_f-C9fldtuCwAbpubUcdK8NsoZCpj0czUGa_XqK7IXsR383kMqG5HyPZlCUA5ULrHB0tfjWFUkbhnqrYD4OAhgMbaXYJ7YKivs-4mQfp1eee2o3do_DKBb2myzrQ_s8y7b4rx6kxN21LeErvLsbDl4FCRmKQvp9ByCdTfC0PDWYJXtQjVvRKV2x69raffiZmX4EGaFhXFEbisM0nDSbvP_7pejUVRwoddP5i1g8hIYPQ1Zz2RvUld_Bh_ZrfeloBtoC9dnwhltPN9hrXOXGqv9gMiuEY9UTtmyCN-un4Chy9_w0KdzxKOGIBxkYWGZcpIrIdtANef319p3kcXtpc1vF5fJ1khSc6-rIN2rOO5Dz-YByOgUk3ageiJfczDhKKaxeyVAxq8YWvf7TQ1iPnq79lpkKcAJ8MEako2fLNXTbwzKuDE-8dd4jZ7b9U0TSzjjKpQx44Sd52eNbn3I9G6H34QX7RMpFV0XvRkzEuWRoXlG0tHnAM-iTFwqh9_rej-1PRIg7aX2f4fcONH5wcFVFSj_BqL6ZZXfPTzxlhSm4tbJ5J0eweddtTVrHrrDm2mFHeyEvhf0fHqIVZxUirA7L1hAeezO03D4VoeKD8uLZrxnGs_0D0dh7p7XwlYxgChmMi3FhHvPOaGAHaior_-WcGnFknos72HvwMFXfmPB6mVHByV2wbxKdkPlvMCrbEJ1NOYuVeX9C-2QS8r4QjWKFDXa9fBEEyDBh0kpbvUbAFIA55__AfsNrO8Sv5T8S84iXkbP_SGrAPVTIpDzYj_kRHdRIt1wEyFybEJCJK9BpGzvaqkpQjFhrO31N8O2KnSvZmMa6QpZTV2Nx3iRTHH2ImVTmi0rhmqEXKWfQ-mkj-MjdPzQKKDz3rrDW38n7r4mjSE4DJi8H9o2UP6AzDqkhdctd0t9LchBSyO3mIE2rfSFVqhLG7jEfsXPURQyaw_VCK5AINzqimZ9sWvZI3KpOHwkTuFk04i6Gnjg60avgT7a3Jx_Wpe2Wd1RWoiZSlp3mXaiAdggHc7FiCCRgHZyhz79MnMBgMIdkAyrlhWducBbVa_sePOQqkuL-uoE8AqWY_1KFgVpcY3cLv7HE1ULpy2xKjD2tJ0QM96TnEzP2Ap0WfAvUknvoq1cUhfV0ZMAFJbxH7DwUGmEIBPI1wYhILm400aCApGl20IuZjgLs0appL9tNQUabSM3c8124aVCjnkAlhPKme_uWYCG1jl4CSNeL5vzO_x3iDwqq0mZ0wEt1V1EmHL1pFNb0O01P82fJLJJANeutHZD7wdyGRykBGLgCVy7-5ynCXtRbtvhuO48hDc1cSjoYMV2g8SsyodAlg2-lgGAl1p3Ay24DPQ);">
                    <div>
                        <span class="mainTitle">One For All (OFA)</span>
                        <br><br>
                        <div style="display: table-cell; margin: 0;">
                            <img src="init/index_img/profile.png" style="width: 30px; cursor: pointer;" onclick="pjaxPage('/');">
                        </div>
                        <span class="subTitle" style="display: table-cell; text-align: left; vertical-align: middle; padding-left: 20px; line-height: 125%;">작성자: 여행 초짜<br>작성일: 2023.09.04</span>
                    </div>
                </div>

                <div id="content">
                    <p>
                        시작하기 앞서 틀린 부분이 있을 수 있으니, 틀린 부분이 있다면 지적해주시면 감사하겠습니다.
                        
                        <br><br>이번에 소개할 논문은 바로 2022년도에 공개된 Large Multi-modal Model (LMM) 모델인 One For All (OFA)입니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">OFA는 이미지와 텍스트의 modality를 다루며, multi-modal pre-training을 위한 통일된 구조인 Sequence-to-sequence (Seq2Seq) 구조를 사용합니다.</span>
                        OFA는 이러한 놀라울만큼 간단한 구조를 바탕으로 다양한 task에서 SOTA 결과를 보여주었고, 이로써 multi-modal task에 효과적임을 입증하였습니다.
                    </p>
                    <div class="link">
                        <a href="https://arxiv.org/pdf/2202.03052.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);">OFA 논문</a>
                    </div>
                    <p>
                        <br><br>오늘의 컨텐츠입니다.
                        <ol>
                            <li>OFA 목적</li>
                            <li>OFA 구조 및 학습 Task</li>
                            <li>OFA 결과</li>
                            <li>OFA 의의</li>
                        </ol>
                    </p>



                    <h1 class="subHead">OFA</h1>
                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center;">&ldquo;</span>
                        <span>OFA의 목적</span><br>
                        <span>Objective of the OFA</span>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        OFA의 목적은 3가지가 있습니다.
                        
                        <ol>
                            <li><b>Task-agnostic</b>: 어떠한 Task에도 적용 가능하도록 함.</li>
                            <li><b>Modality-agnostic</b>: 어떠한 modality에도 적용 가능하도록 함.</li>
                            <li><b>Taks Comprehensiveness</b>: 모델의 일반화 성능을 높이기 위한 다양한 task 적용.</li>
                        </ol>

                        <br>일반적으로 위의 3개의 조건을 만족하면서 좋은 성능을 내는 모델을 학습하기란 어렵습니다.
                        따라서 많은 모델들이 pre-training을 한 후 각 task에 맞게 fine-tuning을 하거나, 아예 특정 task에 특화된 모델을 자체적으로 학습하는 방법을 많이 사용합니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">하지만 저자들은 이 모든 조건을 만족하는 모델을 위해 Seq2Seq 구조를 이용하여 모델을 구성하고, 이미지와 텍스트 modality 모두 하나의 vocabularay로 통합하여 다양한 instruction으로 multi-modal 정보를 모두 학습하도록 합니다.</span>
                    </p>



                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>OFA 구조 및 학습 Task</span><br>
                        <span>OFA Architecture &amp; Training Tasks</span>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        <span style="font-size: 20px;"><b>1. OFA 구조</b></span>
                        <br>OFA의 구조는 놀라울만큼 간단합니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">아래 그림처럼 단순한 Transformer Seq2Seq encoder-decoder 구조를 사용합니다.</span>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AKsag4MxSN4XbP4fn6QCdkZiqffw95CRLEZTvmvlTuAJdsfRMRYpGunR8GLXsReDJorOyaz8Nblw1t1_lpjX291Au38LTmoF34qjBK1-ZWCTocm52NfxLko4kFouwrevEPtQBW21b6HYP7q14vuJU4LS1W0vD9rkfYrP-Gn1qWcOmW0UcwrG8xfsS8veDsUA1_f-C9fldtuCwAbpubUcdK8NsoZCpj0czUGa_XqK7IXsR383kMqG5HyPZlCUA5ULrHB0tfjWFUkbhnqrYD4OAhgMbaXYJ7YKivs-4mQfp1eee2o3do_DKBb2myzrQ_s8y7b4rx6kxN21LeErvLsbDl4FCRmKQvp9ByCdTfC0PDWYJXtQjVvRKV2x69raffiZmX4EGaFhXFEbisM0nDSbvP_7pejUVRwoddP5i1g8hIYPQ1Zz2RvUld_Bh_ZrfeloBtoC9dnwhltPN9hrXOXGqv9gMiuEY9UTtmyCN-un4Chy9_w0KdzxKOGIBxkYWGZcpIrIdtANef319p3kcXtpc1vF5fJ1khSc6-rIN2rOO5Dz-YByOgUk3ageiJfczDhKKaxeyVAxq8YWvf7TQ1iPnq79lpkKcAJ8MEako2fLNXTbwzKuDE-8dd4jZ7b9U0TSzjjKpQx44Sd52eNbn3I9G6H34QX7RMpFV0XvRkzEuWRoXlG0tHnAM-iTFwqh9_rej-1PRIg7aX2f4fcONH5wcFVFSj_BqL6ZZXfPTzxlhSm4tbJ5J0eweddtTVrHrrDm2mFHeyEvhf0fHqIVZxUirA7L1hAeezO03D4VoeKD8uLZrxnGs_0D0dh7p7XwlYxgChmMi3FhHvPOaGAHaior_-WcGnFknos72HvwMFXfmPB6mVHByV2wbxKdkPlvMCrbEJ1NOYuVeX9C-2QS8r4QjWKFDXa9fBEEyDBh0kpbvUbAFIA55__AfsNrO8Sv5T8S84iXkbP_SGrAPVTIpDzYj_kRHdRIt1wEyFybEJCJK9BpGzvaqkpQjFhrO31N8O2KnSvZmMa6QpZTV2Nx3iRTHH2ImVTmi0rhmqEXKWfQ-mkj-MjdPzQKKDz3rrDW38n7r4mjSE4DJi8H9o2UP6AzDqkhdctd0t9LchBSyO3mIE2rfSFVqhLG7jEfsXPURQyaw_VCK5AINzqimZ9sWvZI3KpOHwkTuFk04i6Gnjg60avgT7a3Jx_Wpe2Wd1RWoiZSlp3mXaiAdggHc7FiCCRgHZyhz79MnMBgMIdkAyrlhWducBbVa_sePOQqkuL-uoE8AqWY_1KFgVpcY3cLv7HE1ULpy2xKjD2tJ0QM96TnEzP2Ap0WfAvUknvoq1cUhfV0ZMAFJbxH7DwUGmEIBPI1wYhILm400aCApGl20IuZjgLs0appL9tNQUabSM3c8124aVCjnkAlhPKme_uWYCG1jl4CSNeL5vzO_x3iDwqq0mZ0wEt1V1EmHL1pFNb0O01P82fJLJJANeutHZD7wdyGRykBGLgCVy7-5ynCXtRbtvhuO48hDc1cSjoYMV2g8SsyodAlg2-lgGAl1p3Ay24DPQ" style="width: 100%;">
                        <p class="caption">OFA 구조, 출처: OFA 논문</p>
                    </div>
                    <p>
                        <br><span style="font-size: 20px;"><b>2. OFA Tasks</b></span>
                        <br><span class="highlight" style="color: rgb(0, 3, 206);">위 그림처럼 OFA는 다양한 task로 학습을 수행하는데, 텍스트 뿐 아니라 이미지, object location (bounding box)까지 모두 토큰화하여 unified vocab을 구성하여 학습을 수행합니다.
                        이는 다양한 modality를 하나의 공간에 표현하도록 학습하기에 용이하고, 모든 학습을 cross-entropy loss로 가능하기 때문에 학습이 매우 간단해집니다.</span>

                        <br><br>그렇다면 어떻게 이미지와 object 위치를 토큰으로써 나타냈는지 알아보겠습니다.
                        <ol>
                            <b><li>Object Location Tokens</li></b>
                            먼저 object같은 경우는 이미지의 가로, 세로 길이를 location token 1,000개로 나누어 각각의 위치를 표현하게 됩니다.
                            <span class="highlight" style="color: rgb(0, 3, 206);">가령 가로 세로 크기가 100인 이미지에 boudning box 좌표 중 하나가 [20, 40]이고 위치를 나타내는 토큰의 vocab 크기가 1,000이라면, [&lt;loc200&gt;, &lt;loc400&gt;]으로 표현하는 것입니다.</span>
                            
                            <br><br><b><li>이미지 토큰</li></b>
                            <span class="highlight" style="color: rgb(0, 3, 206);">기존에 많이 사용되는 이미지 토크나이저를 이용합니다. VQ-VAE, VQ-GAN, Taming Transformer, DALL-E의 dVAE 등에서 이미지를 이산 토큰을 만드는 이미지 토크나이저를 사용합니다.</span>
                            이렇게 했을 때 좋은 점은 이미지 역시 이산 토큰을 가지기 때문에 cross-entropy loss로 학습이 가능하며, 토큰화 된 이미지를 decoding하는 decoder만 있으면 쉽게 이미지를 생성할 수 있다는 것입니다.
                        </ol>

                        <br>이제 위 내용을 숙지한 후 다시 위의 task를 보면 이해하기가 쉬워집니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">위의 task들을 보면 multi-modal learning만을 한 것이 아니라 uni-modal learning도 포함 된 것을 볼 수 있습니다.</span>
                        그리고 아래는 위에서 설명한 모든 modality를 이산 토큰으로 바꾸어 수행한 학습들입니다.
                        <ul>
                            <li>Task 종류</li>
                            <ul>
                                <li>Multi-modal Learning</li>
                                <ul>
                                    <li>Visual Grounding (VG)</li>
                                    <li>Grounded Captioning (GC)</li>
                                    <li>Image-text Matching (ITM)</li>
                                    <li>Visual Question and Answering (VQA)</li>
                                </ul>
                                <li>Uni-modal Learning</li>
                                <ul>
                                    <li>Object Detection (Detection)</li>
                                    <li>Image Infilling (MAE와 유사)</li>
                                    <li>Text Infilling (MLM과 유사)</li>
                                </ul>
                            </ul>
                        </ul>
                    </p>


                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>OFA 결과</span><br>
                        <span>Results of OFA</span>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        위의 방법과 구조로 학습한 OFA의 모델 종류와 그 결과를 보겠습니다.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AKsag4MV122-qEXkzkv1-256zdjDcIY2KWhHRuTVXJA1RyzvyUlJjnpYZDckkqqRi9SScoxFUrEd5s2kQvQlNwTpjI9bDAU4vx8mvB1xHv_0pR5sBOBXr-mhaqmUwqOBEq8UKFeStNKXCWfHuZU76mY711_grmru7GGXBy-KcAr4tyEbEQzelG-fYskuz2lmOVemJ80Dgukb_KNFY43hUuaMx_Yxc4c1nLgzGJC3Cj1XXA9JY83sFRbjb7e0yzvu5YFlrkYuiWZI1x36ZZvD165mlgZmS1DIB8HmVZ5FOzSoedBFcHrUdJmkZYbvWjbWONUsYIbh67SbzOqbG1RZ3mPm230DZ_-6gV2My18BntqPnG9k01tHLz0tReVgyNSA3cy5kfKq8ctBDkLteqMdQRRE-V6QFdz0fWcFGc1kHke33qx7BdNGlRGQxM5rV2EAQRbAGqdkb1Az4gE7_jceVn6VSrDPBLK-QaMW-qEut2yXvEEwC9OieRAwAwJnKfpSVktwmSGowKAC7i3CXXrvVyzqLX2___bQpgDrRElvBNTFg2hZZrrkpGIrV2xTrcCVBO-tBpgLWCvAGi0vJtY6TTkH18FZp-uOcVQ8Ep-sRVG5g-ep_19-P6kVuEYXg4ev6qloD0Qah8N8JgyGmDzSxIKSE9vY17J-WMS3kKtJpynfMrGuDP8HU9qsM5M3kT_mPy_HEqatZasN3npmKJ6eeZtYBtRddCa1GuXVe16ReObKXH6mPMRqBmKVVZwapJSyzLzHtMzzNJKxhwf-KmnNv3mqR7u_lJf_j2jshixMyj7957Ae1TuHUt8mVEd9FjLNvZ6EBaVi48csxo3D8SiMonj5QvOoe5ICuu4BPKvuKGlW-aQxukj8SHBvnzoorNTTp3Jk27bZsEzPX8p5A_h6hTjgdEKp8Hwg6K72q4oB9fnZFn_uTLP9o2jPjLpAJ-n3kb90To66KH2333WAFpxm4dCTPFSayaoRQLKA0B6aceN1Zl0aqSETgGG1IGswwQHJ88wLN0XNum_s1lieJX5QFHmaPK_X1GPUeAtenVsf3_0PaqJiu-3BANV4vFCxVpkeCvPFqV_GPV_OVvIRzi11KjwuG6HzbaSxBX3cPz_rr9rM8GCFFSLUeKl_afupeKrtMc_6iaVRx56jRejzkUsDsNlmmjUWdP1PDYhD6URfNBDpMo2t3yQHBEK0G5zAa7IquVprokTIe0MgKpwJI-qDu0iPJFb478FT82UPtgXzRNDVObnhm0tSgsVOcUd49KW6VUud_N-s5UjIZWVOdYqNY7-3vZe4RUGb2_U8fIUdE4d5eqpkh2EOm6WVb6zO4AWxwFjN-WvdNDtiyTFJ8G55N7k2Yau42fetIc60kGDXsP49cNY6_UfaSBWeu_MU1vNitIFaa4a-zGWBN3uE9ab8XwCNcVlCaRwGOBb6Ce4gInMQqY4KaIGqzw9ZM_Kn5npYmhgCqGFc6GFSO50dI_plERe3qelYvtxpRJIPn0llPKYBE3zByGD9YiGzxMaFbDE72ZXXnbO1c6bcmFS0eD3IAQ" style="width: 100%;">
                        <p class="caption">OFA 모델별 크기, 출처: OFA 논문</p>
                    </div>
                    <p>
                        <br>아래는 VQA와 SNLI의 visual entailment 결과입니다.
                        OFA가 SOTA를 달성한 것을 볼 수 있습니다.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AKsag4PuKk87xTjfFNXYa645DhYMUJ1WOfDpNcBQof1aCmxSf1KLHbJqbT7bzHkSwL7G4BBjc3AngpSKai0cya1vF9h99ln3JAd3y4pKkrnNu7TGKQvBgKTarEodFs-0S6fXZrdC37wLeNMIIZABpVkOJ9mzWQEeXzutYbPy0qYdvSmPDVz4jrn-vLxiDeXjOEcoLaGXTZYwD6xZKGYnnuEi2vqiRCdB0XcoqkoAEKfi65pqGQYge95bAIHRijw4ULU2Okc698f4W31u3pGFKR009Ii8oGuM6_d5pOLom5_5KqQMH1ebT7ipT7W6qqjSszpzhdoAeZQSthawKMvlS0lqpDnl_yaf1NtgHSmW4DhQxMrdilqE7TLm5hZu1BIgvhaOtmCk-hVBPlqqL98BCCqDamIip7e8t6Pl-D8j0ZRPFQQYHo9oSBN6v9uueJxQN26osZHSfpjhYnm33rimtYqgPa6hGpEeAlbRJ4Iv6EFjuhPelcQpQ9oUivL8DbYt7PqECsA7Tcy3V6NWc93OWuvZ1lzKHTFceRK2h4pr8sN_pN2k-X76d8umkljZxPgKfn0nWvq9uI1FGtc40D0YyvXRqRgWPhg1F4rxfAlhx8O98OufCO2l6t9JC1C8MphjmYftHGZwDERmdci3rZNKiG7yWDTrhDYevPWsCt5nL-XRoYOKATv0tqr1yRGmz8qFpPaKsUnQvlNIl1VyLCHqqiHr6BzGxcM_Db4dFu9EebY9vQlLBZKZmnkaE-6ta7RYNDN2bZ_kf6p6gAOqkitS2IBHCJkx6rHj8frxpvvpW5cwoYzTPUbWRqOjMJT-yWOV03jaEdwbtDXX0_tiZRjfCSTKdUWdu8ZyfO8MisfZbFITfWMYWJYUh7L8B2KsWcE8QC9wjNJXavCI1pHdp2Cnkz8ItC39ddm54qD6IIBsMxi2sXsxObS3tX2q4pvgIZb9E2BGLFuPHEdfhofNGiUh7fLb1E8BiE2I09PWccwS9HoEldvUppxGBWTjOPoMN1fdTGtfTpxKm_zARLTD9j5bwGhcxgu0f4yeFUytUgqSr5X4Co5Zv4JL6zKdUifiQuD5prQ7_RY8SYc2tvQFaftVThUXmAQLNY6RlrcRCBU5csPmJEWWqWsI37ScLZLhJ9vDRZ7F_aULOeBkj6hrUQvWOCqyGJNf_A1fr9uu_jHtGn_lwje1EizyXPTg3sowEiyNE6uY9XYCTdi2NDSp5tYhVs-xrngOJL9J1BdesOiFr-1H5M6Ar5YQGMn2O2GsimBhMngqTI7nN30NHJ20zCg4fYFoLB5Y0pZ6dmHia9mY86jA6b2bPMJAK98SVjjeiwCu-7Iyh1f0zpQy5CaZpSSIn9dpTJvcciS-upZgYPt0VqSLhg0sb09eZZa4AjDP1Rz9sHhvcUVHZAHGDE_XGNtiYV9l5WgclQ9P6IbpjV5wwZ2lsYn9HGQ6MA-zqnUkvHSah7dHSwrBQYkBK6fy1ob8MK3sjRtRSt6Sn9fiIe5KnC2fe-0dAsmjkAVJYtnlypAW27e2YmT5V0YBMNyPg61Xpg" style="width: 70%;">
                        <p class="caption">OFA VQA와 SNLI-VE 결과, 출처: OFA 논문</p>
                    </div>
                    <p>
                        <br>아래는 image captioning의 결과입니다. 역시나 OFA가 훌륭한 성능을 보여줍니다.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AKsag4NjetH7-X-R5-1agkQnBzlMN58O3d7p5zcoS6Io9VRDtDdKdk9ue0y1knkXegcxjmXlRT_mp38fUP52d2F0SzAv-Y7aRMLCEtEosSTnMb_z1jAsBxg_BEd02sYTWuJoqrMW8aVzA7zQtRZHSl76P9zpn8aBsuk5HV74Ym4Js8FaXjCrBBc1UY6-8sU7uPKjY787WNoVa44HIIF7f0iMlql4JF-kEAo8seVAv7lxk1D6Y_m9OOzX-a9tYzEIAY-wxj4UMIR3U1_sZPOLsvNjJgnQZdYgx5xXau4VoEIZLkF7ZiB_378e4LNoIuJSb8_s0iMtCnZ0RHRr2UjQcEPUAgq6XRR0jYu6aEMCdpIJSPhGR1GSJv-XYIdPsDm568BJVodojc0NDhbPvHi_hWiRBIKAp0B1ImJ3CfI2GPl1ieAhI5iDHlAXKi8up6tcp3k6aQBbmS7gL4kuB03cx6k3AmNsN6KGcDIaJfLIRiewtRO15u0hp0TViKAqT2rLAk5EZgcPH0y6UMcueCM_u-77c9-Vc63mtzh_9w6vzEM6ZMNSykyDsuOVRTP-fMwbkLaTssaKhEpNzPRv0L4Lu59be_cD0lCHDlIMnenVxYdwkQ5vhw2IvN33_PvX2r8wawZnbwtddZOMQi6St1rA59Luusv66kpGMP7zbsHXZI36BNMI6n3IioB0hxKqEWBmPLgbwLLbxdp4gbxqqlUacpyPsTWEb3YExFWbVAb2XDQv3RfnWUOjCMl0-qRmNacHdPiG9_kccRcQufm0TOeBqiJOTTIl82xMD5aH34JI71ERrQ-jXjpT9dw34MYsav5TC8ouqn5yZMArqDPhjTQAnlnCRmHWVIXVNpmp-jtPFqvM-S0Lkrl3RDkCcF9gPLW_7kD4QROLKo1yuTPj0d3j9s4OHcVsxjrjwa66X0f4GG1HRcbhYxPe5mGHUXlmbPEDP-BO3kzyPNPHR1EdeioXueWSeSlXDWic6Zb-7ZoSPE9D6NScCOxgPhmUq5S4767W36r0eHDfP1VxTRqYIODe0QJVWh-YcgET6SWLIujWDmU_-KlYkPUPZTr_AvzlHsMB0eBTjNiK_k89y4DQ7ZOaooOJukZxDgOl_Z4zDA4Jy-FABYmBh_rCNWF0CVs_8rSXtlmcnPGLsXXhwYEfUGKHnwaDBLfTJmVct-K61ggjTyWLaa6P_e7K2pSPprfqTM2P9N_yVpDlV5a6Gc4NHp8gYngsmWZAR79pElSIAbAMDFM2QvQQ-bVL6MvFM8Y8H2lu5xh0NGDPM883UnPiyVC0dIUGsD1v6RyF46oeMREb2J0XtQv2_CXWrmkjDMMiHT3Qz2G1UmjjDCpLe9esVtd_M6GEs-memFzI5H_mjH8NpSf8WiNX5JZVc5gPJX6aNhb5LOreftKbQ8f6Fz6Lj5nOFVhnudsLZ7ZhyNTU9cOe1vgj9fsipV9vXq1d8mvY358_xgmaNST6kUEmw1MMsYxDpa0ZHSgEAOMMZ7HG55TMkC7IXvygNXK-gX5Mtj52jgdUXRQDgH4Xs51vOquVX3p7Aw" style="width: 70%;">
                        <p class="caption">OFA 이미지 캡셔닝 결과, 출처: OFA 논문</p>
                    </div>
                    <p>
                        <br>마지막으로 아래는 text-to-image generation입니다. 즉 텍스트를 묘사하는 이미지를 생성하는 것이지요.
                        <span class="highlight" style="color: rgb(0, 3, 206);">이때 이미지의 생성은 이미지 토크나이저의 decoder를 사용하여 생성하게 됩니다.</span>
                        좌측의 예시는 사실적인 text query, 우측은 반사실적인 text query를 주었을 때 OFA가 생성한 그림의 결과를 보여줍니다.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AKsag4MlW1UtVwoE-aJXP62Uv-roUk_EkZsSBGErOQkd6Fx9KrKKnWjMGRITRzU9Bg0blrGFM1yoOcouO8vkGM9_2ddBIr0Aela7-80Gq1UwbFRmqCT6iQ4d55DYPVPajdznUsR-XTbxIWJy6asZY4FJTecWGuEpsCyP7t92pGx0B5-EUSc1kqKaa3Mst2fGKg84THgkzV6JPJk1KqT2bs0iNDxHjBxhIZkTYuVOrXgzAGvIh2OANewW-FIiDX8PQJ0HoWyysqO5Puc-Pyhg1s5ag8hNxlSrVt0VSx3h552pWNZTf1EYIheFjrtfXP0xfxYESxlKcDe7r59Pu_74eIW2KMSugmc7o5U_B28JW9TKJdYWwuP_976OlEslkKVwmymHoG3TAjvKHem4NxbqKXa8XDZlX2qbGsSTx1waGg4uIOX0eZ0e49vE8CzgKMPTfLEAB-b9I-G3enjkKjthskfKnqvTQ1CgEUlqnStV14fXtX2k6xIL6oBDVZ6Ds4XMYERYEPvBvGhqKmqXgzj9056VMNDKe-V4JuRRUJBmRuFEwUf0GgM0QUAgvP3CLfzlUsXeDnJiJoeVNFmX_A1ncZB3Qnui1nXK88BJz10KuGvvj-kwr-wYVefGJkSyJmsUsUCwrRy59r5T_dDv6L7GilxfXlQxbn1IOWYPKFc-bUKEOZ8RD-1pv1A5Y97paIyZEtEIXWTxe4xgKja3clJGWwl7-9uLy2RyMCOW11ZsBsevmt4IqMpVfu8MExRl1L03pZaf5xJVjtnNNRXyC87fyVmwpQn1L6nSTP0VOKpG2PKvyYK5y9lQ2v9yTGB5I61b0otAT-2cxIQp_YoLmprySq-XS3W56vluCRYLaHyewyjWaherSIeHk2_0rUtgEXycShakHbYLoL1cnOfTcrYBizY0mvlu5FThVrmZ4bAqxjtS5g9E1KELTk7tDol-Uz6Jkonoea_IfZRlVEdU6NvCf2J4yfraCVi1C_w63p78Hf_iKojOOUuS134go-dYy0Rp3xoVNYAVNqqfrpjPeqTGSYqBpjxbZ_0i6sQu8ZJ0X6q8JUQ54OnjOouTUhbgz6WwMf_nsFjjrBTNba4aNMk5OQ8alIEFWg9mioqU-HWJz7zVTDn6AXpmRMHTftpKnO7v6dfc2Dw9sAKrrQFuDj1-7WsUOumwqCux0Dcafjo945XX0bxMYuUOsdp9_4hzv-VI_ph6D7mUflbHV7EjQ3oklnPjOLCuOAjNnDYrGTspPePzOq9IqDh5XrEAFKGMDqUT78r_dGzvOgQctNRc0EcQwbU2XZb8UtobNHvK6txB6tcGv8-Qe6biQiv8gxiC7bdJsf2LENFvmh0TxZdlBxi8uLRLHW1m6pxa-LpGlU_8qsogqFpWlSpUmD3NuPfIgz3tqDqOX3vTmf9EiVhhlYt_b7BaRug23UyRbdZj_0yqQwi8Qk5e4Gg57JjVLGTPROYl10zvd4uSsZ0p4coRnN6jFT4ZJYc745vBj-A5FV3Fwj455d30nX6HU9hWcgaJX9TC2e034BjHYp2QRwmK6pETkw" style="width: 70%;">
                        <p class="caption">OFA text-to-image generation 결과, 출처: OFA 논문</p>
                    </div>




                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>OFA 의의</span><br>
                        <span>Significance of OFA</span>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        OFA의 의의는 아래와 같이 정리해볼 수 있을 것 같습니다.
                        <ul>
                            <li>간단하고 적은 크기의 모델로 다양한 downstream task에서 SOTA를 달성.</li>
                            <li>20M의 비교적 적은 image-text pair를 이용하여 여러 multi-modal task에서 SOTA를 달성.</li>
                            <li>Task, modality-agnostic한 모델을 제작 &rarr; Language, vision-only, vision &amp; language task를 하나로 통합.</li>
                            <li>Uni-modal의 특정 task-specific한 모델(e.g. RoBERTa, ELECTRA)보다 modal을 unify하여 학습을 수행한 결과 comparable한 성능을 보여줌.</li>
                            <li>Language token, visual token(VQGAN의 이미지 codebook 사용), location token을 하나의 vocab으로 구성하여 multi-modal 데이터를 통일된 공간에서 표현하여 학습.</li>
                        </ul>
                    </p>
                    


                    
                    <p>
                        <br><br><br>OFA는 간단한 구조와 비교적 작은 파라미터 수를 가진 모델을 이용하여 multi-modal 뿐 아니라 uni-modal에서도 뛰어난 성능을 보여준 모델입니다.
                        다음에는 다른 LMM 모델을 리뷰해보겠습니다.
                    </p>


                    
                </div> 
                <div class="tag">
                    <b>태그</b>&emsp;#OFA
                </div>
                <div class="pageTurner">
                    <div class="pageTurnerLeft">
                        <span><a style="position: absolute; left: 0;" onclick="alert('OFA 첫 게시물 입니다.\n\nThis is the first post of OFA.');" onmouseover="colorOn(this);" onmouseout="colorOff(this);">&lang; 이전글</a>
                        <br></span>
                    </div>
                    <div class="pageTurnerRight">
                        <span><a style="position: absolute; right: 0;" onclick="alert('OFA 마지막 게시물 입니다.\n\nThis is the last post of OFA.');" onmouseover="colorOn(this);" onmouseout="colorOff(this);">다음글 &rang;</a>
                        <br></span>
                    </div>
                </div>
                <span id="readNum"></span>
                <div id="disqus_thread"></div>

                <script>
                    headHighlightColorChanger();
                    (function() { // DON'T EDIT BELOW THIS LINE
                    var d = document, s = d.createElement('script');
                    s.src = 'https://novicetraveler.disqus.com/embed.js';
                    s.setAttribute('data-timestamp', +new Date());
                    (d.head || d.body).appendChild(s);
                    })(); 
                </script>
                <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </article>
        </div>

        <div id="menuRelated">
            <div class="menuButton">
                <img id="menuImg" src="init/index_img/menu_black.png" onclick="openMenu(this);">
            </div>
            <div class="menu">
                <img id="menuExtension" title="메뉴를 확장합니다." src="init/index_img/extension_black.png" onclick="extendMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
            <div class="bigMenu">
                <img id="menuCompression" title="메뉴를 축소합니다." src="init/index_img/compression_black.png" onclick="compressMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
        </div>

        <script>
            detectScroll();
            pushFunc();
            detectSize();
        </script>
    </body>
</html>