<!DOCTYPE html>
<html>
    <head>
        <title>One For All (OFA)</title>
        <meta name="description" content="OFA에 대해 설명합니다.">
        <meta charset="utf-8">
        <link rel="stylesheet" href="init/index.css">
        <link rel="stylesheet" href="init/contents.css">
        <link rel="stylesheet" href="init/index_img/icons/css/fontello.css">

        <link rel="preconnect" href="https://fonts.googleapis.com"> 
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> 
        <link href="https://fonts.googleapis.com/css2?family=Dongle:wght@300&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Gowun+Batang&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic&display=swap" rel="stylesheet">

        <link rel="stylesheet"
            href="init/highlight/styles/github-dark.min.css">
        <script src="init/highlight/highlight.min.js"></script>
        <script>hljs.highlightAll();</script>
        <script src="init/highlight/highlights_line.js"></script>
        <script>initNumber(window, document);</script>
        <script>hljs.initLineNumbersOnLoad();</script>

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        <script src="init/index.js"></script>
        <script src="init/jquery.pjax.js"></script>
        
        <meta name="viewport" content="width=device-width, initial-scale=0.8, max-width=1">

        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-219110982-1"></script>
        <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-219110982-1');
        </script>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7745178886614102"
        crossorigin="anonymous"></script>

        <meta property="og:url" content="https://ljm565.github.io/contents/ofa1.html" />
        <meta property="og:title" content="One For All (OFA)" />
        <meta property="og:type" content="website">
        <meta property="og:description" content="OFA에 대해 설명합니다." />
        <meta property="og:image" content="https://lh3.googleusercontent.com/fife/ALs6j_FAuuvyvau4YU42EFMFFyGpUIoqA-E762xLB_YWyM0QQwrp3VKePO-BGhmFiecHRaRE2ceApytHWf2ppkBP-fCbyUU09EdCdneqrLELjkUQh24AvvJ8m5sXoP30uPEQzPTGNKi7NBMjKiJrtalFeieTWoow1lqZAkOT2DuYUg1MzvhJ_T2YDzLRNeyEUtjyY58zKKx51gBwsYMPnXgjlV251f8Ulw17eh3GoJ5CmD0qbgn9f8mfuYUF2tCnPJpoP6-zSITZOu9ICDfkslKedgMvLwVGNuowyvMrSAEVcvwB58dxu9F3b4lqBE-QOdjAouTHRl5SlT68tTRkf20Lhr4WUFuyElS2nHmq9TSA3d7cLINbuzHpzw9DlJNkaYNjy9ZI4IdcOZhlfKQQpfeb-VlbpgRmXskBwN7fZaQ31o5YKPFTWkDSfi0Di3LBbvx7BARrou5ATTm_nvx0MyXxRMSmd-QBbVkQmR10cdc-nwAQCqJqzKwCZv1QArzkhEE0XsYcyQOeA314SAK46RxgI7E0kkynCFPB3dGViYtxBbqFZS5wIBbVVvyOTAEQgJ9UuZ9XgecPkDfkSTAFDd7VvuqOmBaknUU4qzkNkRhGFh1YKgEOzpqWq34lf82MlbO_kQ2-2bzh9cjt9mpckWvakCKZXyuyX7w6iY_MOQ2xP9L3jf0_vN-NCnpfLOADbucJ925vPqFugFha5ulsRGCFxY_nkGZuYFWOjrf-RgVTBrsb94bWtfD7dGH8FidmdgwcUEbFuk3SbUzvPXW59CABoGPG5FZVQOJ9B5MmnYuC_IucO2dtB2WIQWkhjGqHY7lLag17T8hp31UjLKXATT57_pEcNgKTH7ia27NTbGEkJmANUvpPQSimnsw3Ecw6ohnCZABF4s8-Y-XaHsmdi1HjYwaXBSDWnT6j5lf65USH57DQ6KN2Uzz5W8SQs0JB3n9nIt8NxST-Mitw0XJwcna9ZvLMYBeJsLDTz2oyITkNpQb1tVtiU5yUAAzb1-FQsdQvwlmEIgUP5gA2U4Q074eIxixOhjq_jssoXQLjVNQLqsOIvPHKGFRAqa4BXAGsUlDCQ0QVhna694VWC_untBNOL8dCi0cVypOXDHP_1YkGIFd9eqDFA-try2pdFt1Wp4EtjToF7e-_Yi2LCfRmQTiUh1PGuKqjYUY9iCRDwnPgg3OhsTcibkdp23Zwh57GwakS-2CoKc4r7qSLSHWvn-S0GOqICRQ9bRmqrP_lyms7rS6S5nUDL-b5ozH5wp0wJNhIwEETdV_qdVUigIj1I22_4zYn8cqqVUnkMwxYPHfjg2EquGZikGrNyRqyOsom9sd2MwL8yrA43TUQUP5N13yXva3JOjBVa9iSkeD4PeYZsDZ-eeuB4EPTGOnRCdb-_GpZOXL9xZKJCObBssgqFPWh-_vub_OgGz4aXbtdXAsl2Q70VJh76r4DHylPu1TsrtoKeGytvF8DLvvrFA_RdEEhu2IsmDEKMT6_xadQutJzqKc1vMcTSQwHObcItG97JT7MXh91zmuu0A" />
    </head>   
    <body>
        <div id="modeButton">
            <button type="button" value="dark" onclick="darkMode(this)" onmouseover="hoveringOn(this)" onmouseout="hoveringOff(this)">
                <div class="modeImg"><img id="modeImg" src="init/index_img/moon_off.png"></div>
                <div id="modeState">다크 모드로 보기</div>
            </button>
        </div>

        <div id="container" onclick="reload();">
            <article>
                <script src="init/highlight/highlight.min.js"></script>
                <script>hljs.highlightAll();</script>
                <script src="init/highlight/highlights_line.js"></script>
                <script>initNumber(window, document);</script>
                <script>hljs.initLineNumbersOnLoad();</script>
                <script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
                <script>
                    initMathJax();
                </script>
                <div id="mainHeadWrapper">
                    <div id="mainHead">
                        <h1 class="contentHead">딥러닝 이야기 / One For All (OFA) / 1. One For All (OFA)</h1>
                    </div>
                </div>
                
                <div class="title" style="background-image:url(https://lh3.googleusercontent.com/fife/ALs6j_FAuuvyvau4YU42EFMFFyGpUIoqA-E762xLB_YWyM0QQwrp3VKePO-BGhmFiecHRaRE2ceApytHWf2ppkBP-fCbyUU09EdCdneqrLELjkUQh24AvvJ8m5sXoP30uPEQzPTGNKi7NBMjKiJrtalFeieTWoow1lqZAkOT2DuYUg1MzvhJ_T2YDzLRNeyEUtjyY58zKKx51gBwsYMPnXgjlV251f8Ulw17eh3GoJ5CmD0qbgn9f8mfuYUF2tCnPJpoP6-zSITZOu9ICDfkslKedgMvLwVGNuowyvMrSAEVcvwB58dxu9F3b4lqBE-QOdjAouTHRl5SlT68tTRkf20Lhr4WUFuyElS2nHmq9TSA3d7cLINbuzHpzw9DlJNkaYNjy9ZI4IdcOZhlfKQQpfeb-VlbpgRmXskBwN7fZaQ31o5YKPFTWkDSfi0Di3LBbvx7BARrou5ATTm_nvx0MyXxRMSmd-QBbVkQmR10cdc-nwAQCqJqzKwCZv1QArzkhEE0XsYcyQOeA314SAK46RxgI7E0kkynCFPB3dGViYtxBbqFZS5wIBbVVvyOTAEQgJ9UuZ9XgecPkDfkSTAFDd7VvuqOmBaknUU4qzkNkRhGFh1YKgEOzpqWq34lf82MlbO_kQ2-2bzh9cjt9mpckWvakCKZXyuyX7w6iY_MOQ2xP9L3jf0_vN-NCnpfLOADbucJ925vPqFugFha5ulsRGCFxY_nkGZuYFWOjrf-RgVTBrsb94bWtfD7dGH8FidmdgwcUEbFuk3SbUzvPXW59CABoGPG5FZVQOJ9B5MmnYuC_IucO2dtB2WIQWkhjGqHY7lLag17T8hp31UjLKXATT57_pEcNgKTH7ia27NTbGEkJmANUvpPQSimnsw3Ecw6ohnCZABF4s8-Y-XaHsmdi1HjYwaXBSDWnT6j5lf65USH57DQ6KN2Uzz5W8SQs0JB3n9nIt8NxST-Mitw0XJwcna9ZvLMYBeJsLDTz2oyITkNpQb1tVtiU5yUAAzb1-FQsdQvwlmEIgUP5gA2U4Q074eIxixOhjq_jssoXQLjVNQLqsOIvPHKGFRAqa4BXAGsUlDCQ0QVhna694VWC_untBNOL8dCi0cVypOXDHP_1YkGIFd9eqDFA-try2pdFt1Wp4EtjToF7e-_Yi2LCfRmQTiUh1PGuKqjYUY9iCRDwnPgg3OhsTcibkdp23Zwh57GwakS-2CoKc4r7qSLSHWvn-S0GOqICRQ9bRmqrP_lyms7rS6S5nUDL-b5ozH5wp0wJNhIwEETdV_qdVUigIj1I22_4zYn8cqqVUnkMwxYPHfjg2EquGZikGrNyRqyOsom9sd2MwL8yrA43TUQUP5N13yXva3JOjBVa9iSkeD4PeYZsDZ-eeuB4EPTGOnRCdb-_GpZOXL9xZKJCObBssgqFPWh-_vub_OgGz4aXbtdXAsl2Q70VJh76r4DHylPu1TsrtoKeGytvF8DLvvrFA_RdEEhu2IsmDEKMT6_xadQutJzqKc1vMcTSQwHObcItG97JT7MXh91zmuu0A);">
                    <div>
                        <span class="mainTitle">One For All (OFA)</span>
                        <br><br>
                        <div style="display: table-cell; margin: 0;">
                            <img src="init/index_img/profile.png" style="width: 30px; cursor: pointer;" onclick="pjaxPage('/');">
                        </div>
                        <span class="subTitle" style="display: table-cell; text-align: left; vertical-align: middle; padding-left: 20px; line-height: 125%;">작성자: 여행 초짜<br>작성일: 2023.09.04</span>
                    </div>
                </div>

                <div id="content">
                    <p>
                        시작하기 앞서 틀린 부분이 있을 수 있으니, 틀린 부분이 있다면 지적해주시면 감사하겠습니다.
                        
                        <br><br>이번에 소개할 논문은 바로 2022년도에 공개된 Large Multi-modal Model (LMM) 모델인 One For All (OFA)입니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">OFA는 이미지와 텍스트의 modality를 다루며, multi-modal pre-training을 위한 통일된 구조인 Sequence-to-sequence (Seq2Seq) 구조를 사용합니다.</span>
                        OFA는 이러한 놀라울만큼 간단한 구조를 바탕으로 다양한 task에서 SOTA 결과를 보여주었고, 이로써 multi-modal task에 효과적임을 입증하였습니다.
                    </p>
                    <div class="link">
                        <a href="https://arxiv.org/pdf/2202.03052.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);">OFA 논문</a>
                    </div>
                    <p>
                        <br><br>오늘의 컨텐츠입니다.
                        <ol>
                            <li>OFA 목적</li>
                            <li>OFA 구조 및 학습 Task</li>
                            <li>OFA 결과</li>
                            <li>OFA 의의</li>
                        </ol>
                    </p>



                    <h1 class="subHead">OFA</h1>
                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center;">&ldquo;</span>
                        <span>OFA의 목적</span><br>
                        <span>Objective of the OFA</span>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        OFA의 목적은 3가지가 있습니다.
                        
                        <ol>
                            <li><b>Task-agnostic</b>: 어떠한 Task에도 적용 가능하도록 함.</li>
                            <li><b>Modality-agnostic</b>: 어떠한 modality에도 적용 가능하도록 함.</li>
                            <li><b>Taks Comprehensiveness</b>: 모델의 일반화 성능을 높이기 위한 다양한 task 적용.</li>
                        </ol>

                        <br>일반적으로 위의 3개의 조건을 만족하면서 좋은 성능을 내는 모델을 학습하기란 어렵습니다.
                        따라서 많은 모델들이 pre-training을 한 후 각 task에 맞게 fine-tuning을 하거나, 아예 특정 task에 특화된 모델을 자체적으로 학습하는 방법을 많이 사용합니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">하지만 저자들은 이 모든 조건을 만족하는 모델을 위해 Seq2Seq 구조를 이용하여 모델을 구성하고, 이미지와 텍스트 modality 모두 하나의 vocabularay로 통합하여 다양한 instruction으로 multi-modal 정보를 모두 학습하도록 합니다.</span>
                    </p>



                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>OFA 구조 및 학습 Task</span><br>
                        <span>OFA Architecture &amp; Training Tasks</span>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        <span style="font-size: 20px;"><b>1. OFA 구조</b></span>
                        <br>OFA의 구조는 놀라울만큼 간단합니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">아래 그림처럼 단순한 Transformer Seq2Seq encoder-decoder 구조를 사용합니다.</span>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_FAuuvyvau4YU42EFMFFyGpUIoqA-E762xLB_YWyM0QQwrp3VKePO-BGhmFiecHRaRE2ceApytHWf2ppkBP-fCbyUU09EdCdneqrLELjkUQh24AvvJ8m5sXoP30uPEQzPTGNKi7NBMjKiJrtalFeieTWoow1lqZAkOT2DuYUg1MzvhJ_T2YDzLRNeyEUtjyY58zKKx51gBwsYMPnXgjlV251f8Ulw17eh3GoJ5CmD0qbgn9f8mfuYUF2tCnPJpoP6-zSITZOu9ICDfkslKedgMvLwVGNuowyvMrSAEVcvwB58dxu9F3b4lqBE-QOdjAouTHRl5SlT68tTRkf20Lhr4WUFuyElS2nHmq9TSA3d7cLINbuzHpzw9DlJNkaYNjy9ZI4IdcOZhlfKQQpfeb-VlbpgRmXskBwN7fZaQ31o5YKPFTWkDSfi0Di3LBbvx7BARrou5ATTm_nvx0MyXxRMSmd-QBbVkQmR10cdc-nwAQCqJqzKwCZv1QArzkhEE0XsYcyQOeA314SAK46RxgI7E0kkynCFPB3dGViYtxBbqFZS5wIBbVVvyOTAEQgJ9UuZ9XgecPkDfkSTAFDd7VvuqOmBaknUU4qzkNkRhGFh1YKgEOzpqWq34lf82MlbO_kQ2-2bzh9cjt9mpckWvakCKZXyuyX7w6iY_MOQ2xP9L3jf0_vN-NCnpfLOADbucJ925vPqFugFha5ulsRGCFxY_nkGZuYFWOjrf-RgVTBrsb94bWtfD7dGH8FidmdgwcUEbFuk3SbUzvPXW59CABoGPG5FZVQOJ9B5MmnYuC_IucO2dtB2WIQWkhjGqHY7lLag17T8hp31UjLKXATT57_pEcNgKTH7ia27NTbGEkJmANUvpPQSimnsw3Ecw6ohnCZABF4s8-Y-XaHsmdi1HjYwaXBSDWnT6j5lf65USH57DQ6KN2Uzz5W8SQs0JB3n9nIt8NxST-Mitw0XJwcna9ZvLMYBeJsLDTz2oyITkNpQb1tVtiU5yUAAzb1-FQsdQvwlmEIgUP5gA2U4Q074eIxixOhjq_jssoXQLjVNQLqsOIvPHKGFRAqa4BXAGsUlDCQ0QVhna694VWC_untBNOL8dCi0cVypOXDHP_1YkGIFd9eqDFA-try2pdFt1Wp4EtjToF7e-_Yi2LCfRmQTiUh1PGuKqjYUY9iCRDwnPgg3OhsTcibkdp23Zwh57GwakS-2CoKc4r7qSLSHWvn-S0GOqICRQ9bRmqrP_lyms7rS6S5nUDL-b5ozH5wp0wJNhIwEETdV_qdVUigIj1I22_4zYn8cqqVUnkMwxYPHfjg2EquGZikGrNyRqyOsom9sd2MwL8yrA43TUQUP5N13yXva3JOjBVa9iSkeD4PeYZsDZ-eeuB4EPTGOnRCdb-_GpZOXL9xZKJCObBssgqFPWh-_vub_OgGz4aXbtdXAsl2Q70VJh76r4DHylPu1TsrtoKeGytvF8DLvvrFA_RdEEhu2IsmDEKMT6_xadQutJzqKc1vMcTSQwHObcItG97JT7MXh91zmuu0A" style="width: 100%;">
                        <p class="caption">OFA 구조, 출처: OFA 논문</p>
                    </div>
                    <p>
                        <br><span style="font-size: 20px;"><b>2. OFA Tasks</b></span>
                        <br><span class="highlight" style="color: rgb(0, 3, 206);">위 그림처럼 OFA는 다양한 task로 학습을 수행하는데, 텍스트 뿐 아니라 이미지, object location (bounding box)까지 모두 토큰화하여 unified vocab을 구성하여 학습을 수행합니다.
                        이는 다양한 modality를 하나의 공간에 표현하도록 학습하기에 용이하고, 모든 학습을 cross-entropy loss로 가능하기 때문에 학습이 매우 간단해집니다.</span>

                        <br><br>그렇다면 어떻게 이미지와 object 위치를 토큰으로써 나타냈는지 알아보겠습니다.
                        <ol>
                            <b><li>Object Location Tokens</li></b>
                            먼저 object같은 경우는 이미지의 가로, 세로 길이를 location token 1,000개로 나누어 각각의 위치를 표현하게 됩니다.
                            <span class="highlight" style="color: rgb(0, 3, 206);">가령 가로 세로 크기가 100인 이미지에 boudning box 좌표 중 하나가 [20, 40]이고 위치를 나타내는 토큰의 vocab 크기가 1,000이라면, [&lt;loc200&gt;, &lt;loc400&gt;]으로 표현하는 것입니다.</span>
                            
                            <br><br><b><li>이미지 토큰</li></b>
                            <span class="highlight" style="color: rgb(0, 3, 206);">기존에 많이 사용되는 이미지 토크나이저를 이용합니다. VQ-VAE, VQ-GAN, Taming Transformer, DALL-E의 dVAE 등에서 이미지를 이산 토큰을 만드는 이미지 토크나이저를 사용합니다.</span>
                            이렇게 했을 때 좋은 점은 이미지 역시 이산 토큰을 가지기 때문에 cross-entropy loss로 학습이 가능하며, 토큰화 된 이미지를 decoding하는 decoder만 있으면 쉽게 이미지를 생성할 수 있다는 것입니다.
                        </ol>

                        <br>이제 위 내용을 숙지한 후 다시 위의 task를 보면 이해하기가 쉬워집니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">위의 task들을 보면 multi-modal learning만을 한 것이 아니라 uni-modal learning도 포함 된 것을 볼 수 있습니다.</span>
                        그리고 아래는 위에서 설명한 모든 modality를 이산 토큰으로 바꾸어 수행한 학습들입니다.
                        <ul>
                            <li>Task 종류</li>
                            <ul>
                                <li>Multi-modal Learning</li>
                                <ul>
                                    <li>Visual Grounding (VG)</li>
                                    <li>Grounded Captioning (GC)</li>
                                    <li>Image-text Matching (ITM)</li>
                                    <li>Visual Question and Answering (VQA)</li>
                                </ul>
                                <li>Uni-modal Learning</li>
                                <ul>
                                    <li>Object Detection (Detection)</li>
                                    <li>Image Infilling (MAE와 유사)</li>
                                    <li>Text Infilling (MLM과 유사)</li>
                                </ul>
                            </ul>
                        </ul>
                    </p>


                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>OFA 결과</span><br>
                        <span>Results of OFA</span>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        위의 방법과 구조로 학습한 OFA의 모델 종류와 그 결과를 보겠습니다.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_GxKzuH6Gl3rKEqrRzBF7PHH0YQxvAC1AqeevVv0x4OJ-yetpJXd6x5Uss6QWiJKmTJEDr3-K7Qxea0ggf_TLKXQlcHefrKP_vHN1sfoAwuva4I9RcETMOo83luw1IbscG_hrszQ153iCSVT9TXf_KG7LDKJI935glTnT0cTv9zUPUu1f-xLT6aQo5hvhvHJiPTX9n9XxhggIJ-pIkbN7GEeMhOFQJ5DgnUe33beMSH5N2LXO7WD9rJDeGgKRvZRmAB0t1QEjM6GYn_hi3fBwxbZ2JJF5I7e3LNVlMxE6Rv4s-QBJ667wqAslhDHYmnEb0e44JqviuLcJygBIvLvRAzha2s4BVogyIf1kHaV1h0CHc3zffQu2VCvHRSlJ0Jo8kD_zrpbLHZ0b0SgtRJyN91-_6QOCFQ02OjXUkBgMn28JcnYNVuMiApBBWv7menwGBqwFLz3A-pLtJ-6D6l53q-L47hFJdaWnbUXPmmqo8noIABNhFzPLT5uwhdIVK2Mj1MqFbdfO6GBN1t8WLnad8fJGoGu4Ymz_eoROhhshvuMq1nkLOvTk5JdPCLHPGLxiPciQ4kpc24waC-6Kgj4V-YsVK3Uth2ikQN6ZYKuotUKcOkBjeViLQ1etFfNONmQ7n6TkwJWBfKKUwEjvkDM9cEP2YQkrb3tPrVsnnPn1pi2z8UlmLezUWK7L6Vad5HoTeKLHF57g3q9jyX0YnniYATzHTLW-AwXQEGcaryMD5h-ROZ6vHkuqI-2b7h3p10i1Au2O2KmfuGoLQlfsVjBe981pYSxUvGfa80QLKGWToVwEr5PZ5ajqspYxvN1o2kZdVA6KKJ7jYPeJJnoKlzNQLjG8qpeR0S69iYH8H-VdH0k3jaarl-dC5XCHvAWMyBJIPfdU3GK7c-W5lOafeegj5u0F9jSB6dpwkli7tFNG_qrk-BEelZs4h1NTR1jRt0X4647Urn12DNFx0jVDrlkUtSi-gBKUGKVJZI8zTRbh2Mhh2wBOOx0FsSFKRpAIemvFSmrlvJKTClk2aDkHznSVM-bIqBVYgOfBt7uQlW84s2Gmsdy4qvxEFKHmpNlMHzfPhWvDddmq_TU6w_Tr86xiO8AgsIv8c8nI2OAIWYQlmtByozVn8qSGq6nV8QByk1OON3qyLdNIBlm4flHk4ikrGjmRA7LNnvMPg58WmBOjPC6p_BVMbFUsTejYSa5chAD_YEUGo0aoGt4rO228tGetgJPlrvLpX47yAGjMbfAZCoJRTmipUzG4HWinovE3npv32L7yQwDPYB75f2Y-PY3E7nqCZb8h3Pzl1Fpk33MASpKUp2ZQAYlz6bA_uKmqqm-ahLG9VeGNCMIO4kJhHVKqFL7fbwp__jhBniPrFB0wfQzifvB5H4jlcSRBAzUT062G3Se65HiM9qPD1G8on2NH7nDCfsYDES74jjzFx5i_cFzAqDmdz4lUYtObhAPsjYdf3P_H2hXpieLk9iop54h-AWK0KtnwWeNCcz6iReKFENkPubL6COI70cNMWRCE1V9RkWqVjHYccA" style="width: 100%;">
                        <p class="caption">OFA 모델별 크기, 출처: OFA 논문</p>
                    </div>
                    <p>
                        <br>아래는 VQA와 SNLI의 visual entailment 결과입니다.
                        OFA가 SOTA를 달성한 것을 볼 수 있습니다.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_EgLEUudSSbjDRDPvXhZD_Au992_k3NOW1FuPW6V1lKD2TnbQ83BvDYQ7v4JRCJPmcYrzqflkdvlmRUKPe7bU2Vyou7m_COHI6nsbrPy3fcdmz_JQqFiWbFSXFT-rCoPKLmmmsippVhsuvVTYZS1PXRtf9Zvv33cUH3MO8ANbev7BwSlxOLStFLrFk08nSHQxIfHY04nAOlasRJexo84zTELfwMYNlFi17oXwoSlH_ey1kSaA8-rdzOaJO5KoBpXw1fT64EzyPYJKVigVD_B4wWLsgzf3_uPZDtmGlSLZ4S-0qcmbxwko5q_GOyf5UtsZLrMFGii_0dPQBfPjsz5mmN75B2HCE2yqdD1S1Ro0vbd6l4qUDTBJ2FShDoA-HZ53y11SWgXlgv-VuW2tZfsHFz9g4M0qx-3NdFKWvjNPp9ILe1PR7Lm7UScaXOgnRkVlrYD_Ha-dJf0BOTV1B-3jBJhFNlNiPA_VCyVEU0OQixyL5A28fYumcOqtIdmYnaYQe0rEAIGy8bDIjEWsaaTcSzNokHbZ3IpukE_56vNbElKgyMPaRNEfKIKbIP1B9HeJSnYpkZKJIh4ZAIVYRPiJ2AmZDyGyDWRDppyKbaPZ8neZyMifrF1dtWLCEy-Cw8PMkYY__TwQQCzaeyi4bq7VDnLb78Y-U-0VejwXidoC7yJdYnUuWp3TaxWFXnVwgN83iPCBug-UrGDzr1R6t5asswpTW1BkpAOSD7-QWPHCUmL8iXfNTrIKLEasUY9hNm-uikYC5G9QA5PpaC5hdzfD-4HKRoLWkOU9VaCZNYSYMrF07_HJkITb6lBzLbiKHQQqfu0o1sdeOlcRvl9KL0Fz3rzBMNs4VQ1WwxXJgYfQvYtLGsPwu4OX4r2v4McDJ6nKo2ycPYgeeeRM55a9TiLd0Dh1GHrGxOWueuuBiD7UerSo7sCnGQOHAd4h3XjhNjDL3H4Fq0Djvvpkpv4QDTwXJ0zWVXF6bDoccaDUTrvUOTZBLLuhkUk9wwRHcgybZjZKCOeQwgz4y7cwue2CjZrwZRV5t62TnsE7YkiXoboxmMPuMstPV1_ClKEdQWwvdspjBQ9qRH7Dxx6pNFXkasu9g4EggFrKuY4puA_WiMqtGj_uBTUh-0aalvqz2oUoU7DIrjACplM3m9RpC1UjJk0Fgs_-SWmQ4k--8GPMl0X9c2O_hTguq_2f6YqvNQbdJCiiETB8FpriuCiNeUpd4iH7lkxC5Fo6DL-RiEdP45butRa5LYpFHAxEAAlElVM5iAxZh_Js7UFu-j_z59c4wrDC713TBwZWpEIry6RAE54_NdKfZq36tc6bqVyBxlNQHuUq56gbI2wximeyvUo7Hr7QwXzlLa2aruOJC2zTUtCqPRHmjrnCVTqYlc5K6RGImPBfQYzmqiZfH55UY5yjKt7eL4354J3VpnJRQCxeGarCkn123a3o11TmQrxYDcZFziKGLCXDovVO38GJvDxKznqQ4Pira73ZLRUqdxo5h3LUoz3gVHPxE_oVXfD1FKKUirduxb8BvrHQ" style="width: 70%;">
                        <p class="caption">OFA VQA와 SNLI-VE 결과, 출처: OFA 논문</p>
                    </div>
                    <p>
                        <br>아래는 image captioning의 결과입니다. 역시나 OFA가 훌륭한 성능을 보여줍니다.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_GUOPtop2sbitBcUaMw6-RiTs4ILqHAskNxoGMF3Thho-sLfiFiQT9qAwRGnrOJ5qOuvLW0leBDpbkVrbaykKDHIXa39I5gu8SVBX33KyyuuBFl1q1ItQuifIfUysYxdTfenXASb2KVmzhc5ktTbpK116UYDnb8BQvnAg-DJPMKb3LKVAeAtCEQ6OrN2gG4f6Y1H9c7kW86NogtHOnu7j5lnq1R3WQOYxxssYtkdpjVgo6Om104Yh_7uWodbZzCqZzb--c1_7ECQBuFnRJRqjgA1NK6sNGf1FRl_VpULqi8wTbsJanx-OInVigDMrWvErDMllCpmtKS0CiG7WCAeC2Zqw3apHlm7UO1hQcyRsfIUcyzzYbiCJ_ejVCskPR8ttKRmnwWM2gf-J3MWm0JiKU3SEcbQzHrsQEPKJn_Xfw-Y5lVWg9GOvDhd1Ot6fTMZsk5zhmEEDCStW9I_iQ6FYpmvSnSR_mgrR2A-xgQCIPK2_Lj5Q9m75f83U1i7-Uw0lru5XXLg8p0BmA0LNfpCmehQ57hHhNWnAjF2v0u-WffI7_f8uN7OvbaUYn7DcL3hnjcS3UASKqDCPpiDU6_Jvc5xdWy7NQ7kWhcr-WXBD2kFZ8n10TLyG5cpq8dk2XtzsYCm6cbS17BQJZ0l1mv7d95X0q3SfaAmep8pcUu7K4xvu6Fb5AESvo_48EaFziHCGqGaKDJwRvFoEpWLMAHGjJaJkvmhld4vnrfuTR38xX1yFZ5BtGlFyCMsSKzZfSfsu51ZyHsa6OoVF6F4_3eF4YaLXqpI6QVxZhsojI25H9ReRxhM4UD6hf3uCMRzmPNEP7EuFwg7QPuuDEmGidYUzEizTS6Wq6aYE5-sDi0ozmU3zjb1Ff2469HWWXMOBvrGMWyhIkUuBto1SXDsh7h-cxE0ZmQ5MgmRk44RX4_8VjLsnBgYGyrdoTzej0g3CraMk_8RDTItK0nWVpNNi2P1GMjlW7JjLHjujII6tDIub0txsJDr2heH-SNR1EYw8xd6SAkCvkN3JBCaX1nDcyHAQV3Kcfh9xiaEljk0eIAvCdI-w3QCQgKk9vdH3EOVJCtYPLvzhE6rI9tjGeIxxNEk8cJaA2NhSyd7o6P7LMYArSp3onUCpnNXtjEyaPVXzb6bOzBSExNtVVLHhk_W4yx9nkHQ9MAIE23vq89DHRYLw_BCycJXzrjVeOoUOPuv19xTFnLF56GkX1izTLOm3XGSYdYqqnAy-RNuyrVHM4-sdxE7KiR24twDqzOR6r-YNHqOH8rXBwjKRvA8Inx5MGRuComD_1JrwbmvvfXutYmHz0e3IOAqgauyM3all4HzMqCrsths3J-NU5C0oeUox8sTH1POhFcAspSdONR-m3xBP0RtQX5G60-Ouc1YbI50Cf0C8ZKSDlru_oIf8YpGEnTIvMlSeTiwRdk5gsBJ84-Gcgb0oIfIbnuXJxkHMjtpRh0E-k6PTAT535upkmtjf-0CX73bixC7f9M8vmmVAXOraYnMHhaqvgT9qlHNM6ykzMHXjvllA5Y7gmg" style="width: 70%;">
                        <p class="caption">OFA 이미지 캡셔닝 결과, 출처: OFA 논문</p>
                    </div>
                    <p>
                        <br>마지막으로 아래는 text-to-image generation입니다. 즉 텍스트를 묘사하는 이미지를 생성하는 것이지요.
                        <span class="highlight" style="color: rgb(0, 3, 206);">이때 이미지의 생성은 이미지 토크나이저의 decoder를 사용하여 생성하게 됩니다.</span>
                        좌측의 예시는 사실적인 text query, 우측은 반사실적인 text query를 주었을 때 OFA가 생성한 그림의 결과를 보여줍니다.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_H1gSIsIrapyRBDvz5sgsaIQf9ZpSLl3jifz4bwuURfLuZKYc8q1NrmgBZ3UkQ_LGH7ibq2mPNhGyTpjZXiviihL0FpQeHnn39-zVfdodkua9BRZQafBESO1VA8Vy8yu-0tVLfhZnAWKYx8g7hkWytVVi675Pdlg9FvweHBetqpHPhzuIPhrnI4-5nmGOfDrKpxNSH6XzlcpahIlEnu-qUH1ROQxiRTogE0ZFo1-qds0_EpaYsYIgHTrENT0jgv3Yblx0Gsb21dohPXhwOd-Sfk7sazkcS7_sqsNUZ-f3c6OwDeOdPNrmpWiV7zbOZyaCfdnvLehacTmcX2CHSc1e-krfGbvCEe_0nJJ92NcYBCKlW5T-d1k_iBiamY0-IzdhUBJ5u0meaqkYAhgev-VIRJUIGsncAV48kDlH6eLiTEFfJqK_dcSLgqZxyxKm5-COam95o_RdGt4_cyHM8PC1Avfj7US6uaFdIjCjGQTeen_lpKHlELwdcu8OLL93unrhiPZDL0dAmF-DpR_AYA0U_0wuETuJL5aniBJbNDs2V3E8XpbS7RzKWD0BUa7vhRPk1fncqitItp133UD5d8tPsOb4Ij01-69__dxIiSM9-ecCVQ6dgIIrL2C1OZbIs08Cbpe4JbeTGPS_Jj713NQtlaS649-vnA4e3dne8e8rmMdzMjaIEvZkAn82NAO5IL6mGZPopMjydl4waTmA-BY9yZIexhYKbOC9jt_5ns8ydlbiBd65jhMos5VN_gQ3maEQA1DOaYPQ0lJhkgIJU2nszlCJKFC0_vI_GGN0EXHB2RidvsiF4_xIMzZbl6YE30W-RuhkiQsIsUUXKU5ZI9dw4BlmgNWzZrUGPWO_1DVrcAnstaCxdrU9SABJagHDKgCiYIlWOdbg0pzkEn7auHc9Grs7VAaOU0LiQCbCF6moAval7GHWH-TR2bmQguZBjDNkYf8oO4iOEMLJq-H_atv2Y0ra7BEHicTsIRh7iJWA-lZnvqTemFUuMCwFAGKjj4ekutrTRkMF4CvSPHVcnY3L2k_UvYCP_RZAjOsu0uH5WSwjqWnWZr53r2F8Xc2iuXXEN0GVkW15lJJjjFfNQmjmODh74UomD_6eGZFwYoLaXL-PbZhcWce71nFwxWLiIs4RAd0vLjhc3Pw8INz86N7Tar8CqYgICjiRXJ62Bzsr6PDRvH60RMJGy0_IngKzJmoFimsHVlU1a1-Abes4HxftthJJSzzH8GdlfBKCqmSPOQjdUP3xn4_8b8CLXlNEYjN1kTTOJN4hKY3K4KY-OvzVa3SIBaZYRNHI6vCUA2GNm7-WJgH-6NkTq3wJApBUgNQOmAsENKu27gpve_LRmqbvRqjzGMTnpYnANAFp0xyqS1eMa233bOzVtecunKic-extPfBPx0SyCk94bOrG2sPc1HQAOQHl6bmBHw64Bof_J6YsgO5fuqQDj8npriZmnLZmdz8TuPUpm4vHjwQ76GjFCckmGDtlCGiS0D3ebIpKkZ4lmlbesXONqqkK_T8pJQB0IZ0JIwqQ" style="width: 70%;">
                        <p class="caption">OFA text-to-image generation 결과, 출처: OFA 논문</p>
                    </div>




                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>OFA 의의</span><br>
                        <span>Significance of OFA</span>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        OFA의 의의는 아래와 같이 정리해볼 수 있을 것 같습니다.
                        <ul>
                            <li>간단하고 적은 크기의 모델로 다양한 downstream task에서 SOTA를 달성.</li>
                            <li>20M의 비교적 적은 image-text pair를 이용하여 여러 multi-modal task에서 SOTA를 달성.</li>
                            <li>Task, modality-agnostic한 모델을 제작 &rarr; Language, vision-only, vision &amp; language task를 하나로 통합.</li>
                            <li>Uni-modal의 특정 task-specific한 모델(e.g. RoBERTa, ELECTRA)보다 modal을 unify하여 학습을 수행한 결과 comparable한 성능을 보여줌.</li>
                            <li>Language token, visual token(VQGAN의 이미지 codebook 사용), location token을 하나의 vocab으로 구성하여 multi-modal 데이터를 통일된 공간에서 표현하여 학습.</li>
                        </ul>
                    </p>
                    


                    
                    <p>
                        <br><br><br>OFA는 간단한 구조와 비교적 작은 파라미터 수를 가진 모델을 이용하여 multi-modal 뿐 아니라 uni-modal에서도 뛰어난 성능을 보여준 모델입니다.
                        다음에는 다른 LMM 모델을 리뷰해보겠습니다.
                    </p>


                    
                </div> 
                <div class="tag">
                    <b>태그</b>&emsp;#OFA
                </div>
                <div class="pageTurner">
                    <div class="pageTurnerLeft">
                        <span><a style="position: absolute; left: 0;" onclick="alert('OFA 첫 게시물 입니다.\n\nThis is the first post of OFA.');" onmouseover="colorOn(this);" onmouseout="colorOff(this);">&lang; 이전글</a>
                        <br></span>
                    </div>
                    <div class="pageTurnerRight">
                        <span><a style="position: absolute; right: 0;" onclick="alert('OFA 마지막 게시물 입니다.\n\nThis is the last post of OFA.');" onmouseover="colorOn(this);" onmouseout="colorOff(this);">다음글 &rang;</a>
                        <br></span>
                    </div>
                </div>
                <span id="readNum"></span>
                <div id="disqus_thread"></div>

                <script>
                    headHighlightColorChanger();
                    (function() { // DON'T EDIT BELOW THIS LINE
                    var d = document, s = d.createElement('script');
                    s.src = 'https://novicetraveler.disqus.com/embed.js';
                    s.setAttribute('data-timestamp', +new Date());
                    (d.head || d.body).appendChild(s);
                    })(); 
                </script>
                <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </article>
        </div>

        <div id="menuRelated">
            <div class="menuButton">
                <img id="menuImg" src="init/index_img/menu_black.png" onclick="openMenu(this);">
            </div>
            <div class="menu">
                <img id="menuExtension" title="메뉴를 확장합니다." src="init/index_img/extension_black.png" onclick="extendMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
            <div class="bigMenu">
                <img id="menuCompression" title="메뉴를 축소합니다." src="init/index_img/compression_black.png" onclick="compressMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
        </div>

        <script>
            detectScroll();
            pushFunc();
            detectSize();
        </script>
    </body>
</html>