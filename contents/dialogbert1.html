<!DOCTYPE html>
<html>
    <head>
        <title>DialogBERT</title>
        <meta name="description" content="Multi-turn 대화를 위한 모델 DialogBERT를 소개합니다.">
        <meta charset="utf-8">
        <link rel="stylesheet" href="init/index.css">
        <link rel="stylesheet" href="init/contents.css">
        <link rel="stylesheet" href="init/index_img/icons/css/fontello.css">

        <link rel="preconnect" href="https://fonts.googleapis.com"> 
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> 
        <link href="https://fonts.googleapis.com/css2?family=Dongle:wght@300&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Gowun+Batang&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic&display=swap" rel="stylesheet">

        <link rel="stylesheet"
            href="init/highlight/styles/github-dark.min.css">
        <script src="init/highlight/highlight.min.js"></script>
        <script>hljs.highlightAll();</script>
        <script src="init/highlight/highlights_line.js"></script>
        <script>initNumber(window, document);</script>
        <script>hljs.initLineNumbersOnLoad();</script>

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        <script src="init/index.js"></script>
        <script src="init/jquery.pjax.js"></script>
        
        <meta name="viewport" content="width=device-width, initial-scale=0.8, max-width=1">

        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-219110982-1"></script>
        <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-219110982-1');
        </script>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7745178886614102"
        crossorigin="anonymous"></script>

        <meta property="og:url" content="https://ljm565.github.io/contents/dialogbert1.html" />
        <meta property="og:title" content="DialogBERT" />
        <meta property="og:type" content="website">
        <meta property="og:description" content="Multi-turn 대화를 위한 모델 DialogBERT를 소개합니다." />
        <meta property="og:image" content="https://lh3.googleusercontent.com/fife/ALs6j_GpNXAP2lAuOJcPllQz4-jvLx47qVR8ojqOcWsKYCTqI2PKUbmNbCs9I47NZTE4D7R2YZ_z-ni9R8nmG3zuoqcxlL5mmonyaSZeJDePcVWk_DUAiRuy5YhVIrnUJs8AX72DJSXpYxiCD_zbgxI8Ir1QhgBRCElzHyy-JrcWxANvS_aQRLR6hFXYZ6DDUXwgGmo0lWHck6kEMVC66L3wubXgN7fgDYrFSFh-u_kppDBpdRmzPb6FLY8_uL_8zgg7BsCwochCUXxPtONXwCQJ2BMvCd02-6t6qXX-sLb88FlBThXWESY0ENh7P15hfOLGBQIRyUH_2AMTOR2Kpw9-K2xbHkKTMeGicXDBf-Y5G0tQZFjrdgN7aLNR5MEu_PtT5OIVjEiH2mqpoiwlQO5tOXRE3wCaDnj62g8lViZwVEy-hzoetP81D8yoGDJZAkInXo5p3xROvbjRUulY381cLPeFbGtdTmoXT6SVYl5JamQeMKBqVhuzAh-HlAZSodtuj8Yg-MJ1rn0sIJBhsjJi4rlaQFWSpGdtUqaZ8grPkC2GhLRXU679ctbPpuC5wvhAgJUO2-99VPRNwGn3w48lJm_merOE5MzmL2kxneMZMlYSVZpOVVBK9_LKCR7F5saF5w3VONnUt8jUrkHfrPQNFpDRQJkRzHf2LmYnXY-1O_byQdPk8KTYOEEVBD5G99d6CQr7h6KGkkIsrxZnwc320TQ52sOxiVflj8Kl4c3E7eUlfYjTWrAkyOd7DUaXzVjk9a39KCRw2lS9Xutddi9mD3h5TQfjcYA4l1-EfAjJ8g8KGiPIyM8FCxO521ur01QwwgVQf6O60WE0EGqHNbwdBgYnKFtCUNlEltdwfPhmErDlMfaYX4LYLYikyu-xto2MXwRvP8iiPMEwLj-9-Rl6byjP0pOJota0MtHN85BPJTRjFndU8VdT5dzsP2AXQGfzzz32NWDlW0ueVVMiYe7H7AeBduMprLeBahFGRKeeWD-eMaSY5CRzOgDZIhWv1m_WMHvCTP231CmUeKigaxFSzdN9DVPuhasPnuG_ZcDgLHZ8dwbdz3yKJsPLi17u0v1OY2G9F_6Zny1EpewuxcJLJqwQtCGqjQ5pKLJhFqME6JKzRYHwOht-1pd528xxc18Z24ck6ofdLH7RmhPCbi-EfMZWkxbaSgeOrirpz7ehe0CvhJzaqKsCZN2WJU3gzCl2H8Vm2DZYm5Vh9ggcBtO0B18ZxWhMr8fpbGOVMIuGAXdrnWseF5o6XF7lZVleCguOZ8YplyEURtNsim1YMarGssSQtGgMomFiBqtihcDl0cImIJJxmyLcKslYWq28pYe3MBr_-4DrX-0HxoGi3i9Kapeaj7YFfxxcXeWexpsYoIoo9NJa6j63OJ89qcYEpahXSyAWoSiW3oTeBgK_3ynxOmhzE35TsgnkiuAV9Z_ZDYDiMdaI1rfQ_CfNzqttmb9MQqWkDZLEVOtuktQ0pA9PS1_IEhzkkDIwsodO8Tb0Gvy5AZGNDSL2tcaxWzl1DlIGasaxKDY5jw" />
    </head>   
    <body>
        <div id="modeButton">
            <button type="button" value="dark" onclick="darkMode(this)" onmouseover="hoveringOn(this)" onmouseout="hoveringOff(this)">
                <div class="modeImg"><img id="modeImg" src="init/index_img/moon_off.png"></div>
                <div id="modeState">다크 모드로 보기</div>
            </button>
        </div>

        <div id="container" onclick="reload();">
            <article>
                <script src="init/highlight/highlight.min.js"></script>
                <script>hljs.highlightAll();</script>
                <script src="init/highlight/highlights_line.js"></script>
                <script>initNumber(window, document);</script>
                <script>hljs.initLineNumbersOnLoad();</script>
                <script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
                <script>
                    initMathJax();
                </script>
                <div id="mainHeadWrapper">
                    <div id="mainHead">
                        <h1 class="contentHead">딥러닝 이야기 / DialogBERT / 1. DialogBERT</h1>
                    </div>
                </div>
                
                <div class="title" style="background-image:url(https://lh3.googleusercontent.com/fife/ALs6j_GpNXAP2lAuOJcPllQz4-jvLx47qVR8ojqOcWsKYCTqI2PKUbmNbCs9I47NZTE4D7R2YZ_z-ni9R8nmG3zuoqcxlL5mmonyaSZeJDePcVWk_DUAiRuy5YhVIrnUJs8AX72DJSXpYxiCD_zbgxI8Ir1QhgBRCElzHyy-JrcWxANvS_aQRLR6hFXYZ6DDUXwgGmo0lWHck6kEMVC66L3wubXgN7fgDYrFSFh-u_kppDBpdRmzPb6FLY8_uL_8zgg7BsCwochCUXxPtONXwCQJ2BMvCd02-6t6qXX-sLb88FlBThXWESY0ENh7P15hfOLGBQIRyUH_2AMTOR2Kpw9-K2xbHkKTMeGicXDBf-Y5G0tQZFjrdgN7aLNR5MEu_PtT5OIVjEiH2mqpoiwlQO5tOXRE3wCaDnj62g8lViZwVEy-hzoetP81D8yoGDJZAkInXo5p3xROvbjRUulY381cLPeFbGtdTmoXT6SVYl5JamQeMKBqVhuzAh-HlAZSodtuj8Yg-MJ1rn0sIJBhsjJi4rlaQFWSpGdtUqaZ8grPkC2GhLRXU679ctbPpuC5wvhAgJUO2-99VPRNwGn3w48lJm_merOE5MzmL2kxneMZMlYSVZpOVVBK9_LKCR7F5saF5w3VONnUt8jUrkHfrPQNFpDRQJkRzHf2LmYnXY-1O_byQdPk8KTYOEEVBD5G99d6CQr7h6KGkkIsrxZnwc320TQ52sOxiVflj8Kl4c3E7eUlfYjTWrAkyOd7DUaXzVjk9a39KCRw2lS9Xutddi9mD3h5TQfjcYA4l1-EfAjJ8g8KGiPIyM8FCxO521ur01QwwgVQf6O60WE0EGqHNbwdBgYnKFtCUNlEltdwfPhmErDlMfaYX4LYLYikyu-xto2MXwRvP8iiPMEwLj-9-Rl6byjP0pOJota0MtHN85BPJTRjFndU8VdT5dzsP2AXQGfzzz32NWDlW0ueVVMiYe7H7AeBduMprLeBahFGRKeeWD-eMaSY5CRzOgDZIhWv1m_WMHvCTP231CmUeKigaxFSzdN9DVPuhasPnuG_ZcDgLHZ8dwbdz3yKJsPLi17u0v1OY2G9F_6Zny1EpewuxcJLJqwQtCGqjQ5pKLJhFqME6JKzRYHwOht-1pd528xxc18Z24ck6ofdLH7RmhPCbi-EfMZWkxbaSgeOrirpz7ehe0CvhJzaqKsCZN2WJU3gzCl2H8Vm2DZYm5Vh9ggcBtO0B18ZxWhMr8fpbGOVMIuGAXdrnWseF5o6XF7lZVleCguOZ8YplyEURtNsim1YMarGssSQtGgMomFiBqtihcDl0cImIJJxmyLcKslYWq28pYe3MBr_-4DrX-0HxoGi3i9Kapeaj7YFfxxcXeWexpsYoIoo9NJa6j63OJ89qcYEpahXSyAWoSiW3oTeBgK_3ynxOmhzE35TsgnkiuAV9Z_ZDYDiMdaI1rfQ_CfNzqttmb9MQqWkDZLEVOtuktQ0pA9PS1_IEhzkkDIwsodO8Tb0Gvy5AZGNDSL2tcaxWzl1DlIGasaxKDY5jw);">
                    <div>
                        <span class="mainTitle">DialogBERT</span>
                        <br><br>
                        <div style="display: table-cell; margin: 0;">
                            <img src="init/index_img/profile.png" style="width: 30px; cursor: pointer;" onclick="pjaxPage('/');">
                        </div>
                        <span class="subTitle" style="display: table-cell; text-align: left; vertical-align: middle; padding-left: 20px; line-height: 125%;">작성자: 여행 초짜<br>작성일: 2023.01.16</span>
                    </div>
                </div>

                <div id="content">
                    <p>
                        시작하기 앞서 틀린 부분이 있을 수 있으니, 틀린 부분이 있다면 지적해주시면 감사하겠습니다.
                        
                        <br><br>이번에 소개할 논문은 multi-turn 대화형 챗봇 구현을 위해 여러 모델을 리서치 해보다가 발견했던 DialogBERT 입니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">저자의 원본 코드는 논문을 위한 실험을 해야했기 때문에 불필요한 코드가 많아 다시 제 코드로 고쳐서 구현을 했을 때 reporduce 되지 않았습니다.
                        그래서 잘못 구현했나 싶어 저자의 코드를 clone하여 돌렸을 때도 논문의 결과가 reproduce 되지 않았습니다.
                        그래서 저자의 코드 issue 부분에 들어가보니, 저와 비슷하게 reproduce가 안된다는 이슈가 많이 있었습니다.</span>
                        왜 reproduce가 안되며, 저자는 어떻게 논문을 쓸 수 있었는지에 대한 더 자세한 고찰은 <a onclick="pjaxPage('dialogbert2.html');"><span class="highlight" style="color: rgb(0, 3, 206);">다음글</span></a>에서 다루어보도록 하겠습니다.

                        <br><br>비록 reproduce가 안되기는 하지만, 아이디어 자체는 좋아보여 소개하려합니다.
                        그리고 논문에는 나와있지 않은 디테일한 부분은 코드를 구현하면서 확인하였기 때문에 이러한 부분도 이야기를 해보겠습니다.

                        <br><br>아래는 DialogBERT 논문 링크입니다.
                    </p>
                    <div class="link">
                        <a href="https://arxiv.org/pdf/2012.01775.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);">DialogBERT 논문</a>
                    </div>
                    <p>
                        <br><br>오늘의 컨텐츠입니다.
                        <ol>
                            <li>Auxiliary Tasks</li>
                            <ul>
                                <li>Next Utterance Generation (NUG)</li>
                                <li>Masked Utterance Regression (MUR)</li>
                                <li>Distributed Utterance Order Ranking (DUOR)</li>
                            </ul>    
                            <li>NUG, MUR, DUOR 동시 학습 방법</li>                                      
                        </ol>
                    </p>



                    <h1 class="subHead">DialogBERT</h1>
                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center;">&ldquo;</span>
                        <span>Auxiliary Tasks</span><br>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        <span style="font-size: 20px;"><b>1. Next Utterance Generation (NUG)</b></span>
                        <br>먼저 DialogBERT는 multi-turn 학습을 위해 모델에게 3가지 auxiliary task (보조 task)를 수행하게 합니다.
                        그중 하나가 바로 NUG인데, 이는 여느 language modeling과 동일합니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">바로 source를 바탕으로 target 문장을 생성하게 하는 것입니다.</span>
                        그리고 아래 그림에서 생략되었지만 각 문장 끝에 [CLS], [SEP] 토큰이 들어가며, 각 문장의 max length를 맞추기 위해 남은 부분은 [PAD]토큰을 추가해줍니다.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_Gkh0V1Ko1zDHqgrOg2IYYYdErsM7_WQgdLU8jnMhpVEfkDHEJP357xpBhprRzJQ9X7X3aaht5hNWdwqChlIxyrr_ZlLlWmPDobWrDhZO4LdWIFAXGvVYx5-k3O1VnZuQvoQQwKpyF-LMthcZrS9ij0NES8-dXh_rv-ucKKrquz4ImVvNq7TqS7W44nIg0tfHJBi_tveOJ0dAMh2GqKQa_-MYpsdyrVj5l-UDkrd5qGD0M45SPmSWasGUhXQ-0bxHvvQ47eLDE-zgRReTE2mwXdUhJBJFbkEptyFZjp69xbo-YK8ffZM7fHBoeW9FHdscabd6C8scdNil14C6tmn6BxBTMA4gpfluxd6-0EfdFKi8uW9riGkJUPsUO624rRGknA5VSRs-T9frgLzhKP9FenHW-j7WhPqW7-uBqGiLMed9EBBVwKfyWaSy6_WrX9ADwGlb-V_vlbhgOrLY0QVsy2RjnZi9caGChBWaPEmVUM0lNeUKVxOTloAiRjK9KlQe9ZVcg2_FoHKMryhqS18IBNj8ttk-KNQMF_uCN7Ajnmn2kCl_1m0yXP3YVl1igGQwacz8xzKug7pwY9TzWhSe7ilqVqv6g1wRv68z_F9d1FJST8G4AMavR9GgeSYRqtuT6hWTBooW-6-RFN_puqeWyo69ueiaDCLDmlILvHHOWAm_aGUq13uR5e6PmP_-LpncOLSCHjPC8b-MA-U8zsh_vl2PAPnIRJid9SQ-5nsZYIEysZURc4Je89Oi_C1oPPiK1nnbNgNdtGtJyoLe6uaDFFLuAL6Ts6wWateH646GXwt2kKysG6dW-ImVNjHM2NGm70W9eAc5psLphtSr7T24kAn6ajfMFlQlVGlJbMTBJDdlLNKGglIZcEDo0FK0Iz3hO38BKGUPujSm-z4BG4OuTjmHWznWXoRx65We5PEfmN22O0Nthq3a1kNS2envtjGNy3VhdTZAeVyGQV9M6PwTO5g9CxXfkiPwXMvvPHOwzQ1GWi9EMDqmRcAFZdz1Yrggf3OeX3Oxbld9nVS53Oh6az2H9r1FNP55qE5mThGNawh9DIxbXSsbsLuMk2EYzkANNPv2hcRKFSYN_sFZ3rPrQtEPInGp5eD20-s5gFLwp3kyEorgDTB3BcKJ2gwMD5aO8fwmc3_R9ALUQCdWQKf3P6kJCukX9ukc_i9l-tZhBt_3iqIpGvhCGJETBU5SMY3bKYEA-An-EEQzSex6BKUdcaDi_Lf8bArwr-_YIkPb12aGSrkd1tsDgjAF6Q_e4_3doKhANY3kdX3CEALpiVgVS9T5oomlgtmzEoXCxqHYSriupUnbKKiBW_EbKTboqkuEHvtta1Yrt89qBHm_XC4QBhjtOcd3h_n9vucAXWEgefVG38dexWTrCspO5ucd5kaCGtEMR1i_e0zwEEFt7Z6JogNBHctyhqTF3cdEZC3Ll_PnohiTND_mKBNfmJLu_mZRCaPEVS9FlLnFR6Jq6FKBpBSXuniwSortIeI9VCpU1DnPfk2gwy-ZNMOn6Zhj9oPI3tEqZ2petD" style="width: 80%;">
                        <p class="caption">Next Utterance Generation (NUG), 출처: DialogBERT 논문</p>
                    </div>
                    <p>
                        <br>대신 DialogBERT는 모델의 target 문장을 생성하기위해 앞의 multi-turn 문장을 representation 하기 위해 BERT를 사용합니다(BERT 설명은 <a onclick="pjaxPage('bert1.html');"><span class="highlight" style="color: rgb(0, 3, 206);">이전글</span></a> 참고).
                        각각의 multi-turn 문장을 BERT에 넣은 후, [CLS] 토큰들을 모아 다음 BERT에 넣습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">이때 multi-turn 문장을 input으로 받는 BERT는 utternacne encoder, utterence encoder의 [CLS] 결과를 input으로 받는 BERT는 context encoder라고 부릅니다.</span>

                        <br><br>그리고 마지막 context encoder로 나온 결과, <span class="highlight" style="color: rgb(0, 3, 206);">즉 multi-turn의 의미를 함축하고 있는 결과는 transformer decoder처럼 encoder output feature로 사용됩니다.</span>
                        그리고 target 문장과 함께 decoder로 들어가서 encoder-decoder attention을 수행하면서 target 문장을 학습하는 것입니다.
                        
                        <br><br><br><br><span style="font-size: 20px;"><b>2. Masked Utterance Regression (MUR)</b></span>
                        <br>두 번째 task는 바로 MUR이라고 하는 task입니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">이는 BERT의 MLM과 비슷하지만, 토큰을 masking하는 것이 아니라 multi-turn 문장 중 하나를 masking하여 예측하게 합니다.</span>
                        이때 MUR을 적용하는 조건이 3개 문장 이상의 multi-turn일 경우만 하는 등의 논문에 나와있지 않은 여러 조건이 있긴 하지만, 이러한 상세한 부분은 <a onclick="pjaxPage('dialogbert2.html');"><span class="highlight" style="color: rgb(0, 3, 206);">다음글</span></a>에서 코드와 같이 보도록 하겠습니다.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_FHp6QhaeqF3g3wNB0bvJ8f3BbMsCJHJ1fAN5YAO9uF_uH2efMX5Hh84Uh0zJ1WVh9OJxHVXKh6J-05iVznhDlREvygEgS-rjMipn4L8w9YM-ajC5w86zMv1jvMqZtcJfo5DpJI1gN49GOIB9_8ph715KdcTjkp4BxFQaOfs6l9ACOiHEessUSvR_hJOYn9dBFpKKzgK8AvQQBWG8YRv0lfvVdZFhLQSQa7EZWwJqgYIlQSFJJXGIahb_BnAciQ0K19xBLG7XZXUOQcqLPUIE8znsjACjS1I9y7m_0b2i6EyU1A8x0xrH9a8_uIHRRDu1bXYLWyMblq7zd6ALTRPjTuSCLnnOm8kF__y67UGMZwpHKwpM2EZTH2lNWxpjYR37Oa6ctjrRY-vbGEDPThKQ4hgtsu733dfX5Y9mCFWRq_saPUgK7Fl_26TdKr3dECx_j8LWPXuxGit2YUf3ri6SN2Fn7qDNF_Z6LLy1KiP-8iWTRc_57vk2ushuH9aO967Rmxg45RhyLIkWx_EOamHIkjUkYeRYcosMHsRzWzwoCoojPYNd_FyYjO6wrsJY6y-DeX7R8L4WMmZw4E8RNdF8i978QSDuvbYs8PeFM7xpNlWWibKVEBFceDD1igRVIG7OWRlfazGMz6QGgPBDfwVOhRlMfzucPTN_Lfd2CU9QsmGkV7MIU_fzoQluqWzMbkSDzHngkGbUrrXf2-WJ8y42Ipmv0gkma6TmYSoB2U0BYYocI6LJk8rKd9R-306Ig55xWfcO5eABWybDqvgm6vWad8oPgr-x-IkYrggUJetGCrNKIVSECopuEu00M0K0xpkJLS9CcT4xdTcXhKGsSvXOeNUpiapVPlglx_pHmG9nk8ISBfOPnaGQ4PucqZ9o-8-nA1LBgNDm5gQ501pO5q6-G3NsyH_ZyZu5UQeQZRS8aXt9Y8vrk90uirmoyGGMKro5v8A03RIhhp6NDgAJodHwAzmXw4JN-6eBk6DjyUPxq1jIa1bByH4GqC_dD1jCd9TIYClSmWuLEqrMzai7BRzwiU-MCr_As_Y5G5Ou59WA3tLgpqihFpcdC22zLc7a4DTRsURyMS8AxMV1CS-UoupKOoFhbhAv6EIquUCSbyHp0-PpEmJT0xPM157VbylrTJOmuSaS_Lh6cEYF4REdprrA49TRI69sxp-vDgLpRtKwSPUhuNLtCHsWLnH9zCkCDXm3p4GPKY74bhwB0ewSaQmnDdqR9pgjXCvii6-7Sco0yL5rrfIFs7Szi9D4iXrkG7qylYVFgGumn7mJnqXdsy2TjqkeUv1WCxrdAku110MxFOisEHBT4I4NTwfZ1stA93U3ULTKjgrSQvmE6kAHJZm-4WZShK3gwRKG0CjWUvhXAYTNgEI9P7bn0g3dSW49gR2UTd32h610XFb8504LaLlpIYqqxS1XEyCeJtA1d3ekCawJ_UlPHZDzNhGWpZq7BAv1-S53cdfFXNFY4UWMbiOQvJfyLqNK9wpk9GKm1Rn8VEKczQAAhz021CMDry_Fll527gc_4Z_uFd" style="width: 80%;">
                        <p class="caption">Masked Utterance Regression (MUR), 출처: DialogBERT</p>
                    </div>
                    <p>
                        <br>그렇다면 MUR을 하는 방법에 대해 알아보겠습니다.
                        <ol>
                            <li>Multi-turn 문장 중 하나를 80% 확률로 [MASK] 토큰으로 마스킹.</li>
                            <li>Multi-turn 문장 중 하나를 10% 확률로 다른 문장으로 대체.</li>
                            <li>Multi-turn 문장 중 하나를 10% 확률로 그대로 유지.</li>
                        </ol>
                        위와 같은 조건을 하나의 문장에 적용하고, 적용한 문장에 대해 loss를 구합니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">위의 조건이 적용된 문장의 context encoder BERT 모델에서 나온 hidden state를 linear layer (Encoding Converter)를 하나 더 거쳐 나온 결과와, 원래의 문장을 utterance encoder BERT 모델에 넣어 나온 결과와 MSE loss를 구합니다.</span>
                        이렇게 나온 loss를 줄이는 것이 바로 MUR입니다.
                        
                        <br><br><br><br><span style="font-size: 20px;"><b>3. Distributed Utterance Order Ranking (DUOR)</b></span>
                        <br>마지막은 DUOR입니다.
                        DUOR은 아래 그림처럼 multi-turn 문장을 섞은 후, 각각의 섞인 순서를 예측하는 방법입니다.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_GpNXAP2lAuOJcPllQz4-jvLx47qVR8ojqOcWsKYCTqI2PKUbmNbCs9I47NZTE4D7R2YZ_z-ni9R8nmG3zuoqcxlL5mmonyaSZeJDePcVWk_DUAiRuy5YhVIrnUJs8AX72DJSXpYxiCD_zbgxI8Ir1QhgBRCElzHyy-JrcWxANvS_aQRLR6hFXYZ6DDUXwgGmo0lWHck6kEMVC66L3wubXgN7fgDYrFSFh-u_kppDBpdRmzPb6FLY8_uL_8zgg7BsCwochCUXxPtONXwCQJ2BMvCd02-6t6qXX-sLb88FlBThXWESY0ENh7P15hfOLGBQIRyUH_2AMTOR2Kpw9-K2xbHkKTMeGicXDBf-Y5G0tQZFjrdgN7aLNR5MEu_PtT5OIVjEiH2mqpoiwlQO5tOXRE3wCaDnj62g8lViZwVEy-hzoetP81D8yoGDJZAkInXo5p3xROvbjRUulY381cLPeFbGtdTmoXT6SVYl5JamQeMKBqVhuzAh-HlAZSodtuj8Yg-MJ1rn0sIJBhsjJi4rlaQFWSpGdtUqaZ8grPkC2GhLRXU679ctbPpuC5wvhAgJUO2-99VPRNwGn3w48lJm_merOE5MzmL2kxneMZMlYSVZpOVVBK9_LKCR7F5saF5w3VONnUt8jUrkHfrPQNFpDRQJkRzHf2LmYnXY-1O_byQdPk8KTYOEEVBD5G99d6CQr7h6KGkkIsrxZnwc320TQ52sOxiVflj8Kl4c3E7eUlfYjTWrAkyOd7DUaXzVjk9a39KCRw2lS9Xutddi9mD3h5TQfjcYA4l1-EfAjJ8g8KGiPIyM8FCxO521ur01QwwgVQf6O60WE0EGqHNbwdBgYnKFtCUNlEltdwfPhmErDlMfaYX4LYLYikyu-xto2MXwRvP8iiPMEwLj-9-Rl6byjP0pOJota0MtHN85BPJTRjFndU8VdT5dzsP2AXQGfzzz32NWDlW0ueVVMiYe7H7AeBduMprLeBahFGRKeeWD-eMaSY5CRzOgDZIhWv1m_WMHvCTP231CmUeKigaxFSzdN9DVPuhasPnuG_ZcDgLHZ8dwbdz3yKJsPLi17u0v1OY2G9F_6Zny1EpewuxcJLJqwQtCGqjQ5pKLJhFqME6JKzRYHwOht-1pd528xxc18Z24ck6ofdLH7RmhPCbi-EfMZWkxbaSgeOrirpz7ehe0CvhJzaqKsCZN2WJU3gzCl2H8Vm2DZYm5Vh9ggcBtO0B18ZxWhMr8fpbGOVMIuGAXdrnWseF5o6XF7lZVleCguOZ8YplyEURtNsim1YMarGssSQtGgMomFiBqtihcDl0cImIJJxmyLcKslYWq28pYe3MBr_-4DrX-0HxoGi3i9Kapeaj7YFfxxcXeWexpsYoIoo9NJa6j63OJ89qcYEpahXSyAWoSiW3oTeBgK_3ynxOmhzE35TsgnkiuAV9Z_ZDYDiMdaI1rfQ_CfNzqttmb9MQqWkDZLEVOtuktQ0pA9PS1_IEhzkkDIwsodO8Tb0Gvy5AZGNDSL2tcaxWzl1DlIGasaxKDY5jw" style="width: 80%;">
                        <p class="caption">Distributed Utterance Order Ranking (DUOR), 출처: DialogBERT</p>
                    </div>
                    <p>
                        <br>예를 들어 섞인 문장의 순서가 [0, 1, 2, 3, 4, 5, 6] &rarr; [0, 3, 4, 1, 5, 2, 6]으로 바뀌었다고 가정해보겠습니다(코드상 저자는 양끝 순서는 바꾸지 않습니다).
                        <span class="highlight" style="color: rgb(0, 3, 206);">저자는 [0, 3, 4, 1, 5, 2, 6] &rarr; [6, 3, 2, 5, 1, 4, 0]으로 이렇게 바뀐 순서를 빠른 문장일수록 큰 수를 가지도록 다시 변환해줍니다.
                        그 후 context 길이 중 가장 큰 수로 나눠준 후, softmax를 씌운 결과인 \(softmax([6, 3, 2, 5, 1, 4, 0]/6)\)를 ground truth로 사용합니다.</span>
                    </p>
                    <div class="equation">
                        \[GT\,=\,softmax([o_{n}, o_{3}, o_{n-1}, ... ,o_{0}]\,/\,n)\]
                    </div>
                    <p> 
                        <br><span class="highlight" style="color: rgb(0, 3, 206);">그리고 context encoder BERT 모델에서 나온 hidden state를 order ranking network라고 하는 linear layer를 거쳐서 나온 결과를 \(A\)라고 했을 때 \(score=A*A'\), 즉 내적을 통해 구합니다.
                        그렇다면 \(score\)의 크기는 (batch * context_len * context_len)이 될 것입니다.
                        그리고 최종적으로 score를 평균 내어 (batch * context_len)의 크기를 가진 결과를 softmax를 씌워 예측값으로 사용합니다.</span>
                    </p>
                    <div class="equation">
                        \[Pred\,=\,softmax(mean(A\,*\,A'))\]
                    </div>
                    <p>
                        <br>그리고 DUOR은 위에서 구한 GT와 Pred 확률 차이를 Kullback-Leibler divergence loss를 이용해 줄이는 task입니다.
                    </p>
                   
                    



                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>NUG, MUR, DUOR 동시 학습 방법</span><br>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p> 
                        <br>위에서 소개한 3가지의 task를 어떻게 수행하는지 실제 코드를 짜보는 입장에서는 많이 궁금했습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">어떠한 경우에 MUR을 하는지, DUOR을 할 데이터의 비율은 어떻게 되는지, 아니면 MUR, DUOR을 동시에 수행하는지 등 디테일한 부분이 궁금해서 코드를 보고 어떻게 위 task들을 수행하였는지 알려드리겠습니다.</span>
                        
                        <br><br>먼저 데이터를 구성할 때 아래와 같은 조건으로 구성합니다.
                        <br><br><b>전제 조건</b>: "[CLS] [CLS] [SEP]", s1, s2, ..., sn, "[CLS] [SEP] [SEP]" 형식으로 multi-turn 문장들 양 끝에 [CLS], [SEP] 토큰으로 구성된 special 문장을 추가합니다.
                        <ol>
                            <li>Multi-turn이 1개 이상이라면, 즉 single turn이어도 special 문장들을 제외하고 40%의 확률로 순서를 섞습니다(즉 양끝 special 문장은 제외).</li>
                            <li>만약 문장이 섞이지 않았고 multi-turn이 3개 이상이라면, special 문장을 제외하고 하나의 문장을 마스킹 합니다.</li>
                            <ul>
                                <li>80% 확률로 하나의 문장을 "[CLS] [MASK] [SEP]"로 대체합니다.</li>
                                <li>10% 확률로 하나의 문장을 다른 랜덤 문장으로 대체합니다.</li>
                                <li>10% 확률로 하나의 문장을 그대로 유지합니다.</li>
                            </ul>
                            <li>위 2가지 모두 거치지 않았을 때, 단순히 multi-turn 데이터로 내보냅니다.</li>
                            <li>위에서 마스킹 과정을 거친 데이터만 MUR을 수행합니다.</li>
                            <li>위에서 순서가 셔플 된 데이터만 DUOR을 수행합니다.</li>
                            <li>위에서 순서가 셔플되지 않은 데이터만 NUG 수행합니다(셔플, 마스킹 과정을 거치지 않은 데이터 포함).</li>
                        </ol>
                        위와 같은 방법으로 모델을 학습하게 됩니다.
                        더 디테일한 부분은 다음글에서 코드와 함께 살펴보겠습니다.
                    </p>


                    
                    <p>
                        <br><br><br>다음에는 DialogBERT 상세 구현 및 왜 재현이 안되는지 개인적인 견해와 함께 살펴보도록 하겠습니다.
                    </p>


                    
                </div> 
                <div class="tag">
                    <b>태그</b>&emsp;#DialogBERT&emsp;#MUR&emsp;#DUOR&emsp;#NUG
                </div>
                <div class="pageTurner">
                    <div class="pageTurnerLeft">
                        <span><a style="position: absolute; left: 0;" onclick="alert('DialogBERT 첫 게시물 입니다.\n\nThis is the first post of DialogBERT.');" onmouseover="colorOn(this);" onmouseout="colorOff(this);">&lang; 이전글</a>
                        <br></span>
                    </div>
                    <div class="pageTurnerRight">
                        <span><a style="position: absolute; right: 0;" onclick="pjaxPage('dialogbert2.html');" onmouseover="colorOn(this);" onmouseout="colorOff(this);">다음글 &rang;</a>
                        <br>DailyDialog를 이용한 DialogBERT 구현</span>
                    </div>
                </div>
                <span id="readNum"></span>
                <div id="disqus_thread"></div>

                <script>
                    headHighlightColorChanger();
                    (function() { // DON'T EDIT BELOW THIS LINE
                    var d = document, s = d.createElement('script');
                    s.src = 'https://novicetraveler.disqus.com/embed.js';
                    s.setAttribute('data-timestamp', +new Date());
                    (d.head || d.body).appendChild(s);
                    })(); 
                </script>
                <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </article>
        </div>

        <div id="menuRelated">
            <div class="menuButton">
                <img id="menuImg" src="init/index_img/menu_black.png" onclick="openMenu(this);">
            </div>
            <div class="menu">
                <img id="menuExtension" title="메뉴를 확장합니다." src="init/index_img/extension_black.png" onclick="extendMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
            <div class="bigMenu">
                <img id="menuCompression" title="메뉴를 축소합니다." src="init/index_img/compression_black.png" onclick="compressMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
        </div>

        <script>
            detectScroll();
            pushFunc();
            detectSize();
        </script>
    </body>
</html>