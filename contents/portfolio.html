<!DOCTYPE html>
<html>
    <head>
        <title>Portfolio</title>
        <meta name="description" content="포트폴리오">
        <meta charset="utf-8">
        <link rel="stylesheet" href="init/index.css">
        <link rel="stylesheet" href="init/contents.css">
        <link rel="stylesheet" href="init/index_img/icons/css/fontello.css">

        <link rel="preconnect" href="https://fonts.googleapis.com"> 
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> 
        <link href="https://fonts.googleapis.com/css2?family=Dongle:wght@300&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Gowun+Batang&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic&display=swap" rel="stylesheet">

        <link rel="stylesheet"
            href="init/highlight/styles/github-dark.min.css">
        <script src="init/highlight/highlight.min.js"></script>
        <script>hljs.highlightAll();</script>
        <script src="init/highlight/highlights_line.js"></script>
        <script>initNumber(window, document);</script>
        <script>hljs.initLineNumbersOnLoad();</script>

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        <script src="init/index.js"></script>
        <script src="init/jquery.pjax.js"></script>

        <meta name="viewport" content="width=device-width, initial-scale=0.8, max-width=1">

        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-219110982-1"></script>
        <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-219110982-1');
        </script>
        <!-- <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7745178886614102"
        crossorigin="anonymous"></script> -->

        <meta property="og:url" content="https://ljm565.github.io/contents/portfolio.html" />
        <meta property="og:title" content="Portfolio" />
        <meta property="og:type" content="website">
        <meta property="og:description" content="Portfolio" />
        <meta property="og:image" content="" />
    </head>   
    <body>
        <div id="modeButton">
            <button type="button" value="dark" onclick="darkMode(this)" onmouseover="hoveringOn(this)" onmouseout="hoveringOff(this)">
                <div class="modeImg"><img id="modeImg" src="init/index_img/moon_off.png"></div>
                <div id="modeState">다크 모드로 보기</div>
            </button>
        </div>

        <div id="container" onclick="reload();">
            <article>
                <script src="init/highlight/highlight.min.js"></script>
                <script>hljs.highlightAll();</script>
                <script src="init/highlight/highlights_line.js"></script>
                <script>initNumber(window, document);</script>
                <script>hljs.initLineNumbersOnLoad();</script>        
                <div id="mainHeadWrapper">
                </div>
                
                <div id="content">
                    <div class="portfolio_name">
                        <span><b>Jun-Min Lee</b></span>
                    </div>
                    <br><br>
                    <div class="portfolio_ko">
                        <p style="padding-top: 40px;">
                            한국어 페이지는 <a onclick="pjaxPage('portfolio_ko.html');"><span class="highlight" style="color: rgb(0, 3, 206);">[여기]</span></a>를 참고해주세요.
                        </p>
                    </div>
                    <div class="portfolio_intro">
                        <img src="init/index_img/profile3.png" style="width:25%; float: right; margin-left: 60px; padding-top: 40px; padding-bottom: 30px;">
                        <p style="padding-top: 40px;">
                            I am an AI developer who wants to make the world a better place through artificial intelligence.
                            I believe that AI can play a significant role in various fields, such as saving lives and increasing work efficiency.
                            When I first started studying AI, I couldn't have imagined such a future, but now, with the development of technologies like LLM and MLLM, AI is able to perform many tasks that only humans could do. 
                            I am thrilled that we are getting closer to the ideal AI I have envisioned.
                            This naturally led me to take an interest in LLM, and I am currently studying and working with it.
                            I am continuously striving to gain diverse experiences to become an AI researcher and engineer who contributes to making the world a better place.
                        </p>
                    </div>
                    
                    <div class="portfolio_about">
                        <p style="border-bottom: solid rgb(199, 199, 199) 1.5px;">
                            <span style="font-size: 20px;"><b>Skills</b></span>
                        </p>
                        <ul>
                            <li><b>Programming Language</b>: Python, Java (Spring)</li>
                            <li><b>Tools</b>: FastAPI, PyTorch, PyTorch Lightning, LLM Training &amp; Serving (Triton-client, TensorRT-LLM, TensorRT-LLM Backend, vLLM, ollama), PEFT, RAG, Docker, Git, Elasticsearch, GCP</li>
                            <li><b>Environment Preferences</b>: Linux, Mac</li>
                            <li><b>Others</b>: PostgreSQL, HTML, CSS, JavaScript</li>
                        </ul>
                    </div>
                    <div class="portfolio_contact">
                        <p style="border-bottom: solid rgb(199, 199, 199) 1.5px;">
                            <span style="font-size: 20px;"><b>Contact</b></span>
                        </p>
                        <ul>
                            <li><b>Mail</b>: ljm56897@gmail.com</li>
                            <li><b>GitHub</b>: <a href="https://github.com/ljm565" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);">https://github.com/ljm565</a></li>
                            <li><b>Blog</b>: <a href="https://ljm565.github.io" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);">https://ljm565.github.io</a></li>
                            <li><b>CV</b>: <a href="init/cv.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);">[PDF file]</a></li>
                        </ul>
                    </div>
                    <div class="portfolio_researchArea">
                        <p style="border-bottom: solid rgb(199, 199, 199) 1.5px;">
                            <span style="font-size: 20px;"><b>Research Area</b></span>
                        </p>
                        <ul>
                            <li>Healthcare</li>
                            <li>Natural language processing</li>
                            <li>Document Understanding</li>
                            <li>LLM, MLLM tuning and serving, PEFT</li>
                        </ul>
                    </div>
                    <div class="portfolio_education">
                        <p style="border-bottom: solid rgb(199, 199, 199) 1.5px;">
                            <span style="font-size: 20px;"><b>Education</b></span>
                        </p>
                        <ul>
                            <li>Ph.D. in KAIST Graduate School of AI, 2021 ~ present</li>
                            <li>M.S. in KAIST Aerospace Engineering, 2019 ~ 2021</li>
                            <li>B.S. in Aerospace Engineering in KAIST, 2015 ~ 2019</li>
                        </ul>
                    </div>
                    <div class="portfolio_work">
                        <p style="border-bottom: solid rgb(199, 199, 199) 1.5px;">
                            <span style="font-size: 20px;"><b>Work</b></span>
                        </p>
                        <ul>
                            <li>Kakao Healthcare, 2024.10. - 2025.04. (DS/IX, Student internship)</li>
                            <ul>
                                <li>Performed both PEFT and full training of a medical NER-specialized LLM, and deployed the model to multiple specialized medical centers using vLLM for inference.</li>
                                <li>Built a GCP-based healthcare counselor chatbot by integrating RAG to provide accurate and context-aware health consultations.</li>
                            </ul>
                            <li>Lomin, 2023.04. - 2024.09. (ML team, Military service replacement)</li>
                            <ul>
                                <li>Trained a document-specialized LLM for document understanding tasks and deployed it on-premises to enterprise environments using TensorRT-LLM and TensorRT-LLM Backend for optimized inference.</li>
                                <li>Deployed various deep learning models—including text detection, recognition, and classification—to multiple enterprises in on-premises environments using BentoML and Triton client.</li>
                                <li>Customized YOLOv8 to improve the performance, speed, and robustness of the text detection model specifically for document images.</li>
                                <li>Built a zero-shot document classification system by developing a document embedding model capable of generalizing to unseen document types without task-specific fine-tuning.</li>
                                <li>Departed from the conventional two-stage OCR approach by designing and implementing an end-to-end pipeline that unifies text detection and recognition, resulting in enhanced management efficiency.</li>
                                <li>Developed a lightweight Autoscan model capable of real-time prescription detection, and deployed it using TensorFlow.js for in-browser inference across multiple pharmacies without the need for server-side computation.</li>
                            </ul>
                            <li>IBRICKS, 2021.09. - 2023.04. (AI Tech, Military service replacement)</li>
                            <ul>
                                <li>Maintained and added new features to a document analysis product developed in Java, ensuring its stability and continuous improvement in functionality.</li>
                                <li>Designed and implemented an open-domain chatbot system using models like GPT-2, DialoGPT, and BART prior to the rise of LLMs.</li>
                                <li>Built a BERT-based extractive summarization model for long documents by identifying and extracting key sentences, enabling concise and relevant summaries.</li>
                                <li>Reduced model size and complexity by replacing traditional sequence-to-sequence architecture with a shared encoder-decoder model, improving efficiency while maintaining performance.</li>
                                <li>Developed TESGAN (Text Embedding Space GAN), an unsupervised GAN-based model that generates rich embedding space for text data augmentation, designed prior to the advent of LLMs.</li>
                                <li>Developed an OCR model specialized for extracting text from online home shopping advertisement images.</li>
                            </ul>
                        </ul>
                    </div>
                    <div class="portfolio_researchContrib">
                        <p style="border-bottom: solid rgb(199, 199, 199) 1.5px;">
                            <span style="font-size: 20px;"><b>Research Contribution</b></span>
                        </p>
                        <ul>
                            <li>2025 PC Member, Association for the Advancement of Artificial Intelligence (AAAI)</li>
                            <li>2023, 2024 PC Member, Association for the Advancement of Artificial Intelligence (AAAI)</li>
                            <li>2023 Industry Track Committee, Empirical Methods in Natural Language Processing (EMNLP)</li>
                            <li>2023 PC Member, Empirical Methods in Natural Language Processing (EMNLP)</li>
                            <li>2023 PC Member, Association for Computational Linguistics (ACL)</li>
                        </ul>
                    </div>
                    <div class="portfolio_publication">
                        <p style="border-bottom: solid rgb(199, 199, 199) 1.5px;">
                            <span style="font-size: 20px;"><b>Publication</b></span>
                        </p>
                        <ul>
                            <li>[P7] Geun Hyeong Lee*, <b>Jun-Min Lee</b>*, Kihoon Sung, Ji Young Min, Jae Won Jang, Eun Jin Ahn, Yun Ah Baek, Hyun Jung Kim, Ji Yeon Park, Min Young An, Yu Ri Cho, Hye Yeong Kim, Dosang Cho, Choongki Kim, Hong Seok Park, Kyung-Jae Lee, Joo Heung Yoon, Hyo Jung Kim, and Soo-Yong Shin (2025), Large Language Model-based Named Entity Recognition for Unstructured Clinical Test Reports: Multi-centre Implementation and Validation, <i>Preprint</i> (*: equal contribution). (under review)</li>
                            <li>[C2] Jiyoung Lee*, Seungho Kim*, Jieun Han, <b>Jun-Min Lee</b>, Kitaek Kim, Alice Oh, and Edward Choi (2025), Trans-EnV: A Framework for Evaluating the Linguistic Robustness of LLMs Against English Varieties, <i>Preprint</i> (*: equal contribution). <a href="https://arxiv.org/abs/2505.20875" target="_blank">[pdf]</a></li>
                            <li>[P6] <b>Jun-Min Lee</b> and Tae-Bin Ha (2023), Unsupervised Text Embedding Space Generation Using Generative Adversarial Networks for Text Synthesis, <i>Northern European Journal of Language Technology (NEJLT), 9(1)</i>. <a href="https://arxiv.org/abs/2306.17181" target="_blank">[pdf]</a></li>
                            <li>[P5] <b>Jun-Min Lee</b>*, Hyun-Soo Kim*, Tae-Bin Ha, Hojin Park, and Youngmin Ahn (2021), Open-Domain Dialogue Generation using Pre-trained Language Models in Korean, <i>Conference of Korea Computer Congress (KCC)</i> (*: equal contribution). <a href="https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11113420" target="_blank">[pdf]</a></li>
                            <li>[P4] <b>Jun-Min Lee</b>, Yunshil Choi, and Jung-Ryul Lee (2022), Laser structural training, artificial intelligence-based acoustic emission localization and structural noise signal distinguishment in a thick FCEV fuel tank, <i>International Journal of Hydrogen Energy (IJHE), 47(6), 4236-4254</i>. <a href="https://www.sciencedirect.com/science/article/abs/pii/S036031992104372X" target="_blank">[pdf]</a></li>
                            <li>[P3] <b>Jun-Min Lee</b>, and Jung-Ryul Lee (2021). Acoustic emission localization on composite hydrogen storage tank and feature analysis of acoustic emission and noise signals. <i>Conference of The Korean Society for Aeronautical and Space Sciences (KSAS)</i>. <a href="https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE10613500" target="_blank">[pdf]</a></li>
                            <li>[C1] Yunshil Choi, <b>Jun-Min Lee</b> and Jung-Ryul Lee (2020), Nondestructive Testing and Structural Health Monitoring for Pressure Vessels of FCEV using Guided-Wave Ultrasonic Propagation Imager, <i>Conference of The Korean Society for Composite Materials (KSCM)</i>.</li>
                            <li>[P2] <b>Jun-Min Lee</b>, Yunshil Choi, and Jung-Ryul Lee (2020), Structural Health Monitoring of Hydrogen Pressure Vessel using Artificial Intelligence, <i>Conference of The Korean Society for Nondestructive Testing (KSNT)</i> (<b>Award</b>).</li>
                            <li>[P1] <b>Jun-Min Lee</b>, Yunshil Choi, and Jung-Ryul Lee (2019), Acoustic Emission Simulation using Pulse Laser-induced Wave with Considering Arrival Time for Quantification, <i>The 1st Korea-China-Japan Joint Symposium on Composite Materials</i>.</li>
                        </ul>
                    </div>
                    <div class="portfolio_project">
                        <p style="border-bottom: solid rgb(199, 199, 199) 1.5px;">
                            <span style="font-size: 20px;"><b>Work Projects</b></span>
                        </p>
                        <ul>
                            <li><span style="font-size: 18px;"><b>LLM Training &amp; Serving (2023.12 ~ 2024.09)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: I train LLMs for chat and document understanding. This involves using various training methodologies and the latest LLM models, including cutting-edge PEFT techniques like LoRA, DoRA, and MoRa. I also conduct performance experiments on these models. To serve the trained models on-premises, I use tools such as TensorRT-LLM, TensorRTLLM-Backend, vLLM, and ollama.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 100%</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, PyTorch, TensorRT-LLM, TensorRTLLM-Backend, vLLM, ollama, Deepspeed</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>Full-parameter tuning of LLM with AMP and deepspeed.</li>
                                    <li>Cutting-edge PEFT application.</li>
                                    <li>LLM serving via TensorRT-LLM, TensorRTLLM-Backend, vLLM, and ollam.</li>
                                </ul>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>BentoML &amp; Triton Serving (2023.08 ~ 2024.09)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: BentoML and Triton Inference Server are used to serve products in on-premises. Additionally, I continuously perform maintenance to improve model performance and meet customer requirements.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: I managed five projects, three of which are still ongoing.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>:Python, BentoML, Triton Client, Trition Inference Server</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>BentoML serving.</li>
                                    <li>Trition inference server serving.</li>
                                </ul>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>Document Detection Model Enhancement (2023.11 ~ 2024.09)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: This project was initiated to improve the performance of the documents detection model. To enhance speed and performance, I created a custom model by making the detection model more lightweight. Additionally, I improved and implemented the model to classify and predict various classes.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 100%</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, PyTorch</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>Improved speed.</li>
                                    <li>Improved performance.</li>
                                    <li>Supported various model transformations including ONNX and TensorRT.</li>
                                </ul>
                            </ul><br>
                            <!-- <li><span style="font-size: 18px;"><b>Lina (2024.01 ~ present)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>MRAS (2024.03 ~ present)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>보건연구원 (2023.11 ~ present)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>Jeekim (2023.09 ~ present)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                            </ul><br> -->
                            <li><span style="font-size: 18px;"><b>Zero-shot Document Classifier (2023.06 ~ 2023.12)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: This project was initiated to reduce the effort of training for each document every time document classification is performed for each business.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 70% (Two individuals involved)</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, PyTorch</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>Trained model.</li>
                                    <li>Quantitative evaluation (Contribution: 40%).</li>
                                </ul>
                            </ul><br>
                            <!-- <li><span style="font-size: 18px;"><b>Hanwha Aerospace (2023.08 ~ 2023.09)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: It was a project to extract table data from English documents. We developed an end-to-end model that takes document images and outputs table data.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 30% (Two individuals involved)</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, PyTorch</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>Trained model (20%).</li>
                                    <li>Post-processing of model results (Contribution: 80%)</li>
                                </ul>
                            </ul><br> -->
                            <li><span style="font-size: 18px;"><b>End-to-end Document OCR Model Development (2023.06 ~ 2023.11)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: For document OCR models, the process typically involves two stages: detection and recognition. These stages are interdependent, leading to maintenance challenges and instability in training. To address this, we developed an end-to-end model capable of predicting both the text content and its bounding boxes in documents. We then compared the quantitative performance of this model at each stage with that of several popular detection and recognition models.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 65% (Three individuals involved) </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, PyTorch</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>Developed end-to-end document OCR model (Contribution: 50%)</li>
                                    <li>Quantitative evaluation of the developed model compared to several baselines (Contribution: 60%).</li>
                                    <li>Wrote technical report.</li>
                                </ul>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>Autoscan Model Serving (2023.04 ~ 2023.05)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: Autoscan is a technology that automatically takes a photo when a document enters the camera scanner. To achieve this, a model is needed to determine whether a document has been inserted, and this model must be lightweight enough to run on the frontend. I modified ResNet to train a lightweight model and converted the PyTorch model to TensorFlow.js to serve it using WebGL in JavaScript.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 100%</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, JavaScript, PyTorch, Tensorflow.js, WebGL</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>Collected over 5,000 document images and developed augmentation logic to mimic real scanning environments.</li>
                                    <li>Created and trained a custom model in PyTorch and converted it to TensorFlow.js.</li>
                                    <li>Developed a smoothing logic in JavaScript to determine scan status, prioritizing the reduction of false positives over false negatives.</li>
                                </ul>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>KEIT Text Analytic, Classifier, Clustering (2022.03 ~ 2023.04)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: Maintained a document analysis product built in Java and improved the performance of the document embedding model.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 35 ~ 45% (This project involved ongoing maintenance of the company's product and 3 ~ 4 memebers involved).</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Java (Spring), Postman, Apache JMeter, FastText</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>Improved document embedding model performance and evaluated the model via text cloud project.</li>
                                    <li>Implemented a document classification handler using FastText (Contribution: 80%).</li>
                                    <li>Developed API communication using Java Spring and performed testing with Postman (Contribution: 20%).</li>
                                    <li>Developed a server capable of node-based load distribution for multiple requests (Contribution: 45%).</li>
                                    <li>Conducted server load testing using Apache JMeter (Contribution: 30%).</li>
                                    <li>Created category-specific text clouds through K-medoid model training (Contribution: 50%).</li>
                                </ul>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>Open-domain Chat System Modeling (2022.03 ~ 2023.04)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: This project was to build a daily conversation chatbot model using anonymized Korean data. For generative models, we used DialoGPT, GPT-2, and BART as baselines and I was responsible for training the DialoGPT and KoGPT models. Additionally, inspired by the CLIP model, I developed a Text-CLIP model utilizing embeddings of sequential text and this model retrieves appropriate responses from a database based on previous sentences.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 75% (Two individuals involved).</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, PyTorch, Hugging Face, Uvicorn, Websocket, FastAPI</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>Built a generative chatbot based on DialoGPT and KoGPT.</li>
                                    <li>Demonstrated the developed generative chatbot model at a public institution and continued to collect additional chat log data provided by the institution for further training (Contribution: 50%).</li>
                                    <li>Developed the Text-clip model and created a chatbot that provides appropriate responses from a database.</li>
                                    <li>Implemented token streaming using Uvicorn, WebSocket, and FastAPI in an asynchronous manner, allowing multiple chatbot models to generate sentences simultaneously in real-time.</li>
                                    <li>Performed morphological analysis to convert data into the '해요체' (polite informal) form and used it for training the chatbot (Contribution: 50%).</li>
                                </ul>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>Document Extractive Summarization (2022.06 ~ 2022.08)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: This project was conducted at the request of a public institution. To extract summaries, we trained models and used KoBERT and Sentence BERT (SBERT) as baselines for experimentation. Specifically, I developed a model for extractive summarization using KoBERT. Given the large number of sentences in each document, I employed the sentence n-grams technique to address this challenge.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 50% (Two individuals involved)</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, PyTorch, Hugging Face</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>Developed KoBERT-based extractive summarization model.</li>
                                    <li>Developed a large-scale document summarization technique based on n-grams.</li>
                                </ul>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>Language Model Lightweighting (2022.06 ~ 2022.12)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: During the development of an open-domain chat model, I conducted language model lightweighting to enhance training resource efficiency and scalability for various auxiliary tasks. I achieved lightweighting by sharing weights between the encoder and decoder of the existing seq2seq-based model. Additionally, I designed the model to perform various tasks by simply changing its masks. The resulting model demonstrated exceptional performance in semantic tasks compared to conventional models, and it was versatile for multi-modal applications such as text-text and image-text scenarios.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 98% (Two individuals involved)</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, PyTorch</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>Implemented and trained custom model.</li>
                                    <li>Quantitative and qualitative evaluation.</li>
                                </ul>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>Text Augmentation using GAN (2022.01 ~ 2022.12)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: Before the emergence of LLMs, I developed a model for text data augmentation. At that time, text augmentation techniques relied on supervised learning-based autoregressive methods to generate sentences. However, this approach led to data memorization, where the model simply reproduced the training data. To address this issue, I introduced an unsupervised GAN approach to learn the text embedding space and convert it into sentences.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 95% (Two individuals involved)</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, PyTorch</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Paper</span>: <a href="https://arxiv.org/abs/2306.17181" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);">https://arxiv.org/abs/2306.17181</a></li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>Developed and trained a model for idea validation.</li>
                                    <li>Wrote a research paper.</li>
                                </ul>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>Online Commercial Advertisement OCR (2021.09 ~ 2021.12)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: This project evaluated the performance of an online advertising OCR model trained on publicly available Korean text-in-the-wild data and open document OCR data sources such as AI Hub. The trained model's results were compared with major OCR services like Tesseract and ABBYY.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 100%</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, OpenCV, PyTorch, Tesseract</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>Processed text-in-wild &amp; document OCR data using OpenCV.</li>
                                    <li>Trained and tested OCR models based on CRAFT and transformers.</li>
                                    <li>Tested various commercial OCR platforms.</li>
                                </ul>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>Document Inverted Indexing (2021.09 ~ 2021.09)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: I developed an inverted indexing program that considers word frequency and lexicographic order in documents. Using StringBuffer, I implemented the program to generate the inverted index within 3 seconds for 300,000 documents.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 100%</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Java</li>
                            </ul>
                        </ul>
                    </div>
                    <div class="portfolio_individual_project">
                        <p style="border-bottom: solid rgb(199, 199, 199) 1.5px;">
                            <span style="font-size: 20px;"><b>Individual Projects</b></span>
                        </p>
                        <span>* For more details, please refer to <a href="https://github.com/ljm565" target="_blank"><span class="highlight" style="color: rgb(0, 3, 206);">GitHub</span></a>.</span>
                        <ul>
                            <li><b>Universal LLM Trainer</b> <a href="https://github.com/ljm565/universal-llm-trainer" target="_blank">[link]</a></li>
                            <ul>
                                <li>A modular training framework for easily fine-tuning open-source LLMs. Supports instruction tuning, full fine-tuning, LoRA, QLoRA, and training strategies like DDP, FSDP, and gradient checkpointing. Enables autoregressive pre-training and SFT-based instruction tuning with simple model wrapper integration.</li>
                                <li>Tools Used: Python, PyTorch</li>
                            </ul>
                        </ul>
                    </div>
                </div>

                <script>
                    headHighlightColorChanger();
                </script> 
            </article>
        </div>

        <div id="menuRelated">
            <div class="menuButton">
                <img id="menuImg" src="init/index_img/menu_black.png" onclick="openMenu(this);">
            </div>
            <div class="menu">
                <img id="menuExtension" title="메뉴를 확장합니다." src="init/index_img/extension_black.png" onclick="extendMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
            <div class="bigMenu">
                <img id="menuCompression" title="메뉴를 축소합니다." src="init/index_img/compression_black.png" onclick="compressMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
        </div>

        <script>
            detectScroll();
            pushFunc();
            detectSize();
        </script>
    </body>
</html>