<!DOCTYPE html>
<html>
    <head>
        <title>Convolutional Neural Network (CNN)</title>
        <meta name="description" content="CNN 원리를 설명하고 여러 종류의 CNN과 사용처에 대해 언급합니다.">
        <meta charset="utf-8">
        <link rel="stylesheet" href="init/index.css">
        <link rel="stylesheet" href="init/contents.css">
        <link rel="stylesheet" href="init/index_img/icons/css/fontello.css">

        <link rel="preconnect" href="https://fonts.googleapis.com"> 
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> 
        <link href="https://fonts.googleapis.com/css2?family=Dongle:wght@300&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Gowun+Batang&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic&display=swap" rel="stylesheet">

        <link rel="stylesheet"
            href="init/highlight/styles/github-dark.min.css">
        <script src="init/highlight/highlight.min.js"></script>
        <script>hljs.highlightAll();</script>
        <script src="init/highlight/highlights_line.js"></script>
        <script>initNumber(window, document);</script>
        <script>hljs.initLineNumbersOnLoad();</script>

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        <script src="init/index.js"></script>
        <script src="init/jquery.pjax.js"></script>
        
        <meta name="viewport" content="width=device-width, initial-scale=0.8, max-width=1">

        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-219110982-1"></script>
        <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-219110982-1');
        </script>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7745178886614102"
        crossorigin="anonymous"></script>

        <meta property="og:url" content="https://ljm565.github.io/contents/CNN1.html" />
        <meta property="og:title" content="Convolutional Neural Network (CNN)" />
        <meta property="og:type" content="website">
        <meta property="og:description" content="CNN 원리를 설명하고 여러 종류의 CNN과 사용처에 대해 언급합니다." />
        <meta property="og:image" content="https://lh3.googleusercontent.com/fife/AMPSemc3bMQo2966xjEcEloixPFiy6BKHR6D6Z6qcuFcdEOSiiysHIHFHMxgpUH5QuB5f0Gu6X-_5wYPv6SPqhLubHDmZa59GvxHyyWFxdmrNKuDsh146vzj-rJNoOJQVt5J-A2MVSUuX5DWRzjPPz5ijtUnf4r0sf7DbbRUHVR0iX6PnP74Ip_8wCS-z5G0O7uKWPuBsWwn2YXlV8SUBaN7cw2aMru8R1kB4grNLkDghmtJvqdbkuIcDWsrFFBhYxVrNeargnG91jlyx_Em0YmNz6eAmEWM9DA1BH1y6aSYDgYOshgedbpmZvnRMsRg2abxg9DEy_D9CKFKUIkwxGwiqdMSfsSO05L_ZNfVjQDsFezyueg18PBkjGViGyoPib8wHOS9F2Manacp-OhNHuhgrO1k4PIpKuAGa5dv08JRexeSg0xYRK0XTyp6IG3txG4JWD8boas2nqk0f6DfRAcr0SXav-FkHg2B6BCpLDXUUOx13-p5ge8XVLlvx6RbmAMdsoLovzy5gOXeSxDp925x2qIVqKwyif4hemVGwrtzEnzRttFxdehjUi7US_3XUJjGNVVjOw3zCIG5ZENB0cWcY8wwZTEgDARmE_J8YiNIypk13SNEWxRq_zQWiWlXUwyzsZl6gAApWb2pkawPl91mAHRw1DZvh2D0dpUKGRO77BmGazJ5lqMUyqZNIHtflFUpWrRRx3-WGF0CbnfYTuEOqg0mBDOYc5ve8Oz_BRVW4d79J9Zx4e8NSac-n1GXE3xF2J-tENddxXc7YVwNjEXoRGghN-FmJ86iw7lliHLAHC990o5PK_A524ymqa_GCTwMdnwhIkM-9K7bAldDtwhdzabaFC-fgJURi26EUaWpnkf7XJNAHGolyOWuQNB8G_O14xi7ZRw1QYM8doCdpXk5-vh0kORCE4bYLJrstGvS0yS-0lBjHNKwJZOATch8eDxuPKomK8lu-U2HI_tzLDPcQ59ZNV3_OoQLRryh_rsCX4CWW5gu9XGS6yfRRRlKz8C3QrywYfEdio3SM_mg1Tm7gwiA8bvaUyt1-f_fN0h1BIgqX78TtR_0oNIRURKHsd4meoBx05VjUd_D1TqmmYnlwPz8KrY4f8N68ch1e0XVF3EV49KA0vbpfMF2x1UQhkIBL6xO4dZ8zdkFhL1GKxu6D2UlX0OKuE0zEz7nHs_VBObIk33qvVHXls03jR_xXqkZIwSa_CoamJ-lo4X0nj_gmU3NKNfjes4kjqYFxuBbttrS0kfTH9iXtr5zveU78_A5pyyg_z5lzv8IuRq21ZWRbe4CDqLBfCkGE23Oeb8ttgPpxvmJx_AjIcuLyPwoKgIBr_R4vZvSn9RTO1IvA__VK4_U6ftmrJiMZa9OPOZnLTWbRv48xPGr1lcjg9sWfDpUUuh29cjG9XqS94O6Up_lso57x4KbfnOApzzkI_Dn1YKx3QPqR-IQiM7ZWFGgv1xiSSRNxYn_oDci-yO0XrxldPg" />
    </head>   
    <body>
        <div id="modeButton">
            <button type="button" value="dark" onclick="darkMode(this)" onmouseover="hoveringOn(this)" onmouseout="hoveringOff(this)">
                <div class="modeImg"><img id="modeImg" src="init/index_img/moon_off.png"></div>
                <div id="modeState">다크 모드로 보기</div>
            </button>
        </div>

        <div id="container" onclick="reload();">
            <article>
                <script src="init/highlight/highlight.min.js"></script>
                <script>hljs.highlightAll();</script>
                <script src="init/highlight/highlights_line.js"></script>
                <script>initNumber(window, document);</script>
                <script>hljs.initLineNumbersOnLoad();</script>
                <script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
                <script>
                    initMathJax();
                </script>
                <div id="mainHeadWrapper">
                    <div id="mainHead">
                        <h1 class="contentHead">딥러닝 이야기 / Convolutional Neural Network (CNN) &amp; Residual Network (ResNet) / 1. Convolutional Neural Network (CNN)</h1>
                    </div>
                </div>
                
                <div class="title" style="background-image:url(https://lh3.googleusercontent.com/fife/AMPSemc3bMQo2966xjEcEloixPFiy6BKHR6D6Z6qcuFcdEOSiiysHIHFHMxgpUH5QuB5f0Gu6X-_5wYPv6SPqhLubHDmZa59GvxHyyWFxdmrNKuDsh146vzj-rJNoOJQVt5J-A2MVSUuX5DWRzjPPz5ijtUnf4r0sf7DbbRUHVR0iX6PnP74Ip_8wCS-z5G0O7uKWPuBsWwn2YXlV8SUBaN7cw2aMru8R1kB4grNLkDghmtJvqdbkuIcDWsrFFBhYxVrNeargnG91jlyx_Em0YmNz6eAmEWM9DA1BH1y6aSYDgYOshgedbpmZvnRMsRg2abxg9DEy_D9CKFKUIkwxGwiqdMSfsSO05L_ZNfVjQDsFezyueg18PBkjGViGyoPib8wHOS9F2Manacp-OhNHuhgrO1k4PIpKuAGa5dv08JRexeSg0xYRK0XTyp6IG3txG4JWD8boas2nqk0f6DfRAcr0SXav-FkHg2B6BCpLDXUUOx13-p5ge8XVLlvx6RbmAMdsoLovzy5gOXeSxDp925x2qIVqKwyif4hemVGwrtzEnzRttFxdehjUi7US_3XUJjGNVVjOw3zCIG5ZENB0cWcY8wwZTEgDARmE_J8YiNIypk13SNEWxRq_zQWiWlXUwyzsZl6gAApWb2pkawPl91mAHRw1DZvh2D0dpUKGRO77BmGazJ5lqMUyqZNIHtflFUpWrRRx3-WGF0CbnfYTuEOqg0mBDOYc5ve8Oz_BRVW4d79J9Zx4e8NSac-n1GXE3xF2J-tENddxXc7YVwNjEXoRGghN-FmJ86iw7lliHLAHC990o5PK_A524ymqa_GCTwMdnwhIkM-9K7bAldDtwhdzabaFC-fgJURi26EUaWpnkf7XJNAHGolyOWuQNB8G_O14xi7ZRw1QYM8doCdpXk5-vh0kORCE4bYLJrstGvS0yS-0lBjHNKwJZOATch8eDxuPKomK8lu-U2HI_tzLDPcQ59ZNV3_OoQLRryh_rsCX4CWW5gu9XGS6yfRRRlKz8C3QrywYfEdio3SM_mg1Tm7gwiA8bvaUyt1-f_fN0h1BIgqX78TtR_0oNIRURKHsd4meoBx05VjUd_D1TqmmYnlwPz8KrY4f8N68ch1e0XVF3EV49KA0vbpfMF2x1UQhkIBL6xO4dZ8zdkFhL1GKxu6D2UlX0OKuE0zEz7nHs_VBObIk33qvVHXls03jR_xXqkZIwSa_CoamJ-lo4X0nj_gmU3NKNfjes4kjqYFxuBbttrS0kfTH9iXtr5zveU78_A5pyyg_z5lzv8IuRq21ZWRbe4CDqLBfCkGE23Oeb8ttgPpxvmJx_AjIcuLyPwoKgIBr_R4vZvSn9RTO1IvA__VK4_U6ftmrJiMZa9OPOZnLTWbRv48xPGr1lcjg9sWfDpUUuh29cjG9XqS94O6Up_lso57x4KbfnOApzzkI_Dn1YKx3QPqR-IQiM7ZWFGgv1xiSSRNxYn_oDci-yO0XrxldPg);">
                    <div>
                        <span class="mainTitle">Convolutional Neural Network (CNN)</span>
                        <br><br>
                        <div style="display: table-cell; margin: 0;">
                            <img src="init/index_img/profile.png" style="width: 30px; cursor: pointer;" onclick="pjaxPage('/');">
                        </div>
                        <span class="subTitle" style="display: table-cell; text-align: left; vertical-align: middle; padding-left: 20px; line-height: 125%;">작성자: 여행 초짜<br>작성일: 2022.07.24</span>
                    </div>
                </div>

                <div id="content">
                    <p>
                        시작하기 앞서 틀린 부분이 있을 수 있으니, 틀린 부분이 있다면 지적해주시면 감사하겠습니다.
                        
                        <br><br>딥러닝 이야기의 다섯 번째 주제는 Convolutional Neural Network (CNN) 입니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">CNN은 현재 가장 많이 사용되는 모델 중 하나입니다. 특히 이미지에서 그 성능이 우수하여 비전 관련 연구에서 많이 사용되는 모델입니다.
                        또한 이미지 뿐 아니라 1D CNN 같은 경우 자연어 처리에 쓰이기도 합니다.</span>

                        <br><br><span class="highlight" style="color: rgb(0, 3, 206);">이 글에서는 CNN의 원리와 종류, 그리고 CNN이 작동하기 위해 필요한 stride, pooling 등에 대해 알아보도록 하겠습니다.</span>
                        그리고 CNN이 어디에 사용되는지, 유명한 모델이 무엇이 있는지도 간단하게 살펴보겠습니다.
                        마지막으로 CNN의 한계에 대해서도 언급하도록 하겠습니다.

                        <br><br>오늘의 컨텐츠입니다.
                        <ol>
                            <li>CNN의 원리</li>
                            <li>CNN의 종류</li>
                            <li>컴퓨터 비전에 있어서 CNN의 사용</li>
                            <li>CNN의 한계</li>
                        </ol>
                    </p>



                    <h1 class="subHead">Convolutional Neural Network (CNN)</h1>
                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center;">&ldquo;</span>
                        <span>CNN의 원리</span><br>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        딥러닝의 가장 기초가 되는 레이어는 바로 linear layer 입니다.
                        Linear layer를 이용하는 방법은 매우 간단합니다.
                        데이터에 행렬 계산을 진행하고 non-linear activation function을 거쳐, 비선형 변환으로 데이터를 변형시켜 우리가 하고자하는 task를 수행합니다.
                        따라서 대부분의 데이터는 (batch size * hidden size)의 2차원의 크기를 가진 데이터가 대부분입니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">그리고 이 글에서는 batch를 제외하고 생각하여 이 데이터들을 1차원의 크기를 가진 데이터라고 생각하겠습니다.</span>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemdKusDWkB3t8i_XD2mTtz6x8RXfRvEYy2s-5L41j8lI_97wyL-o49XGYYDRss9UXYC6zzubtDhyFD1ruKjm5pbyN-nxAkw9tZONS8c1QYco-Jm49pxMU7PPQfQ3Zrl0BirY7z_txbc1TuWGvzulOABm0-hT41bObvP1VlMlK_HGj4XTT4m5H-PlYxbCk3ftaVIBq6iDOqgDsgC--g6vj797llCS6q0661xl8V3MWQXdpuqlkkak4KHplNEzIgXEO-fK8rSvtwI11pNBZmjEspdbj2_cgH16i00nZSWM_QECSlBPS2okwOH2yzUH8G7A0uOzIqkig5bDC-fA4ncvs-CSrVR1s9NsKNvutnkAmVpF6DoVM-Na-oTB5F3myKoy7Nwt5-LC3ns2KbOv5Rtdmn9cbvPZU38Mg6oHoodzfFb_IobuvVa8LdzXYGtm9QRXJFutitpbhaCXPQLYMXhdfL3cwYFiL3cRe6IYccsBjxG_6nJah8hv_6CvAcvDM0F5NI9tlUnPptqHiNHjPAgD6ZYWvZetQ4lFjURTSvehwDQ81Um97zhDASw1M5Y_0Z37RX_oKU-AWGQ30QfFzrFwpscGFqFLGMDzZ6PSoMfl38gf7p-MzfvhClGA2DD_2NIef9F6gZn5syC-mMfSLHTb_PkOlEAEgnJhZRl5kBNFlJ-3xBWFJMseJIRi7KUTOi-jxyLamstVd6R5b41iDjWJkpov5kd8EDAQxh_piXGUOJ46gmtWojWTBQJG5r9t5nNMDlIL9842FrfiR0KC2ECuy2a0p_8MIOLWGCcdTovvVX4I9bii6fpy4CEL6wGRJkb-HLxH8QVQDm24zWupVtZJUKaHrCuyKjpM88677-VYPXhoVynCPfdNJzgJbJa8VQ9XsiOdXzIhn9QaLBxdfSEsEJy2jx0D1TWKN_5edUwqWBbuxwbRErNeWaiqISw8JREyE4FqEevAsQEv2Z4g2mz8OOHjybF-oP-ZR1u7JFhpuzrH5Z7L3D8UyKUetjOkD49mgUA6cGGHccY4qdaEfFw4Ll64LroeUrUSJkM8bygVXHvz-nu7rT74AAjajKfNzsNBUAfK_sLbZ0niPxuhlEuIISl8qG2qIfcWTYWAkJ7qmpV-nZ2f3fcJlHGPF5ppvMIIYDFa11oIqfNmqVZ8XBC5tRZXqXMqqKw4iSd6i7DGpskafzBkklnT5Z3zc4YyyEengI0BkkV69bPbFlacVcGvNzoq384fxT3GAKFoF-9_7qjoeS6wlvUn79807V6m_nNUVC43uvUx6g5NmPvl0nWPbFvqMAKbqlXrVpZM7lv-VPW8Nl-yBvOEnCbNElLjpJqJ-vfuXmXH-6tgSENlmiJUZI-GGOHVh0rrAPARsxUFuqxrmy_floLQ-VvX6FJ6oO1QHUneZrTre3RfQoITCfGUskROh_pP0YupLUyna1lPeGyYwVjvZkUQFFl3EkYcuNXYFHVfb69jthVE2BcRvEOGakA" style="width: 60%;">
                        <p class="caption">Linear layer를 이용한 학습</p>
                    </div>
                    <p>
                        <br><span class="highlight" style="color: rgb(0, 3, 206);">하지만 CNN은 linear layer를 이용한 단순한 행렬 계산이 아닌, convolution이라는 합성곱을 데이터에 적용합니다.</span>
                        그럼 합성곱 방법은 무엇일까요?
                        합성곱의 방법은 아래의 그림을 보면 단번에 이해가 됩니다.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemel_ujXytJwQItrgCexkYZV9qrfGrU9ExPflExaNV_OEDy4SYIN9hzfXifYssSd-TgqdYrmXoqRuMabg2RSHrnXrHYneCLty9V4rMnl-m3psmowj5U7vkEtTabvvcnBdNUvLUJHT89Rj37WCgfe4EAs9cLE8GQzrmjy9gaxfZslfoOkguxJzjaRWd2uS_A9NHZ-OkrYYA-XNBsbTGKUXGCspM-10AQIPUEAKR6ju57sWWZRYw_vScIh85FSJyqrRKnRyg8YB5pmZeC5zjymGjNIdzxjiKGRDYpRUZQ59_RHgF6eTk1qUJ7zeHFFBY2Z55dv6Yj53aFmXsNiF1j-FIcdu1RgDyOfWb98iw_dngW2DS-qB4GYFVGlotQe19k1b5sPFAwCQNRwRfmIhoQQM0n1fiLKyULt6WxZOJJ8KPhDuHXKFxhgt30oibYKvn9Zl0OBJjBH_Q-GxljIn9_2-WNgVZyixfTurzhJkN6vZQzQHkH-kXF57ISOMlsLybP8eFRvILzFYtMFAwCIp9QNfTf0bOZtOzvWmYsbAaSRq8RRtMUXfvN-rS4q2YTe6fQ7V6EwzQMDJRVbWqwAhV0_Y6YeLWT-U2KuP-uRG3MQhwKm6Eh0vcwcGxcQOh7PzUHang2rbAfFpX7tVqwuSxdd_oVUfMsgW1_HFZ1zdLWzeUHMnJMcfg6BFzXpazSLoDye9rt8UbYJPSBgvHT3GHdEbTFfZEtgT97TL8b3EcSQ5LK_gKvhtH3BAN7L1jBeZn924_XDvgP4vdBtrrtcgQDcInUvd3iw1nKgOtw9RCTBVzmrRTE8MaYOT1ENtISIUshKxgoHNLvdvwBtPagPXwBMTa5WUvUC_4pNIfpR-amx27NUMnxodUG0yij_36k8ONwfXUpqzJam7NC72rW1hLqGvLSzkBUhY-Ku8rXyi_X_weLHgMUe51DO602h3jW7wsWVF1Olffa-wTOs-3hXL3a6GrTxHu7yh1x1rrD54kqiBnVVKZFEMjSyKXQg0KY_6IQ8R4Gq0GT67vjZxJjkzcouLe9w_1RHtS4b4xQPOYfrdW82Gt6PsCpzado_bPMNBifm4_lA4O7V409xZtkaVMTYFpfYHYUBPZz5AnThFkBiR32XXhyeTvJkojoc8sFRDWy-I6NBzuptIvg3lU-LXQEWk37KHdLiEOfsSPh2z6q3OU1qbLNuV6pk-y5YZKEPJ4HVBMDNJ9OaCaPK-QWOIkIgPo6DublZKIjE65z7lsonzSPP-FZ560muEttMoCHj9cS7i87lKAy5e6PrnJC_IPdFy6DTl-WoRIgRgkMLzcGdSIpdGw49D0ghk_RNuPS0KSOMLcGLxbm3eNVpIP30CRqJ2e2FigGZ3vSliCVRYTSKC7EJMJeuavV86RrTnWXTqJ8ebolIpjPbgG7V2EuE6fkLvrX-naB54XFCLqhYOwpST4Pax7e0M0UJkDp7LTMP7zyfTnxs8KiLoUuO9UCf8P4xU5c" style="width: 35%;">
                        <p class="caption">합성곱을 이용한 학습 (input: 파랑, output: 초록),<br>출처: vdumoulin github (https://github.com/vdumoulin/conv_arithmetic)</p>
                    </div>
                    <p>
                        <br>위 그림을 보면 4*4 크기의 데이터에 3*3의 영역이 가로 세로로 한 칸씩 움직여서 2*2의 크기를 가진 결과를 내어주는 것을 확인할 수 있습니다.
                        그리고 위 그림을 보면서 우리는 한 가지 사항을 예측해볼 수 있습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">바로 기존의 한 줄로 연결한 데이터가 아닌 batch를 제외하고 가로, 세로의 2차원 데이터에 대해 특정 영역 범위(위에서는 3*3 범위)에 있는 값들로 계산한다는 것입니다.</span>
                        <br><br>그리고 왜 CNN이 2차원의 데이터 계산을 위해 만들어졌는지 아래 그림을 보면 이해가 됩니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">우리는 2차원의 이미지 데이터를 1차원으로 변형시켰을 때 그 특징을 바로 알아차리기 쉽지 않습니다.
                        이는 컴퓨터도 마찬가지이며, 이러한 문제점을 해결하고 2차원 이미지를 있는 그대로 보아 특징을 파악하기 위해 만들어진 것입니다.</span>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemcZrqjnVqJYKWbCNENato3qm4sNjQan1IB5X_fwhVPPJzBrAo2bZDC9N7jJy5RE9QVKCvwlG_tCQmHS6WWYOGJOhwdnnYjh0CZNeMG4X4QFZ2V9ikiaWPi9z1xOPrBd7pN8auhtdzwBUl8W4M3E-kYYWVGzGov9_Gw0IijsRm7E35twnR5leI5CbMwssxgs4KDpjOGjhFJin5XCkn6v2DPm4q3MTMueEaGEioBnj0Y18iSW2Q-iko2L3GlrnxpVK3l8_MveBsbUYFIZ6ibtDLslJP8AO47ZYizz3_yF5YS8-XYLnn-zZGlSUfWbdjrepU4p5wmIsN-js3D9FZVh6d_NqledhZ6b6ZrFhafmMdMjAygDhgKlqPXNVqrf4emIHyLS3CZTKHBgnoKXTSaHzhtZNzRbYBsjhtLXgcBx5iwrdBs_j1kgeLiZmhTVnPp8Uz8SLMjKOgFqhxlYp-_4ScNU7s_eounpL1pefdGOO-LulOg2WaU_lVyhC6JR5DKVyCGRGrUjCe3P9wMBJ2IOO57iCvfX8dnyCG7GpEWtHT3fiYPwyeco4ORmAqBVFpiO1EI1wOqdmLJToxPSyPfwD_CAnGeMm6XBKJpusD2kALZkXx94o_BJ-Sj8X-4oB5qyaEnseCQbHkEhKveOsT6NQu43V-AGibqD_L4gQ7iixpiAYW96mRfh96tX6VOrAeMbvULENFvH_QuMHW806-3heYgSNuFd4ZTsOxQVvKZZwhGBdPuKzM38YCQPjHoWpxamrq2Wl2ezcTZ9XpQWN8TmprgzkOjgMLvmEGFfy4wulR8wIVwIENfioKmuWevphV8CXx4gflkMlJFLvb1YrOxPtEzJ0-EInJTmt4CqdeX5OsuqSUXibwpNFxvywzgcN2WA6fGZxt52_Ute9ctWjDWHIGGpw1efBMM7ihHO-gFuLaSWRhKokuKzTGNnYlGX9I2z-N6StYV6tlskuwg-xfsMMfOmEfEoYIGCfp9W_kLj-INwpek3vnndDha73MByKOpRC7DJ-DILft9SzTtxFAn_fIAJvo6iriaAhT9lXLRHiIpdMlcfQYky7qM_CEQZn-voPOO2lO4uVq454dWDdu1T9P01aQsqig0olWkq3jqMAz4DKYt_GLH7Z8E-huEgzCAfcfhkNydQWwezJ5nKOA6OEL4HdD73CpepVtUndOK8BMHbhc4HNxtNdbBcbnt5h3iADQznBrxKvLO-LIzstu9j3I2sK_9Zyfs5dC83s2SR4fPBJc3-ABVNiD6b7M_mnyi85GXz21YsgHLWF4ySM4A-HUTM1PQA1husGBt7yZA27qQo1UgYL6zLSJJZCQaFu6BLfEKL7IG7O-Vr5VLx_YKdwsnwZM1Kw4TyY5nYp4GfpcJjttonLCO_928n75PCWnu34W5N-FFBlpLyaL5DseBPgmrP_cW58RNJ026sHhHzO3FTu81FZaYmbrCMGtWKOEQT_RTtduAdR439g5ao0P2364U" style="width: 100%;">
                        <p class="caption">1D, 2D 이미지 예시</p>
                    </div>
                    <p>
                        <br>이로써 우리는 CNN이 왜 가로, 세로의 크기를 가지는 2차원 데이터인 이미지에 많이 적용되는지 알 수 있습니다.
                        바로 2차원 데이터에 CNN을 사용하여 특정 영역에, 즉 국소 영역에 대해 연산을 진행하기 때문에 이미지의 특징을 잘 파악할 수 있는 것입니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">아래 그림의 사람 이미지를 예로 들어 눈 주위의 영역에 대해 합성곱을 계산하고, 코 주위의 영역에 대해 합성곱을 계산하는 식의 방법으로 데이터를 바라보기 때문에 이미지에 많이 사용되고 효과적인 것입니다.</span>
                        즉 3*3의 영역이 왼쪽 위부터 시작해서 한 칸씩 움직이면서 오른쪽으로 한 줄 계산 후, 한 줄로 아래로 내려와서 그 줄에 대해 또 계산하고, 또 한 줄 아래로 내려오는 방식으로 오른쪽 아래 까지 계산하게 되는 것이죠.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemcXHoe8z2NJX-oW2VeRKHt6oapGi26r9e4QKe0wiApiQdmSIatkPXxk3cGiFFtBUubGF6SfqCzMUyeU0Pm3qUi3NOwEmtS37A1MXJVVXykg2pDRCnTVeMU7UiY15Sa-R1EkZz4sixcv37N_1QA6Qaboz8saJnCMYrLiBtTQ3afDlZ7qJfO6SG4QMAtD40GB7DkGGwjKKxe-yO4GBUL8UtU29OFXtZ519CNMxaBt5y35tjuIqfsyLZ3ocE74T8WqLOwU0fbEt-DdBTpvBOFuX-CoAOOT-nVRS64UvA-3EJRVr31MuDMt2Zp58GmjtBkRNRu_bb3hgyVB54y55D85S2eeVHahVnOAr2UULd6UCPJNYPd73UIP0Ul5kkV6U5JYRiips2dV82QYmXKV-v29F_fDBqF8wFECwzjz--D1y1b5y-yewaErHv0htpjh92lIjx5dlxzMZB1ib5-BRYDDa7gYf8uUlLrV-hcO5WQeHmYXY_OVT1YenwxwudZ1oq5tk6X0EvmSkHIRtjDnXfzIQBsdCoJMDDEwfjC2dbqQDe2Ks0WhYq2jdXbxP190Lvc_b7cK9xwMPVw31WQPBFnKu3WjPesFn89ulLXZKp5Lsc3KnCtMaNzmqWxuek4bYpCHOl5h0lzWJFYaotp_Tbq8ktLWju0CYFg_zo8WrxOfSg_h4W6E9qa6GCjHRnFOPhby9i-uOQ4vPdFKkiWClbRE51kWO_bYUIjIntzRFdM1tKIumyZhKCJzfbbpzdbNJ5il4EG00v_UYJ6wHZMKMYVQ4re3gffXJcwPK4e8TzCgLNX8Kki6bebEtS7cxCM6d0k0mkWaS0tnVG7nVEiAK72j7RPl5CrfaUXjDJt2yCS8M-cSONubBh-cAQLs_MSCLHBqKEdgpEkiOY-McF3nj7I9_Fr4E9QnOrQxvtLM4V2w1T3VNOQuBC53LM3tLLAUL6tglNuUgtHzGEw1H52A_ZftdGTI79M58TyaKYwiCNrql0XIn5wqNh2DIgAhTuahK-UXQuf4P_JCYF5b_zEe70c_4yNyamyZrvvGSaxJ8OojMPYPdl-gQOy5q6TKVn2H9PCeaVaVrN8cXbUKSR5MC57iBJ7ejDrEcSYCLRhUc6f6AjAuGAWUVsqo191HKr1Art623CCy4Jm3s9p1vS6w_iZ8bpbV8p_lz-TOrSy-4kIPbVfM2ldi9uMbKQag2W0_EdDPzuGCFxBvsaTzaWhH9qA4Bz1a-DETJuRih1gFITjONTzQijyQAnVqSFqyaPul1oPkXOP3fT4WXY5jA98VW8DT9ulbG3WPC_cnxzMg_IwLalgJ_4FBWrrdfrSsapru0yEe5JdpJmNa61Bi1xV2ER4YLCJRkBcJIVQuirOuRG-z8Hrzf-uVHyy6mhbG6laWCP1a9ol2Ztj5AjNr2x1lqQxBdeYZ83MLmiQckMPZrUU46CKLYH0Npst8mTdtRMFb72UAJ_ZnP_DW7U8Q9Pq31iQ_AwU" style="width: 45%;">
                        <p class="caption">합성곱을 이용한 학습 예시</p>
                    </div>
                    <p>
                        <br>그럼 CNN에 대해 아래와 같은 의문이 생깁니다.
                        <ol>
                            <li>합성곱(convolution)은 어떻게 계산하는가?</li>
                            <li>CNN을 계산하기 위해 필요한 것은 무엇인가?</li>
                            <li>CNN의 파라미터 수와 특정 데이터에 CNN을 수행한 결과의 크기는 어떻게 바뀌는가? (공식)</li>
                            <li>CNN 계산이 가능한 데이터는 가로, 세로의 크기만 가진 이미지 데이터 뿐인가?</li>
                        </ol>
                        위 의문들을 하나씩 살펴보겠습니다.

                        <br><br><br><span style="font-size: 20px;"><b>합성곱(convolution)은 어떻게 계산하는가?</b></span>
                        <br>합성곱의 과정은 덧셈과 곱셈으로 이루어진 아주 간단한 연산이기 때문에 아래 그림을 보면 바로 이해가 됩니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">커널 혹은 필터라고 하는 것과 데이터간의 곱한 값들을 더한 값으로 결과를 내어주는 과정이 바로 합성곱 과정입니다.</span>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSeme0-UHskAX1RSrQtgOG5Rw2tjfyGcol74uCEzajhVBrSZ6LpenIXis9Ui--t8GVHmXZ08Hwl_hqecvrtqA0T54qASr2uHzcBBZ7SiFhKNKsfMjsHdb5y02cXhSNXbgm0ccHd11dUA8jzzEg57wdfCKo_NqzjmILCMrGM70y6GYo0E6evtiej-tmuDQfTE1vIH35VPSOBxgwZp2saBMDDAgdju7-cTpTZFVxRdSC6EppefpugsJ5qHs8KWdqJYpzqQ9K6wGsX9VqoE0tGZXHukdtqUEl4v8iMOsk0HCiIW1i1KznWKGvtjmkrWDiSGNs7fsNQHFV3m80KV4NJ7ilbC3XOz0hO-nbJm1H60bAd8Hm3HB49iFNJFeZMWiEyC6bsHieKnw_28ybzgQEJ-TG9eb0QvZ1IiAIgddkAvs-cs4aqHD-V11oe-sRQ5X0ELm1_CaRp9PZVDc0jTRouKCshi2BawVW4YPiw-bT7RXBp9HxpDoE4kH25OFpLaH63BJ0aNcSJaXGUOIJ3R8Hy6W1FE2GlPg1CGp2fgWlqjg_Ym4eEL1HGbK-PRnaoORS1o7Iv2WaJkaBXz_uNRGqlwXxoMz1VdUTbzskJuxkbgW6IGY_4Up_HFf5Ovgsq4Glc_feZh6rHwx3znAPLVvPJvTVW7iGFBRzoB3CkphvGy-96seYy-SdY7Fg16Aptf79uEWD6m3WxM9NfUZigh7BsN9pn43w78pwOqP6Jw70kwAJdIJfTNK1NMvK2Tg2fGuEK65v8gb_855qc5OWBL3yeZkOvGSraep1oy-RfUXfvLhkRrFAhVOTyZ8vg7woi3bInRTNTPDbrALXJhw-CFyxbMrDWOMn85KwmBfDUWaaVfcWocFX4OjUJ1MuKwNp14TkfZIWUyiWABFnlVDVR0bKeyzMkfHkK-1Dji1uyP9qiCZxWDCNZN3znx1IPawdwE2NSSu31LMFUNKYUfvx7uKk2jwIZ_OI0jCexLfuX_rf8YnE0Xom22zsai2Jf0IZun0xycycmzj-CIyLCvL3WCJUkcBeTn3n69QPKggP5KS03op_TJESpQTrMFqYS-HanSMw1l_IoMfx5SdzMAudMGF8rIy7VBf6Jdtsm5j3kkFuNvFzEBso0luYL5-vZKUKbJkjKt-UNkuZJeqGpP5gqoqVWTcCNu-GxHavdpOuhIe_-pdn-omb5OM1q8SKDOsx3r7g_RHgnxTMUvLr6L4CmmymKcXRgNdlLjT_FByqqlSPa0V7PFzSjUv-v3w_g_pNoDDyH6FHsZXpAxotRP_axe-4FrA6tKzBSAAx-n2E1vXOASzPTgtUupZ9YKOr5EAYChbzHjzHRoIJiKoTD21tcndYqpauzqceby6mq2mj0sK5CFFXu427jH5QPbUn2L1kKnBwjGiEqPOJO_O-I0cO9Ry6iutaqeDlBDb18RTK8MWIByOQRrbzYnXRXBfD29E_s2PTHBKzpeAOSVGWDYX5C92tHdIR3L4" style="width: 100%;">
                        <p class="caption">합성곱 연산 예시</p>
                    </div>
                    <p>
                        <br><br><br><span style="font-size: 20px;"><b>CNN을 계산하기 위해 필요한 것은 무엇인가?</b></span>
                        <br>이제 합성곱 연산의 원리를 알았으니 본격적으로 CNN을 학습하기 위해 필요한 것과, 파라미터로써 사용되는 것 그리고 파라미터 수는 어떻게 계산하는지 알아보겠습니다.
                        <ul>
                            <li><b>데이터</b></li>
                            먼저 CNN 연산을 할 데이터가 필요하겠죠.
                            위에서 이미지 데이터를 가로, 세로로 이루어진 2차원 데이터라고 하였는데 사실은 총 3차원입니다.
                            <span class="highlight" style="color: rgb(0, 3, 206);">그 이유는 가로, 세로 그리고 이미지를 이루고 있는 RGB 칼라 데이터인 채널(channel, 혹은 깊이)이 존재하기 때문입니다.
                            따라서 최종적으로 batch 까지 포함하면 총 4차원의 크기를 가진 데이터가 CNN 연산이 가능한 것이지요.
                            즉 데이터는 (batch size * channel * height * width) 이렇게 이루어져있으며, 칼라 이미지 같은 경우에 channel은 RGB 값이 있으므로 3, 흑백인 경우에는 1로 설정 됩니다.</span><br><br>
                            <li><b>커널(필터), Kernel(Filter)</b></li>
                            위의 그림에서 보면, 커널에 있는 값을 기준으로 데이터의 합성곱 연산을 수행합니다.
                            이 커널은 기본적으로 정사각형 모양을 가지며, 사용자가 커널의 가로와 세로의 크기를 정할 수 있습니다.
                            위의 그림에서는 3*3 크기의 커널을 가지며, 사용자가 마음대로 3*5 이런식으로 커널의 크기를 정할 수 있는 것이지요.
                            <span class="highlight" style="color: rgb(0, 3, 206);">그리고 CNN이 학습하면서 업데이트 되는 파라미터가 바로 이 커널에 해당하는 값들이 바뀌게 되는 것입니다.
                            당연히 학습을 하며서 데이터의 값을 바꿀 수 없으니, 학습이 진행되기 위해서 이 커널의 값이 바뀌게 되는 것입니다.
                            그리고 커널은 학습 데이터와 같은 깊이의 channel을 가져야합니다. 즉 커널의 차원은 (channel * kernel height * kerel width)가 되는 것이지요.</span>
                            커널의 가로, 세로의 크기를 4*5라고 정해줬다고 가정하면, 커널은 칼라 이미지라면 3*4*5, 흑백 이미지라면 1*4*5의 크기를 가집니다.
                        </ul>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemc5kRqoVk1MRO9wfGwJpCl561MePrdOK-dJe_JL6Q2O5nQNvOsH8YO9_TWnSBDAWNslYwHt2eWTOrl-5lY7Fa2MNnNYaYxBwnuOijwAd1o-mubW4x6xa2zkqFWQmxthaeUUEpHVhVGM-8X7_Mf6b1hUxP1AR2GCLD8ieCYnTpU-aOJmpx12dH3DAEQgJtA2NsuXWakaiqh4z0Y46uqyncZO-sjYKgH0wFLIkw1DhR62JtQeAxj4BjB4F7muDTtcEO3utMvqeBoh0ZFGT1Dnju_otwWFheSdCpj_wFcWCqgYOJlTFN3cD4HnTPtdx9CEVolxnPMAhu3ozcSlvIQ5FIic2U0-iyOHKeJL0s4fGzxiftexM5TJBQyIHx0lNm0Jvx_SOuqpl3mbnoeSLuxmHvhQgqfY0UV9eiC_iPfSMRqCyHeYrtATfvzzkC1M12iLNJNjQBJ9Oh6NxmUo_QwDYMwezRVvvPk8HBRWLOptLY_WvuQUfyV3HymeQaF-cZBR0PpC9UXcJ9d09m-KV0uRedofS1zA8vrNxZ6feXfyLp4a8I3UN5SpjQFh1VnjWf0N-ClGfuJlbZgKyqSKTk9m6DGdLzvmt3yLF7LQnSCFMa8i6jRhW_JAnAWoItZVApXUaygOS1PGec4EkX2ptcygInet__CacDKuPdiVvMAI7WUogeR8JSt_qa_PKHLle9cPyyumZxnXVGHyDm8YVHvgX7HoK5MQjBymkLjMCTToxqhYJTdAAGWAVj7lj6iDpHgDodCu_rP9067Q7f_9yjcuH9v0G5RUcu23pHMSFTQdNAZd6TMhPQPU7P6Xi6dkapD0OQGjXJ62fMJXClpzale0uo2DZMavwKOiNRXSHplOdf_S5sNwC2ySv9ZtmubSQReGtrgJtYidX5Zt2mHVyfOASV82oUNFI4yxDhgaZJcMWZsqlXnSrKP6HzVAOvK59Ql06EuommLHuRtOd63KiTjBz0W-h0O8nyDj6jEInwVzC6DjDb94U-8ampm-WVtNvArm5PZWBUSg-MEXwxEDcAhwHH8pdRV-sPM7ZkjNQulSkcvBHtwK2Em10bkc-46FwYGFjDN1Reb-gctLAK5RI2FrF2keqtHvxGR0js79SWZWif8PO8u-jo_uDKT8GudaMgXJv6C1E8-i9jA4C4WoKiJs_zfaYTgNq_KVC6otwolKqWGRzKCh-27QBQedEeKgA-v4vucTaSC7PUpYAg__Exrwf4NhiVFrph6yXmfAVCbuhKiA-gjxEW39WFSXfLG6J1j7tIauxyfnUCwKYSAqMxUajBjwSLzyav4SbgnXgE_PSFi3VrbSFmqqJPyBZVjUx9_PjjwR9vlmerG5pHfaMqhSwfcQkvuXe-fBWZqiGsXNB_4dzQb_iiaaWFDwDG-mHK4yunbVPyCAQY2l-1V_oxmPhZQ7CQpxVcwx8hP9nusWqJdzefwNyulQFYvELF5XwzfVyymuBddTZOryykHAdbgtI8I" style="width: 70%;">
                        <p class="caption">데이터 칼라 유무에 따른 커널의 채널 차원 변화</p>
                    </div>
                    <p>
                        <br><ul>
                            <li><b>스트라이드(Stride)</b></li>
                            <span class="highlight" style="color: rgb(0, 3, 206);">스트라이드는 커널이 데이터 위에서 움직이는 간격을 의미합니다.</span>
                            위의 움직이는 이미지와 합성곱 방법에 대해 설명할 때 사용했던 이미지에서는 가로, 세로로 한 칸 씩 커널이 움직이는 것을 볼 수 있습니다.
                            이 경우에는 스트라이드가 1이라고 볼 수 있습니다.
                            만약에 스트라이드가 2라면 가로, 세로로 2칸씩 옮겨가면서 계산을 하게 될 것입니다.
                        </ul>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemdjqQ18AnSRgKmWjQC5Ianqq7Wsy2Jn5RDfrJCmh5-8IJIYRSCThsJKmuPt4-R60EgdRETGtvk3-K0_5xMaZ3uBruYMCdNLpC783EjZSFu22y3RM50D8G9ZYE0nqufgCzBQU-PrXcCvxw7UwxMipJqBCPDzWlhsISJclYKuxDM83uG6XvYD1lzWMnG07L97LJGTqoJTIac4Bui3F74FPKO5GEQcyGhRdZPpxxx4tBOM7pmPr6rGTM8X_mUjlv68B5ArQtCob6qPdrYjhvtQcninrUjb-_2jm89C05XujOjrud4MgPz0Qt2KH3PXrjrPWFcFLbk9Jwe_QEJMw_Rup0P2tQCwV6iWyvH23vPFcFBfMQNbdl1E9sJJ-jaFh321swQGd_aFjDSuI0cyA9ZESE2d4v_M1PGO5xesfCEdIsqDDWxt-gY4Js1H-24Dwz5u0I1o_JZPGckDDnAz0xrjiIDqGLJUZjqBAHLS_y_KhXPER9ZtGYwnuQhamiZcV66TPLES7_o8UY1uXtxZJuN2-wvt7FUAJWB2_BmL0JtKyQ9GoXqeg8tD93o3UGkQhuYTIOq4B9E1e_uyiHNuke9q5Bcv447_98T69o5ztWbROxCpWp8mbxy6c7XM0wRLilUlMNgo_9nyixZSRGMhzTI3SW7R7RzFZWU0DnMt-fVOFVgURTsmUZ2O7oicNSqsKK9dyvExjQVnrmK5ZTcrGBMjv8XfF_8cpkq8usqm1-LcRBqkjB-vorHfBoN844wlTkS0xb19PQnzdgXdwYQScuVlph8MbcFkZwJb4nnQSxvFDSKbpIjBrRlezoPMcKSMYhvM9X_u526oBFffra7pJ5RCyByVNVbAL-ZSuXVODK_ko3ITigZz9LGWqTUI-CFZ_C8xf_e0oBLHZzb1LiAvym2OwFLFa3V-glGFkIm8edKT6u-JU97LiGnuQf5FxN6SrMkCuBScb08zfB8BharPdr4pyOjNJJ5OBdOwm3ua1onxSlKMtI2jTLYVgYvWnu_nf5g7a8p4VsktZ3PvyKPyFCYk3V8GX304AqX7VrZiTbw2oWyLbuBDXUhKOdHAHFOCYbyEGyC2Hh8F4Ah1WmwcH4fxFCE55TK5lN3_Lad72Q9AHOBkGsfv0UIXHqgawCo_DzNhyUEpgyjQKeecayGxGBrmKGYzpAo3xhqr-m21WDLWaJWJGufwmrpXQK2wPcxUfmskK6fAWG34Do_dBiKIvQiafLhDfEwZnj60vuaRKjNfIfzgeIwMoIq3rytH8y_ED6GVSblduoTVphFEMjkkAGvkJlxFnWy_2RZ6mznJFYmlwYVteXzz-x91YUxGhdumzyWRV81S9qbsq-Nxc7iv1jAHJIlirHj_6NESwfnMWv8eY8kkCw69mFOipwYOmYE8qdSq7XKzLdqSHsgvE0xnPituaQ4fX8iEAw4UwxB39D0xwfaXXBsaCWJh4hZc-9JyZmc59LLs89RAg0XpUwtrfNzxHXg" style="width: 35%; display: inline-block;">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemct9Iebj0PNnNT6HtcFQhrgqFu-MFpvT1BaC46DOrowQvH1duN4qmKBVX0KojNP5JD7tSBQehVgAu1TX3CZtro4pahgiznJSpvT29mhQjPqto3v1TWzrGsr47hF-Rp8veJ59wTG5CDaooAPJO0ObXYNupTvcZ0IBLH_AmSyggTFIlQR6J_1Iy7qEPwWLFJVPFD9_8RHjdIbrVYCbEoe77hQpl7iJU3z6IOi9UHM_Shm9HzSkgybdVQCyiint8vRNqFRNbN70eqF2xMruaaz6Lg7OjbkBPddEM5R_kyd32NnWkNu9mei2vOAbi8QDi3dOLEwzsgyK6g2Vc7Jztuei60GbwtWz1LCzpl_p9GHR5TzpviwNsJGmc4qZ8vK7DbJAqSwIALv0zhb2NXrGM66XuvcSxQuXTimbZgHL2ZeeciDJrtTM2RNOouGUZghDCMNdCdbzUPjX9wWmIOg1F-XqpHRkh_oslBaLnLeq2h_Os553avIHs-n4qoLtDtvQJjN7K-FmZlI4Gb02vc_PjGbGdd2gQtPvIrDMunCYbZbitAPfCrzBAA-m7py18NmIL7bRErSERSobpNOkxul_-qrdLcEm0pr7rUfRO0oztbLARBGzD9Xb6RRneAI3u5naUQI8WXNMQ61TiETguydefRzXjsZ689UqM_0vp_u8u-XQWF_Royi0msDTzm8WaT6BOacnBF5Ggaj6Q-SYnUjDNTPCeFCCFREs2DhDnIcN0CI_fGiGr4_tiV2j6C0Zu5Y3VaBEn-0vZuYACy0JzGE3qa-Kb7Us7O9yCW8QvXOKb0uAlaQrUX6GZ82_iBWPkJ3PZWhZdsfaaYNl5L1fyvyWENhhTMvR4hxFFcegqfc_cxVnmrTkrjAqtjC_Ba9Ga6foP25jPv8ACF2vNG2O8jcd8OqnICz8gwdoUUA27vCfmQu0OKztoh_Pt-LJc7FrEemPPGU4OA5n8dh1T7ecTd0toHOXIdchQIlPnSXtbf9fNkU79c84FweJk5KLrPtPvbHApd5ZJrXe8JW_XbX--f_wWZhoXQoUepPhg7aG_uV5jFf7tUfeZXuurajOyyBEW1m5z2NgMPwzpeC4TAQy6VHV6Vi1a6eBGWyiEQWdyqtbrKlnl_RartR_wv16l6zdzDIoNL9sm5-1wlzJPfuiseDFPzOSAT5PqmJtaQwjoYBQygvEdBPaVav0oe7YMw3V4GKaahDcz1h4gONp06sZt-gvH6e_u0p1laE_zGCfcl2tUufBlzadXV8uaJoL8XsedBq8NIclkY-g-KZL3BuNdhzylZVTmt78aVpCgBC0-zn9yKdgvPkOnoLpL-S5KS-JjYzVJZXX_OstfLX8y_oOKTYq8KSSXybK76C0LCFkuR23enWHTCkJw34K-VrnXbsYFoZQsFeI6IW9azV_KvwitmSaPQxs7doVkT8rRAH7IHObyfzN7Q4ug6sVsXm70EBkbKj-_Z22Ugv1XThw-SLS7qDh3dcO4g" style="width: 35%; display: inline-block;">
                        <p class="caption">좌: stride 1, 우: stride 2 (input: 파랑, output: 초록),<br>출처: vdumoulin github (https://github.com/vdumoulin/conv_arithmetic)</p>
                    </div>
                    <p>
                        <br><ul>
                            <li><b>패딩 (Padding)</b></li>
                            이때까지 살펴봤던 내용을 보면, 합성곱 연산을 수행하면 당연히 input 데이터에 비해 output 데이터의 가로, 세로 크기는 줄어들 수밖에 없을 것입니다.
                            따라서 몇 번 안되는 합성곱 연산을 거쳤더니 결과가 더이상 합성곱 연산을 못할 정도로 작아지게 되면 깊은 CNN을 구성하기가 힘들 것입니다.
                            이를 방지하기 위해 패딩이라는 것이 등장합니다.
                            <span class="highlight" style="color: rgb(0, 3, 206);">즉 input 데이터에 대해 합성곱을 진행했을 때, 크기가 줄어드는 것을 방지하거나 덜 줄어들게끔 해주는 것이 바로 패딩이죠.
                            패딩을 함으로써 데이터에 변형을 주면 안되므로 보통 패딩 값을 0으로 설정합니다.</span>
                            혹은 패딩 값을 바로 옆 값과 복제를 하기도 합니다.

                            <br><br>아래 그림을 예시로 들자면, 패딩이 없는 상태의 합성곱의 결과 크기보다 패딩을 씌운 후 합성곱의 결과 크기가 더 큰 것을 확인할 수 있습니다.
                            <span class="highlight" style="color: rgb(0, 3, 206);">만약 패딩을 더 두껍게 씌운다면, input 크기와 동일한 output 크기가 나올 수도 있고, 혹은 더 큰 크기의 output의 결과가 나올 수도 있을 것입니다.</span>
                        </ul>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemdSRIpQ9Lmtf4HCe37hLnhJO42KQUbEd1WMwXODZu5N9PSE8gPKG7X5ZRJP_Obm_rb55V7eSmlz0uG5F6AVF7WlKHF-lzXaNcnGX62M10FA9XspzoEdgM0ScxdsXkAZABELaG5Dz2SL4xEScW-6Hc15oVA7xPrJi9oKWNjhaKQOpB1TBFVOI-yyfpIOQQVlh83YZ7xJL-nz2M3yYEnP5n3StZXJQzHYtY_yRdsYPhgYeLLp5JiywFfB1U6aYNWOnGg39g8UznYkNq6STzSbSSj-ajJlMG7n_E4fNrX9yspKQQQOpy6ub4-HI3OcJrK1-Epb8R77EWV0kWEz2enr7-Eom6KrXulhmpWCVgvMymzZFKr3O3zlbcL4MHFr7rMgQYkRXdQZZf7nko7BM8042FxidGUJ7BzAW1XdZPfMd9xi9I3MIawY9pgNXuidLXrAoKzdJ5irmZdNaqhBefE7NbhM0Cn6PI45G7e4Kjozwej6BuQScmpOBHFouaVmpQlUGJ5-4SmJ7f5uCRuoBxMJc_6T-VAJEvyAJj8vWBlfj3481LCxKjN7Irg-z6tndona8-fXhPO54d7mXyEgZvx6p83jr9nG4Od6QmZKy57ASo-T4JQqUfEU0qIhDQpFRNYqEOu0YB8kDVMkxyR40cNA_Ndn0D-i3Kk3g1WnAPiVLiGdVIE7aba2_kTS6TNW9IDfP-ZSQ0FtdUgQB-6hXwOC_p6MSZg7Nk7WGTAkbnY5uIWzA50_7fWgw5kcpvNiIy9ogYG8DLI-0qCyT0OOeI6jX1ecxlsc0gmpN7P_TgCnGuXd2tzvSpnEOO66UY3YB-WsagIdwnKMVFm56M71ar82VEa87Nsgec9hqmCpIMiP6Copc0QSuW4OMPUMhzCr8MzJpbdiGWEN5ggj5YibU4XptM4MGWJhUynJ7P9FuA2alkTtx_eAzvdGi5L0x6XdJnf2rFKukvVLKE_dBB4o9UfWaKYV4DK9YqC6TTWfZGO5-pUNE2FK31LvE4Fa-loOjLrOOlIVtkp702mp8W16qAn5qzzOkmkMOqpXMJHfryLy4sXi5X32mwPqmRMwCcabNZ_JPAi4UoCwmEscdHkugUUhPVl4yiJseXMOcBt02MKMiYpD2TzmLvprOAoBR8K0ViXceYWVYZjT5cRUlXdMRW0SQmmKI5zb71URFYxUSHWhTcaQwfim7z00954_OEeQi1DQmLMiMIKJ89S4LDvlOU0AI3zgE9Z3UF3vW2XPE8V_oy7Qed2TVKehqqGsz32I1H1C9C2q9LEQRzBRlUIpmxJy_TgoSs-PdA5PfIsXrUJKTFlAeU4rkpBD0OreEGNuDEVLFo0G6ojn2AOEqqEQQw3sav--QQzRPswMvmopLwNDC1h4t2IBF-sdhkvBWFXFDPF2cN9FRereWZov6JcIyAXqbUCdslkJtQTqfrh_isi5dvPXiHvJL1mSjjTFw4FKbuV3dZGdhANWLiHZNn1JEff5d-4" style="width: 35%; display: inline-block;">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemdeCIBnBp08IMauczfDkNRbXYGK541ZZnqZI8B-Gl7lwbKV_psHqtxSEA9dH1Kh1NWmvDcwQQMp99h1JrNQXHkJyNsS5BaE3xI4SGMXjHMuZk9ffhFQNllG8UTRSOMt4t2611x5IdHK5hG0m950ezBF5qbdiy1Hngu-oNf5T7eQfW2uC042zueZMPEiw74pYz-ZHzgO3brbr3ZSU-rn-ejPp-PCaMnlw_6FgAOaIXzD0tmu6gBabXQn_OHi4UfCilL15HxnE39AnKaI6Ze1g5gY1cCQiAVUK4RldW_4E8vnTPoZZSizKzCyh7VmgryK3nnGunhRIXh-b1DpMtfkLqryl8TZdlZpDivtNYYUxhXyW1H_NR_pn4blJa4wUzCRXa-04DfeQlZONxXsPt2Pl6OG8gk1KNR-kdK-8tAIPVTClGpauijBdnhVj0fT25yTiulAyh5Wx2MsUGG3cXOI3JgTsiIHlc12f2muVbVHohj_Vu4ABBs0bSaxsuaOGBBuuHa19Eta4hOou0qsoYs8rp87EcBS7-k6TsHzTxyvwz1emCOMpy3Aq-Sqqv0jbf6j0zDSFrEsyHSRAhobrXEyc_SENM9aqcpfKGmEUkPBy_Y4qqhbnsB9n3ludXTLzsHi16qX4boUsF1tkbgRx_Kf-FxIJP__2_HvJQXZLU8S5jd6lLTTF9dPqr7QSh9sSsr-oGxFctrfZKVZzIEun03PFG3ZFIvW_m-pkZxp0aJRTONQgDJ5PhYTnfhCHGRRYInOj-h7rmHR8rRPU_EaL78kKe_HnftrZjQtFs8wGaL2kp8R0PQEZHTln89wu3xJQ5X6nRzilHC7Fzqyf7o4pGNlk2ujZ3XczEdqnulUt6IRCSheV6z-Ci-XSHpQIAzhsy1HHDoLXwdFEJXV0Ub28XARkwO1yqsAF3-5P5Byfy_CBuyvzXAlT-9MVGoIiPcjweIOaMkDBTgO6rv-GRGdV8pUpjB2WWMBA4AEyUSTmDGqX-xQ4oCdHASS2Q_jq2NSJdPedXEtxdmxQnzfGzFg7pGbxGkKojVojjth2z6uUyhCAYWtGnkhdN7GmkyZEvrs4W8CNj1TPJK3zt6GuRqGzJ8qT0v_SxWMQzLaR_c9oiOCCA6PCm4w1IUTdOSySeCL6ix2f5B50JZnFyhKMMmroY9pB8FHth9gmh-slOskkQvMfzfQOAnufEClGsO_tbfNlyRMJ-oUGr3C8-Jd6BBzumDUdAlNvMZCGq5HdoouBLyx4mjrLYZQ0bg_xp6F1IxGoxp2xJwxNphASLz5cO8rPakvIfEWiNDaO4yEDqzzRpYWtPHMO_c2r3Q93CtWc4qSaS8wwr1H7hVLZvUvNAIhnabIriD1gk_B_RVnH_Wh9oIXJLP_oq_U1zPW0QvU3KTvHv8GCHEUzvA_wv9_Sv0U6dIngGOw70FaZbdFuHmljA9VX3uilnbKYEYalf-DZJwyHk5Tk7JImJl3vEukGGEEv-214dg" style="width: 35%; display: inline-block;">
                        <p class="caption">패딩 유무에 따른 output 크기 차이 (input: 파랑, output: 초록),<br>출처: vdumoulin github (https://github.com/vdumoulin/conv_arithmetic)</p>
                    </div>
                    <p>
                        <br><ul>
                            <li><b>풀링 (Pooling)</b></li>
                            만약 input 데이터의 크기가 너무 커서 아무리 CNN 레이어를 통과시켜도 여전히 output 데이터가 큰 경우가 있을 것입니다.
                            이런 경우 보통 커널이 움직이는 stride를 크게하여 output 데이터를 크게 줄이는 방법이 있을 수 있지만, 이러한 해결 방법은 세세하게 이미지를 보지 않는 문제점이 존재합니다.
                            <span class="highlight" style="color: rgb(0, 3, 206);">이렇게 데이터의 크기를 줄이고 싶을 때, 모델의 사이즈를 좀 작게 만들고 싶을 때 사용하는 것이 바로 풀링입니다.</span>
                            
                            <br><br>아래 그림의 풀링은 2의 kernel크기를 가진 2 stride의 풀링의 예시입니다.
                            아래 그림을 보면 바로 이해할 수 있듯이 데이터의 크기를 줄이는 역할을 하는 것입니다.
                            <span class="highlight" style="color: rgb(0, 3, 206);">그리고 당연히 어떤 범위에 대해서 얼마나 움직일건가에 대한 kernel 크기와 stride를 정해주어야합니다.</span>
                            그리고 pooling은 max pooling과 average pooling이 많이 사용되는데, 전자는 kernel 범위에 있는 최대값을, 후자는 평균값으로 데이터를 퉁쳐버리는 것입니다.
                        </ul>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemft1SXDmgafWo133QRsQBNTITgIGH7v_hMkfvPtqjId6qvQ0tQvf5tBd2CM-IZoXIcgKAGzG4XWYxogSCPVSaSnO055aD92Sp-qHEv0-Bxiku4L4NOs2cZLKhcM4_sycqzbcQM3G-TxkkbZz3paoyttw-uzdEHSKc3rtJvonZpfbkEiFXwgueoAyxgMHgrlE09F1KjDZvSN0nu3PwRVpkMMgZbljKofqSMKTSyVaAhUip9NPAdYwHaG8K0gx2N4Jgln-to53PLk_VMkPgHjlH8PsStS6Fri-QW74dMN93uGoYxQU6DsVg6VmPl2ew5TnD9Aiyck3W88AgWkwbUSTrMkH_2AGG98nPyL_b-iFUA6Nri2xsssxS7D2r8QOH5SOIU4CtvQxdOOQx6ZmhPwZisvx1d0r0JORFwoXm_1aMjvO5k-sk7YRW0Mw7mBWAZrYAH9i4cQKFZ8v3j1htsuftZNZxWOUck7Bo8V32QfKRjkqMUAyBePayyf8q4TXoUx8CIYTX9ZaCWGQztP-AshgbegWjOYZBqHiM-gDYPhORT2KIxerK198NU5AuFIQYAlpEIBFdnIeL-ORSBbMchSOc5gNXlsMCXHDppr1kDQIQVy8a5lV8r_1RjMwgxdsTSCvWzHfJVoZ0WoVyTcgySiPG4NMzCcf4_bOuyCQVG95DXe_OuZ3kg-XLP32o6t1bx0Gu-AEdp1yFf8kX818-djh1xjzl91hQaAS7c4d9AE-yzScoqlPGBf7nollInV5AfGgvyFvnTrhFMC_HCmR3aUD_CsL1PTLd8EDKKkjK9jJtP7y2oo1Y4dp4Ub4At8VVrdkglgkca10uMX_8huG39TBG0ul94Skf5VRtXnJ_oj_MkRDYeEVoEqpwn8-6Z-cWgvgMaZTfZYuF3xLr7a6fmjs8e7r9THR4BHa2jP7_upnchct6mPkIyfa7eyZwlHlU01bjCXlDj2YTf-jVg5ZFN1vxCP6IhSMq8vQxdE2FA8A-Lt92_saghJTKGDiVCMC4fsot_cru8dOaCx6J9eKmAcyucuTawuWdD7f-lpYI6WrtKiXtpT9Esl-hMe5z1DMROJEYSelQXayx1VzHXHYRCkkO6tQwpAEbXvVDTCAS4XPxsxIGXY54vHvSrfIlWJmVs1P1Xr0wN4kTwZk2Q03u73E9h5oQyr8VhWLF9UkGbjmx1LoNHBjLvVoGjBHn9kR5XD7W8H0W1WZsK767z7SwdEJ4wbTpJ2Vyj9-6uM6E-FNbB43ZlE0NrIvyttcfi_v9RSoTi0lksapL9Gwa93EXiSL5AD6nmqOOol1-U2XmXliM3vWzq5peS6qHguc8mRVeXyPGKlH31MoT7yXP3WZZ-iPXS51tUeL09j7Pz6Of0E4JplZJWGX57xvc7_PeTfoXgy7CWza5pLoMwWmLh5eZdhFIGJpzsWoGqQjOw4oTCvSEsiYjxf5Oo8-snKCWmufJMc9vDgrg-SMVaxldRKowSdm_8" style="width: 50%;">
                        <p class="caption">Max pooling과 average pooling</p>
                    </div>
                    <p>
                        <br>그럼 풀링을 함으로써 얻는 이득은 무엇이 있을까요?
                        <ol>
                            <li>데이터의 크기가 줄어들고, 모델이 가벼워짐으로써 메모리 등 source 절약이 된다.</li>
                            <li>풀링을 함으로써 데이터의 크기 및 모델의 파라미터의 수가 줄어어들게 되고, overfitting (과적합)을 방지한다.</li>
                        </ol>
                        첫 번째에 대해서는 위에서 설명했던 부분입니다. 그럼 두 번째 내용은 무엇을 뜻할까요?
                        <span class="highlight" style="color: rgb(0, 3, 206);">풀링을 하면 데이터의 결과를 줄여줌으로써 데이터의 모든 데이터를 사용하지 않습니다. 또한 학습하는 모델의 파라미터도 데이터의 차원이 줄어드니 개수가 작아질 수밖에 없습니다.
                        따라서 모델은 통해 적은 파라미터와 적은 차원의 데이터를 통해 의미있는 학습을 하게 될것이며, overfitting이 방지 되는 것입니다.</span>
                    </p>
                    <p>
                        <br><br><br><span style="font-size: 20px;"><b>CNN의 파라미터 수와 특정 데이터에 CNN을 수행한 결과의 크기는 어떻게 바뀌는가? (공식)</b></span>
                        <br>위에서 첫 번째와 두 번째 의문을 살펴보았습니다. 그럼 이제 세 번째 의문인 CNN의 파라미터 수와 input, output의 결과 크기를 어떻게 계산할 수 있는지 보겠습니다.
                        <ul>
                            <li><b>CNN 파라미터 개수 계산</b></li>
                            <span class="highlight" style="color: rgb(0, 3, 206);">위에서 CNN의 파라미터는 바로 커널이라고 했습니다. 그럼 우리는 파라미터의 개수를 계산하기 위해서 커널만 보면 되는 것입니다.</span>
                            그럼 아래의 경우 파라미터 개수는 이렇게 계산됩니다.
                            <br><br><b><i>Input: 3 * 32 * 32, Kernel: 5 * 5 크기 10개</i></b>
                            <br>결과: <i>(3 * 5 * 5 + 1) * 10 = 760</i>
                            <br>해설: <i>Input 데이터의 채널이 3이므로 커널의 채널도 3이어야함. 그리고 bias term을 1 더해주고, 이러한 커널이 10개가 존재하므로 760의 파라미터를 가짐.</i><br><br>
                            
                            <li><b>인풋 아웃풋 크기 변환 공식</b></li>
                            <span class="highlight" style="color: rgb(0, 3, 206);">하나의 레이어를 통과했을 때 input 데이터의 크기가 어떻게 변하는지 계산하는 것은 매우 중요합니다.
                            왜냐하면 그 결과를 바탕으로 다음 레이어의 필터와 stride를 정해줘야하기 때문이죠.</span>
                            참고로 크기를 계산할 때는 데이터의 채널 수는 상관 없습니다.
                           <span class="highlight" style="color: rgb(0, 3, 206);"> 채널 수는 사용한 커널의 개수대로 정해지기 때문입니다.</span>
                            예를 들어 위에서 파라미터 구하는 문제의 경우 10개의 커널을 사용했으므로 3개의 채널의 가진 input 데이터에 대한 output 데이터의 채널 수는 10이 되는 것이지요.
                            각설하고 크기 변환 공식은 아래와 같습니다.
                            <div class="equation">
                                \[output\,size = \frac{N - K + 2P}{Stride} + 1\]
                                \[N=input\,size\,,K=kernel\,size\,,P=\,padding\,size\]
                            </div>
                            그럼 아래의 경우 output size를 어떻게 예측할까요?
                            
                            <br><br><b><i>Input: 3 * 7 * 7, Kernel: 3 * 3 크기 10개, Stride: 1, Padding: 1</i></b>
                            <br>결과: <i>(7 - 3 + 2*1) / 1 + 1 = 7, ouptut size: 10 * 7 * 7</i>
                            <br>해설: <i>위의 공식을 대입한 결과이며, output 데이터의 채널 수 10은 필터 개수를 의미.</i>

                            <br><br><b><i>Input: 3 * 21 * 21, Kernel: 4 * 4 크기 5개, Stride: 2, Padding: 0</i></b>
                            <br>결과: <i>(21 - 4 + 2*0) / 2 + 1 = 9.5, ouptut size: 5 * 9 * 9</i>
                            <br>해설: <i>위의 공식을 대입했을 때 결과가 나누어 떨어 지지 않는 경우, 소수점 아래는 버림.</i>

                            <br><br><b><i>Input: 3 * 10 * 21, Kernel: 2 * 3 크기 5개, Stride: (1, 2), Padding: 1</i></b>
                            <br>결과: <i>세로: (10 - 2 + 2*1) / 1 + 1 = 11, 가로: (21 - 3 + 2*1) / 2 + 1 = 11, ouptut size: 5 * 11 * 11</i>
                            <br>해설: <i>가로, 세로의 길이가 다른 데이터에 대해 직사각형의 kernel과 방향마다 움직이는 stride가 다를 경우 따로 계산.</i>
                        </ul>
                    </p>
                    <p>
                        <br><br><br><span style="font-size: 20px;"><b>CNN 계산이 가능한 데이터는 가로, 세로의 크기만 가진 이미지 데이터 뿐인가?</b></span>
                        <br>이제 마지막 의문입니다.
                        이 부분은 설명할 내용이 많기 때문에 아래의 "<span class="highlight" style="color: rgb(0, 3, 206);">CNN의 종류</span>"에서 이어서 설명하도록 하겠습니다.
                    </p>
                   



                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>CNN의 종류</span>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        <span style="font-size: 20px;"><b>2D CNN</b></span>
                        <br>우리가 위에서 주야장천 예를 들었던 경우는 바로 2D CNN 입니다.
                        바로 (batch * channel * height * width)의 크기를 가진, batch 포함 4차원의 데이터인 것이죠.
                        <ul>
                            <li>Input 데이터 크기: 4차원 (batch * channel * height * width)</li>
                            <li>예시: 이미지 데이터 등</li>
                        </ul>



                        <br><br><br><span style="font-size: 20px;"><b>1D CNN</b></span>
                        <br>하지만 우리가 이미지와 같은 데이터만 CNN을 적용할 수 있는 것이 아닙니다.
                        바로 자연어와 같은 데이터에도 바로 CNN을 적용할 수 있습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">다만 달라지는 것은 가로, 세로 크기 대신 문장의 길이만 나타내는 크기가 있으며, 이미지에서 채널이라고 불리는 것이 바로 각 토큰의 임베딩 된 값인 hidden size가 되는 것이지요.</span>
                        <ul>
                            <li>Input 데이터 크기: 3차원 (batch * hidden * length)</li>
                            <li>예시: 자연어 데이터 등</li>
                        </ul>
                        <span class="highlight" style="color: rgb(0, 3, 206);">아래 그림을 보면 각 단어에 해당하는 hidden의 크기는 6이고 이것이 바로 2D 데이터에 해당하는 channel이 되는 것입니다.
                        그리고 빨간색과 노란색에 해당하는 각각의 kernel의 크기는 2, 3이며, 이는 자연어의 n-gram 방식과 매우 흡사합니다.</span>
                        그리고 stride는 1로 설정하면 문장의 길이 방향으로(위아래로) 1칸씩, 2로 설정하면 2칸씩 움직이게 되는 것입니다.
                    </p>

                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemdYKFZN0fCtl1M8uDk5IcZkFlFhQTWMTcEZB_pkwDbf0jhp0K98V0sGvBd_h4dtVczVKw5oKjduYXWimkKCtZZfYeGs4LGf9uqwBL7WA1IYDUX-CkKTttqSndGQ8Lw8gh9ovX_A9odjQsGy8R9s-AUylL6hY3gYLYQ9FggDzUVgr14vtvLnfr2DbfkbK2-5RHhWJEEm-BzvSD4C89USpfIyFWUTYhxKjNMGudwAOgqby0HFBTRCpaXdkH3_Dm1XYm4LWeJpQA8HdKMz4vKyb7zoP93DDt14UESMFWaR22iZSkl7olbUD7Lc_rOatCY_TlghMnvSPWm7YD2ZzlWgThZOMPNSh2SrKlZOlxDgPFokKnCyWzKplB95xNTohAUxpPx1u3PagMbn1am_1o6Ih1MyWZFOmeLx50VTcUx_1vrbArjODsVD7yTHcbihYI-Iw5qRUWcHTUhLW6xVWw9VfYjjH5ezA3tg-kLih5FpzK3TCgG269ap5h9YXln2fZsa4TXoZdhfpm4aa0WmzdtdD1ZrFHEiRC1G5x7VCDHj3GvQW6-2kRVZE2gajHKReLFOMKbPk-RV5hwjX0NNcz9qHuswAtlNBZ1emUeRnhPQAGml-pvGIMtNkOrBb3vjh39TfBlC87MuhpsM3nmgC_trJq-Kbu2UH9MPETv1kBufqkqqRSRlpVnt6VUrNimq979lU0cn97VaRQFwUoSu3jNtKAWaJgiSEO0wHRodl5wOE5YNshCXmtm_6xF2NjUOOUfmz0Mzb7dcDdu14SgP0cLP4O0Y_98ZVd07EZ9SGdCKzmoSb5QVmaDOh7qsARNZ3RlmFSky_gNN9ZpB-AI6RBYW28SfTkqQh8BmdHnLe255r4OOrVwYeKD39zaY3KtEFWRYsl9_8Ebx7hsLGUdfX4IakSD9Z_9dM0HR_25gVibFAPYuUZR_P8m20vbc6ydomZk8bxsjkb36MgAPCofYoFg5Knav0vygwAObgfHe6Ek3Omvp29Ii648az9kPfzPDrpbgT41D0Zyo1_SyYZ5VtJnnu5hzqHeW181jaVMucNL84VzBIs6yEHA4Y7y14cTNdyF17L4vhpGgQleN5P2C4pVTbt9smJR8sOZ3qKi0e-urvDVngBowB_4nb0z098Ma9fbwPhE2TvtMIrw9cWtOZXKCOdkgzSZnSWcvlVP7iewMf4zEdzS0ZlTCzpeZf-EzAowFD0k_l4xWHbBiQEheuVqLdUUlD5mhuCCcMNNF1qRF8tnmMIqR2d7O_kbm0O6_YFjcywCyEFBJRSJW68aC3AMwAQZKn9ePUClPNPxYslTp5gGF8fLvmnWC7ltpJQd2-t5wVVq0FhrTYMPDRmCDo47RmRtScjrfNzNVgqd-2FpZNGsi6K_CkHDB2lWP67o7UK2tzdIENARDzAmu22bu0cTrCGVUIfxEyfS3n9lfIk9BIn_J-lS4k-ARrRQ8raMykm9AGR98-y_XRPUOORqMXOwaW9E" style="width: 100%;">
                        <p class="caption">1D CNN 예시, 출처: Convolutional Neural Networks for Sentence Classification paper</p>
                    </div>



                    <p>
                        <br><br><br><span style="font-size: 20px;"><b>3D CNN</b></span>
                        <br>CNN을 1D, 2D뿐 아니라 3D에 대해서도 적용할 수 있습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">이것은 이미지 데이터의 가로, 세로에 새로운 차원이 더 추가되는 데이터에 적용 가능합니다.</span>
                        예를 들어 이미지 데이터에 sequence가 더해지는 비디오나, CT scan 같은 예시가 이러한 경우 입니다.
                        <ul>
                            <li>Input 데이터 크기: 5차원 (batch * channel * height * width * sequence)</li>
                            <li>예시: 비디오 데이터, CT scan 등</li>
                        </ul>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemc3bMQo2966xjEcEloixPFiy6BKHR6D6Z6qcuFcdEOSiiysHIHFHMxgpUH5QuB5f0Gu6X-_5wYPv6SPqhLubHDmZa59GvxHyyWFxdmrNKuDsh146vzj-rJNoOJQVt5J-A2MVSUuX5DWRzjPPz5ijtUnf4r0sf7DbbRUHVR0iX6PnP74Ip_8wCS-z5G0O7uKWPuBsWwn2YXlV8SUBaN7cw2aMru8R1kB4grNLkDghmtJvqdbkuIcDWsrFFBhYxVrNeargnG91jlyx_Em0YmNz6eAmEWM9DA1BH1y6aSYDgYOshgedbpmZvnRMsRg2abxg9DEy_D9CKFKUIkwxGwiqdMSfsSO05L_ZNfVjQDsFezyueg18PBkjGViGyoPib8wHOS9F2Manacp-OhNHuhgrO1k4PIpKuAGa5dv08JRexeSg0xYRK0XTyp6IG3txG4JWD8boas2nqk0f6DfRAcr0SXav-FkHg2B6BCpLDXUUOx13-p5ge8XVLlvx6RbmAMdsoLovzy5gOXeSxDp925x2qIVqKwyif4hemVGwrtzEnzRttFxdehjUi7US_3XUJjGNVVjOw3zCIG5ZENB0cWcY8wwZTEgDARmE_J8YiNIypk13SNEWxRq_zQWiWlXUwyzsZl6gAApWb2pkawPl91mAHRw1DZvh2D0dpUKGRO77BmGazJ5lqMUyqZNIHtflFUpWrRRx3-WGF0CbnfYTuEOqg0mBDOYc5ve8Oz_BRVW4d79J9Zx4e8NSac-n1GXE3xF2J-tENddxXc7YVwNjEXoRGghN-FmJ86iw7lliHLAHC990o5PK_A524ymqa_GCTwMdnwhIkM-9K7bAldDtwhdzabaFC-fgJURi26EUaWpnkf7XJNAHGolyOWuQNB8G_O14xi7ZRw1QYM8doCdpXk5-vh0kORCE4bYLJrstGvS0yS-0lBjHNKwJZOATch8eDxuPKomK8lu-U2HI_tzLDPcQ59ZNV3_OoQLRryh_rsCX4CWW5gu9XGS6yfRRRlKz8C3QrywYfEdio3SM_mg1Tm7gwiA8bvaUyt1-f_fN0h1BIgqX78TtR_0oNIRURKHsd4meoBx05VjUd_D1TqmmYnlwPz8KrY4f8N68ch1e0XVF3EV49KA0vbpfMF2x1UQhkIBL6xO4dZ8zdkFhL1GKxu6D2UlX0OKuE0zEz7nHs_VBObIk33qvVHXls03jR_xXqkZIwSa_CoamJ-lo4X0nj_gmU3NKNfjes4kjqYFxuBbttrS0kfTH9iXtr5zveU78_A5pyyg_z5lzv8IuRq21ZWRbe4CDqLBfCkGE23Oeb8ttgPpxvmJx_AjIcuLyPwoKgIBr_R4vZvSn9RTO1IvA__VK4_U6ftmrJiMZa9OPOZnLTWbRv48xPGr1lcjg9sWfDpUUuh29cjG9XqS94O6Up_lso57x4KbfnOApzzkI_Dn1YKx3QPqR-IQiM7ZWFGgv1xiSSRNxYn_oDci-yO0XrxldPg" style="width: 100%;">
                        <p class="caption">3D CNN 예시, 출처: https://towardsdatascience.com/understanding-1d-and-3d-convolution-neural-network-keras-9d8f76e29610</p>
                    </div>


                    <p>
                        <br><br><br><span style="font-size: 20px;"><b>2D Transposed CNN</b></span>
                        <br>이번에는 transposed CNN에 대해 알아보도록 하겠습니다.
                        그중에서도 우리가 가장 개념적으로 이해하기가 쉬운 2D에 대해서 한 번 개념을 살펴보고 1D, 3D에 대해서 알아가보도록 하겠습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">Transposed CNN은 CNN의 반대의 연산이라고 개념적으로 이해할 수 있습니다. 다만, 오직 개념적으로 역연산일 뿐이지 절대로 수학적으로 역연산이 아닙니다.
                        예를 들어 (input * 3)의 연산의 역연산은 바로 (input / 3) 입니다.
                        이처럼 CNN의 수학적인 역연산을 deconvolutional 이라 부르고, transposed CNN은 절대로 deconvolutional 연산이 아닙니다.
                        다시 한 번 강조하지만, 개념적으로 역연산처럼 동작한다는 것입니다.</span>

                        <br><br><span class="highlight" style="color: rgb(0, 3, 206);">각설하고 기본적으로 transposed CNN은 input 데이터의 크기를 늘려줄 수 있습니다.</span>
                        CNN을 통해서 input 데이터의 크기를 늘리는 방법은 패딩을 무지하게 넣은 후 output 결과를 크게 만드는 것이지만 이는 결코 CNN의 성능이 좋아질 수 없습니다.
                        하지만 transposed CNN은 패딩 없이도 기본적으로 input 데이터의 크기를 늘려주는 역할을 합니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">아래 그림을 보면 input 데이터 숫자에 대해 커널 값을 곱한 결과를 사용하는 점은 CNN과 동일합니다.
                        하지만 stride를 옮겨가면서 계산된 결과가 이전 결과와 겹쳐진 부분은 더한다는 연산이 추가 됩니다.</span>
                        이것이 바로 transposed CNN의 계산 방법입니다.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemf67szFynspbSpRCelx1-XLL_GNF3JoK70WFlSvUVINjJdVjvZ2L-IR0KPbqlsxpu-V4HARXmdwrAnTDqrwA0z1O78Yh3l78gQSQPyncIDUYFBqsuZ4Ci_CcMkI-0_xsxHcLD6c7_rkbdk-BiCg5MyOOK2fcaKMcVCuc3Op_hAAA0bEdcPKTijGTajpL_jWU6-XcbZiypQ0P23Z_AuehwlAqHJKWUHgRquIOUecahrECGuywatsORMwdvgkAcaD7F-TcJTpJ6IkImS0xT400T3HtODATYcxGO7P7QgrW9k1g0U_ZTX51FKQgLR5gY7voE4WjluzwoD866KNrwsS2wzP3EjHd_a24HbhPDA48qTFcCAHKP6YYV7uYS4wEIXXk8tiSxTcPSQ0jb9ohPBGTMx7zRI-7lT2GQZaGIQ5nq3LVj_3sqtJ-mwvOFY1lnfNk5MKx_JgLlMFxYqZYJL1DVk65awbXo_jNodmfWCh72sUx1SOvuhsSPHbXnA1nW_44kxysifygEubEecJXX9ndRqsRNcsOBdX9qLUu0G0NN17_0EH2n3uSjORCKiVpd4OfYrW9JV3H9v1BSSLJkYGp9aWPVe2aPEUvPNbE8O97dcP6u8PeUuyTH2xMhuQSCf3sgvPBliEs2svYd4v0MfjlB_H0qVPpG8DspPW6PjHDHi_LYmeQ0Tms6ee0nX9I4YhULr3f2MxRQC-tRyiD_Tjl_BRI9cej1ksJJIATYIT-06ev6Nt8FoXkOyhIMVM-hnNWsL7pNLaXCeji9Npb6tSmTktYlRVaEj01Uq6CwP25duCmCGayN58rsYTiCE4g0epXuFxFKe7bee3NdX08yvN-5K0zf8Gk_COO3t6oTcZZ9hCGSQWKXAxEPeXQb9TqViB9IRsUGVzO3zO7ed-hvp7ar0otWdZno8ut43i1W28HpgpzAB2k-aKeR-9ptN5BskM2KbAbhgFJVkB1QtgSmQ7i5Qaio9Z7Uc-JSJrXegNTRCzebxQ3kN5NR2aBTqWopNCnsCwxUEqthgvwUcCvhA2_pytg-iaYeRiUAyzGhYZTb_-3Bhn_1XVjtqCIrNdh0tzoCgRhwIzoFekd_WsoM5gy4H88NYQuWKpLSUoCAizaUb1f0sg2dKLOF02_SbrkhTOBwRs5ppsiYFL1lNUE9Sq2XxV43ve-b3o40g1goOvHPK0Rag-AiBrXLIjFZqx4Tm4fKGl3gGcaLRqNpBTRM9NPSjN9emsJsr3sfLkFgObHj0a_ddpoYS75zELV4emNOe8_c0RGBuFtRy7Ro3yemxKQp21oeYaIC1mYItaWdTPjeIgzQgbQApQJDINdkP9miuyw60jMlYKMMuesgIBGWQLQPbGTGTUvCr-_bfAEz-Jcv_t6iL4-E6w7-51iyhuFdWbbIsHTxlh_WpPft5IPMQmbWawh2GEgJZcHFtGpeEIPy6jeNv9IxdUPxv936Cv4f9C57rlFEdYD7QafanxBzwAl-Y" style="width: 100%;">
                        <p class="caption">2D transposed CNN 연산 방법</p>
                    </div>
                    <p>
                        <br>여기서 주의할 점이 있습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">아래 그림의 CNN 부분의 padding은 input 데이터에 적용시켜 그 결과를 냈다면, transposed CNN은 개념적으로 CNN의 반대의 연산이기 때문에 input 데이터에 padding을 씌우지 않습니다.
                        다만 output의 결과가 padding을 씌운 크기의 결과값이 나올 것이라고 가정하고 연산을 진행합니다. 그리고 실제로 ouptut에 가정한 padding을 생략한 결과가 최종 결과가 되는 것이지요.</span>
                        즉 transposed CNN 부분에 보면 output에 padding을 씌운 결과의 크기가 나올 것이라고 예상을 하여 연산을 한 후, 최종적으로 3 * 3의 padding을 제외한 값이 output이 되는 것입니다.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemeiaUmFxovahLWbHyvuZeOH0aUeDwQeq5c7HxiikKql8dB5NJMYoiiA50M9lGutLEKx-35SmCSPmAAH7W4HNuBGrLuA-4WZ9iw8eODURgU1HBcQ7LWaRZByofhAu2y7ggqUQnsSPZGaRlqmnBUzrmvV7zUHwmlh-A8Dd6BeJAZIscpxm392gNq_7SSpdeaNc5osFr3ycXZ5CPvWUax0x8qdjoQIPSbUa6VKNxStjxeWzu3SB9nzfGwOXM26WV18KbJ8JUMogXAIpjTdDYmm1SQ9ZS0eTIFQPbT0_3obiuix6UMY8OMFQ0oI1i8DHOZpuF6BGfWpe23LK23jr1IZXbgzVBw-zcOYvjaOwYQ9l-Pd4LHEADparS9o7FF0Cw6FALBJYBXsp2fs16pujlU3X0FwMJ8QDIAyTMaYCZtWIOdc0rZnOUAnc9l0Lxfwmx0I63A_ANXICc355y77VA2YS72fQAOwlJBBFkNH576zAIm81VZb9g30iMGJFYbQpk4r8RweXu-Z8CMD78ZZu3NnwP4JaBo508K1uQVBl4ov3feT5s0vAAsTDi-F7d73haRl8_jN8i39J37jml2Y4SpB88eo8SHVExiNKYizX_13kfRnDQ8praj7rPJH4M32aVoSGa8RL110bQQyT_jc5oLqyLdh49aO0Fqgh_1G2xP3QMe_7_0P18g2u3QwMgpIQ33mqM-HUjcuoQ_rZ643YT4E_-zC6RmgDd8xSce2_E54XXH7dJHwZFCj9pVHEH5OTbL75eyCq34hcftCybSGQ33SXHl5XsL8H3j_ZkjGnu7UyCuKUEQdYZqLO8SDRRE_70sXLarqDmOkZFjGXJZLl3swQ3WDTWlKP_h7DmWyFSnlntLd3Yxv3OkUgOV3Yoc1Ru7P_AlSbspen2ZQFhWmaCWkktK3Sck186I7Vqza6k_YjhmoM5fo5pLyj8_3u80vTO3SqOIn27HyOox-ZCJT3MH3Q27N32wH_NiJulz3jhgb3L-C4TerKS23WziQLqoTxfIzOYfgtHazzVQcD3VmQv8hcLOUQ23y7R9EbdnkHX9xZLRQ5MyLWis6zLJ9nGHaNejvEXwoKmmx_skMlQjAwGWRSDIHip1csDnxUkLRzWa4gg7WRos9qQfS2STlGw4DNFEbzSTxXPEslH7TeNBmRjAK7zXxSgiIMCcxJ8y8KOQySUa3KSdO4V8cAwzpPDEyXOIidd-WRFsBcXNI7juEKlyLaKoJGTAl6FhEPhZdqQubjV3t4Cbv5QEYCPHTF_RuLanKYyQwTq8siomHIjEqP-R9MrWwD4gmaURDwsetm1CMcwESkqdw9wTH-ZjYuWO7Vgh_4sag_lV7xC7h8u2720GHgvzTGNTMZhzldTZ_d-gav07-zsh43MxJpwXMNJ9W1S6yTTOpYLA6A8WCGIXond8tNmy_xVtd5_VjhPxucfBZzU1SwkSlj3i8-X7Qyn-m-JoCK1q6VL2cW-7z7O3LV052eS8" style="width: 40%;">
                        <p class="caption">2D CNN과 2D transposed CNN의 비교</p>
                    </div>
                    <p>
                        그리고 CNN처럼 transposed CNN도 input에 대한 output의 예측 결과를 계산하는 공식이 있습니다.
                        또한 CNN과 마찬가지로 크기를 계산할 때는 데이터의 채널 수는 상관 없습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">채널 수는 사용한 커널의 개수대로 정해지기 때문입니다.</span>
                        <div class="equation">
                            \[output\,size = (N - 1)S - 2P + K\]
                            \[N=input\,size\,,S=stride\,,K=kernel\,size\,,P=\,padding\,size\]
                        </div>
                        그럼 아래의 경우 output size를 어떻게 예측할까요?
                            
                        <br><br><b><i>Input: 3 * 7 * 7, Kernel: 3 * 3 크기 10개, Stride: 1, Padding: 1</i></b>
                        <br>결과: <i>(7 - 1)*1 - 2*1 + 3 = 7, ouptut size: 10 * 7 * 7</i>
                        <br>해설: <i>위의 공식을 대입한 결과이며, output 데이터의 채널 수 10은 필터 개수를 의미.</i>

                        <br><br><b><i>Input: 3 * 21 * 21, Kernel: 4 * 4 크기 5개, Stride: 2, Padding: 0</i></b>
                        <br>결과: <i>(21 - 1)*2 - 2*0 + 4 = 44, ouptut size: 5 * 44 * 44</i>
                        <br>해설: <i>데이터의 크기가 커짐.</i>

                        <br><br><b><i>Input: 3 * 10 * 21, Kernel: 2 * 3 크기 5개, Stride: (1, 2), Padding: 1</i></b>
                        <br>결과: <i>세로: (10 - 1)*1 - 2*1 + 2 = 9, 가로: (21 - 1)*2 - 2*1 + 3 = 41, ouptut size: 5 * 9 * 41</i>
                        <br>해설: <i>가로, 세로의 길이가 다른 데이터에 대해 직사각형의 kernel과 방향마다 움직이는 stride가 다를 경우 따로 계산.</i>
                        <ul>
                            <li>Input 데이터 크기: 4차원 (batch * channel * height * width)</li>
                            <li>예시: Upsampling이 필요한 이미지 데이터, <a onclick="pjaxPage('DCGAN1.html');"><span class="highlight" style="color: rgb(0, 3, 206);">DCGAN</span></a> 등</li>
                        </ul>

                        <br><br><br><span style="font-size: 20px;"><b>1D Transposed CNN</b></span>
                        <br>1D transposed CNN은 1D CNN처럼 자연어에 사용될 수 있습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">1D에서의 연산 또한 2D에서의 연산과 마찬가지로 겹치는 부분은 더해주는 연산이 추가됩니다.</span>
                        <ul>
                            <li>Input 데이터 크기: 3차원 (batch * hidden * length)</li>
                            <li>예시: 자연어 데이터 등</li>
                        </ul>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemeePEIN6bwvhUh-BN8K0tPVqleHD9ct3dtCjU8Puz3XNJMXd2tON96m8D2mbjgDisudZoZtZp3jjPQ4OUOI1iNkau06Ggj32EUWnmZVmb1z2cYbDMuZDB8ibsogCa87cKVZBzweD2LGRVz-aeXktqdjrSLJM0XuWxxe_L1iz6VXqv8LDObn1eA4wXZgoLrt2bLxPC0ftQTzNJ8N7SVR8-w5Vs1lIgdZIfscKwCB-2TPx82kMfeHoAIV0E462pI1VwmlfDbZ56zxKy5D3sGh8zFzVs1tLfXFnluwKuxHPBTAJm-JFI_t4Y-eqcMOAHgE_VXipYH579e-_kDysT-TmiVI-XimSY6iM7wvaf2ryGfxYuKtO82ogKAjYXKs013u4_S5yQF99YduUiLvpY10li1ZyJ3NH4Au38vidUPhwRnDbowlxm-GHYgityEdmeo40rupObtTW3G42i_M3TNxXBFldPkg2BlHuzZSJFBJZccmwM9BZ9-BV0TzfbT9i7PWlXj54wODQlSdll5_s1I4pxm1Oluw4x5g7HatlMmtViFUnqdymDMNyCVIgNtAiGBjllc1KpTX7x4PN9-UGoddUbW4GXY95vLt-AbD_tN4kAUw1SIGqfmSWc_61oWWZBaEWfoMSkOudjFw6p1uIfLXaABa-rnylSvq59w4F-VxtxazHsyYrs676Yxc3wtymqeln0IeuIZ59Ofhk6i-I9Bs0uikdi8Sr5YNIaG8yFWVb6OdpG8fjeFyn8yf-oGdxhwRcwlcasc25v5puel90u_pwq-9TRi-b3DNRijcKWxv7tW4FfoXVLb47im-Q_ClonfWyh4WHMFSnwnEiA_fKwuXVBq5yWN4N6x3_7aQoC_BSwhJ7l4ofp2jqrTqOJ1LkhOhKtvNKdZyRS5wQ1aSEoLqmQ9a13r7m2vMZz_a3rSJBvlgQIBI7cXRX_gqVRu-r_3pm5y2bFfuM_NReuEEzrPP7_Pw27cPwN-3pcaiLqW_1-wjqaerlGhuyIOdi9A_sHOORwZk-koHMHCPT940I8l85dz68dNZUd5bmSrbKr2j5y1V_VYuNDQOQg90FmxZ7iM2pt5jThqu0e1Al71Akh3W4lPtweb3zmx_kVLMURsLYxxW8xjTEQIBjSCyCACSGegJH6Xc4pxt2FR28EwQnu9BOfNRvSnuO6ZlGt78q70t2W74w2FLOplSqIsIlSo5ndpvnxGaRY15GHM_GWooSWCT-JK9BwOMbenf8wk8p0YKTKMtwUqX9h8mX05lJk7noT9o1WD5NwhA7JzRaFFBJCE2zP3gisEALqD04CyYPIfqXNkeLHaydOFgp-U5tg33TUKQe6PDYX8by0ZGQUQlD2umKGR7n_Ru5lOREm78st4oIerFX5_R31HGPIpLloBAum5HFZsPX-PPXlFFFePjnKSIPOlyjePhaHJETRgCTBMBC4JN6ESB0AUiGX76oLdZtGRsuOejLfqjbfhJxVN4ekUigiA" style="width: 60%;">
                        <p class="caption">1D transposed CNN</p>
                    </div>
                    <p>
                        <br><span style="font-size: 20px;"><b>3D Transposed CNN</b></span>
                        <br>3D transposed CNN은 3D CNN처럼 sequence의 정보가 추가된 데이터에 적용할 수 있습니다.
                        <ul>
                            <li>Input 데이터 크기: 5차원 (batch * channel * height * width * sequence)</li>
                            <li>예시: Upsampling이 필요한 비디오 데이터 등</li>
                        </ul>
                    </p>

                    

                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>컴퓨터 비전에 있어서 CNN의 사용</span>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        <span style="font-size: 20px;"><b>ImageNet</b></span>
                        <br>ImageNet은 1,000만개 이상의 이미지 데이터가 있는 대용량 benchmark 데이터셋 입니다(ImageNet 데이터를 사람이 직접 라벨링 하는 데 22년이 소요되었으며, 이러한 소모성 노동을 막기 위해 self-supervised learning (SSL), semi-supervised learning 등 다양한 학습 기법 개발의 초석이 되었습니다).
                        한창 CNN 모델을 바탕으로 이미지 정확도를 높이기 위한 vision 대회가 유행일 때 이 데이터를 바탕으로 많은 모델들이 등장했습니다.
                        그중 몇 가지를 소개하려 합니다.
                        
                        <ul>
                            <li><a href="https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);"><b>AlexNet (2012)</b></a>: ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 대회의 우승을 차지한 CNN 구조이며, CNN 연구가 활발히 이루어진 계기가 된 연구. 두 개의 CNN 파이프라인이 병렬로 이루어짐.</li>
                            <li><a href="https://arxiv.org/pdf/1409.4842.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);"><b>GoogLeNet (2014)</b></a>: ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 대회의 우승을 차지한 CNN 구조이며, 1 * 1 convolutional 연산이 등장하고, 22층 깊이의 레이어로 구성.</li>
                            <li><a href="https://arxiv.org/pdf/1409.1556.pdf%20http://arxiv.org/abs/1409.1556.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);"><b>VGGNet (2014)</b></a>: ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 대회의 준우승을 차지한 CNN 구조이며, 그 깊이에 따라 여러 종류의 모델이 있음. 준우승 모델임에도 불구하고 사용하기 쉽다는 장점 덕분에 GoogLeNet보다 많이 사용되는 모델.</li>
                            <li><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);"><b>ResNet (2015)</b></a>: ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 대회의 우승을 차지한 CNN 구조이며, <span class="highlight" style="color: rgb(0, 3, 206);">residual connection이라는 개념을 이용하여 혁신적으로 gradient vanishing 현상을 해결하여 성능 개선을 이루어낸 모델.</span> 사람보다 더 좋은 결과를 낸 모델.
                            <a onclick="pjaxPage('CNN3.html');"><span class="highlight" style="color: rgb(0, 3, 206);">ResNet 글</span></a> 참고.</li>
                            <li><a href="https://arxiv.org/pdf/1512.00567.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);"><b>Inception V3 (2015)</b></a>: GoogLeNet을 응용한 CNN 구조이며, Inception 모델 중 가장 유명한 버전. <a onclick="pjaxPage('GAN1.html');"><span class="highlight" style="color: rgb(0, 3, 206);">GAN</span></a> 모델 평가를 위해 사용되는 Inception score (IS) 지표에 사용되는 모델.</li>
                        </ul>

                        <br><br><br><span style="font-size: 20px;"><a href="https://arxiv.org/pdf/1511.06434.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);"><b>Deep Convolutional GAN (DCGAN)</b></a></span>
                        <br>DCGAN에서는 작은 차원의 노이즈로부터 높은 차원의 이미지를 생성하는 데 2D transposed CNN이 사용됩니다.
                        즉 upsampling을 하는 데 CNN이 사용 되는 것이지요.
                        DCGAN에 관한 설명은 <a onclick="pjaxPage('DCGAN1.html');"><span class="highlight" style="color: rgb(0, 3, 206);">DCGAN 글</span></a>을 참고하시기 바랍니다.

                        <br><br><br><span style="font-size: 20px;"><b>Convolutional Autoencoder (CAE)</b></span>
                        <br>Autoencoder는 데이터의 특징을 추출하는 manifold learning의 일종입니다.
                        Vanilla autoencoder 같은 경우는 linear layer로 구성되어 있지만, 좀 더 복잡한 데이터에 대한 특징을 추출하기 위해서 linear layer 대신 convolutional layer을 이용하기도 합니다.
                        즉 encoder 부분에서는 CNN, decoder 부분에서는 transposed CNN을 사용하는 것이지요.
                        Autoencoder에 관한 설명은 <a onclick="pjaxPage('ManifoldLearning1.html');"><span class="highlight" style="color: rgb(0, 3, 206);">manifold learning 글</span></a>을 참고하시기 바랍니다.

                        <br><br><br><span style="font-size: 20px;"><b>Semantic Segmentation</b></span>
                        <br>Semantic segmentation은 각 이미지 별로 미리 지정된 클래스 개수에 맞춰 이미지를 픽셀 단위로 쪼개어 각 픽셀의 클래스를 예측하는 것입니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">Semantic segmentation은 컴퓨터 비전 분야에서 가장 핵심적인 기술이며, 이미지의 모습을 완벽하게 이해하고 있어야하기 때문에 최근 자율주행에서도 자주 쓰는 기술이기도 합니다.</span>
                        또한 이를 위해서 만들어진 MS COCO, PASCAL VOC 등의 많은 데이터가 존재합니다. 
                        Sematic segmentation 분야도 CNN의 딥러닝 기법을 활용하여 빠르게 발전하였습니다. 
                        <ul>
                            <li><a href="https://arxiv.org/pdf/1411.4038.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);"><b>Fully Convolutional Network (FCN) (2015)</b></a>: 기존 이미지 분류 모델은 pooling과 같이 이미지 차원을 줄이는 레이어가 존재하여 segmentation을 위한 모델로써 적합하지 않음. 하지만 이미지의 차원을 줄이지 않으면 메모리 초과 문제가 발생. 이러한 문제점의 합의점으로써 인코더, 디코더 기반으로 제작된 모델임.</li>
                            <li><a href="https://arxiv.org/pdf/1505.04597.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);"><b>U-Net (2015)</b></a>: FCN을 확장한 개념으로, down-sampling 부분과 up-sampling 부분이 대칭으로 U의 형태를 띠고 있음. 그리고 down-sampling 할 때 결과를 up-sampling 할 때 그대로 concatenate 한다는 특징이 있음.</li>
                            <li><a href="https://arxiv.org/pdf/1511.07053v1.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);"><b>ReSeg (2015)</b></a>: CNN과 pooling을 RNN을 통해 구현한 ReNet에서 파생되어 나온 segmentation 모델. CNN과 RNN을 결합하여 사용하였으며, up-sampling 과정에서 transposed CNN을 사용.</li>
                            <li><a href="https://arxiv.org/pdf/1802.02611.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);"><b>DeepLab V3+ (2018)</b></a>: FCN도 down-sampling 등을 진행하면서 데이터 정보의 손실이 발생함. 이를 해결하기 위해서 ResNet을 적용하고, 확장 비율이라는 새로운 변수를 도입하여 정보 손실의 문제를 해결.</li>
                        </ul>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemeQk6yKvfHgoe-0-zPQQMtq6O_rt9KXKMTNK7Vb3I23pMDtVPevMkhlDa8hvXG7OSSRCWAXssEyLw2ta9qAJD_3Kej5P6Qddvt4Rw4ArUQHzRPo-fRZTTq7sXw65Om_VQLDhnIsjQsPjrypiTLC1XhlLU-Xv3pUXb9VozmCjQjeDFe3auVhUNraik3TIQQ8J5bzTdlA9XUvQOK9Q6UgHIDsky2ipCgAYlyn3Bhcv_W0Iy0cyMu1Wf5SuJE9KMVUsOhH1djyZTPpCUh_Bcpys5zqfLQNSryJG5YNyg6IDlDcNNUVS5y7gKo8H2e-mlEQXmPpbJhr_3f3lze7l7D8hhpu1bKwL-h0IdmbqifHmzgEAP1a19c-dkdRng2aUJT489Bcl_Tff1uSSZOq_6cAeFZgibiCCbqqhEgJ3VfwMgXrG8R-po07EOh1VJ4Nwwk9Hz83Qs5GHaEesUsEIAqbWzNmPWP6PyPnRgyoUH2Z2Y8PmmrXRWopR8h88sS5xE5TzfYL2XCyiWpKHEwwNQ2mtL5Bms4teUZyz0CujtUShtC9QZ76-SR0l4HK7jjJvMJr7iGd6PhpUMGfPeY4i0fZIV1Nl0WdV08_SbGkbAvjRIGIEgp8nNTx4MlpBnwAe5W-rSALGWOXVCwRfbEZK7YspA8NyAfqtDW6-vYd3TDlqkt6SF6C4VfW0S1TSn97mW3dQzgIGdFCmJWnCc07tcNRrLVlpHn1Q2efj29irDFMDT2cj5LPRr9tc2UpqsmxuZncSnzXAU8iYj_OzUV2zIIh5FD1rQu41uZ7KeSwDVnMUu2X0DL9zxDglNr335OecN2cvoAjIIf4nsfRBwBg8c6KN9-ivOQ2ZyW_Xbh3pbb7mkf44abUJHcz_7eSKZ38KCkQzH9S-8ydCflWLDzupFTYzQaKEu_hq-BzcvYHynbfLCZ8ZyOgUrpxfrG9_pqUIk5PUoT-W9hcvSd8d33iVNncYjVZ725csVQy9QQFJrOq3F10ps2cJ583bjXK4_jQbVvHwutplshus9z6DIY7tm1LA71P2LQDpQgOxlvzzBBBneRUEs_umAcUxPXeDbTwVdkYXdd1Ivqvf17vsFdQAJDs2lqhBW6d0uSYeIRDT2sf9sz-f0-iRpo41HZwshoERO7w26hFln-ifOwJYt3adBkSVgP0ypwm-NamIhgWq0Cu-lTRmmF78c96MoB7bu-vihgmduvWHRfwPkUKn0TWLsVSHGf7ubH3Aqtki4xY0KIwzAfJ2rZUbdKg0Or6yrg3wShrE5aYaOotcyfXfo1xLyGwqL0OHDiw6GyPCJkwZbg3IuXuMVH0DmrbnMl4i-LquylNxsyMLXbhPbidXxeoaaL4tlB-n0jZxu69C7zAFCPkMd6tQygLEwyogdT7prJR5LlZ7WutTL5M8XkxcI4kZ6cCpROWdf3w01ZEgi_Zjh67LKYR-UCwtbHRqwCeRI0NMchkGbyV62f75upT0rItYZIJxQ0" style="width: 100%;">
                        <p class="caption">Semantic segmentation 예시, 출처: DeepLab V3+ paper</p>
                    </div>
                    <p>
                        <br><br><br><span style="font-size: 20px;"><b>Image Colorization</b></span>
                        <br>이미지에 있어서 색은 매우 중요한 요소입니다.
                        CNN은 색의 특징을 통해 그 물체가 무엇인지 파악하거나, 알맞는 특징을 추출합니다. 
                        그만큼 색은 이미지의 정보를 많이 내포하고 있습니다.
                        특히 colorization 분야는 흑백 이미지를 칼라 이미지로 바꾸는 데 많이 활용되며, 영상에도 적용이 가능해서 흑백 영화의 색 복원에 사용됩니다.
                        <ul>
                            <li><a href="https://arxiv.org/pdf/1603.08511.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);"><b>Colorful Image Colorization (2016)</b></a>: 이 모델은 ground truth와 동일한 이미지를 만드는 것이 아니라 그럴듯한 칼라로 흑백 이미지를 복원하는 것이 목적임.</li>
                        </ul>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemfNAxxxj2NYaaz_f_5drfeHISEQffuFJwJFEQgpukswqrnkwLs_cEEEjFKmuPvJMDbvtXNbNwS4GfODk8rV3zXJ-dgh90YqGCs6HMyhxvdDYPjufw7grs2cZ5UGqjK1RkJlJ6-qoCvltsBT3Sy5Hl2gtjkCkvKtWBRHpdCB4bGdeRtrmeEFfH5ddRxRZuf7u7YCK5LKOD7AZ30LjZz9wOD6nixQd8xUYkbyUzvAFpCE8ze5Q19qNpmcmmHPpVo6cRDUaPpt9u2iPKZSkcdR6cBVkb9jwXBMBjDIogyl_DVnWge8e1KGhgkfbqZBn5ZsFJNHW99c3IA3k3bO46wK9nkJVgD9fHT-xF7cYTffxyYMY4y58vzlDhEaylvss-w8yXOis3FmBheEMu9qUB-H96hjNcyf_yscySzx98VQtYyXPUE9YHMwux_1S9uMkfRH3Gb_oqO8916ghWl0qQsajPOgO2gAfnsu9pSM248jk23OWh6oc8F55dsX2y3RDWCTocWUS9JNHOxSnlgWh6pbSZPFYQ8womOPSyCcDYyVug3jTTTu4iX0A86xau4Af2DwEN_0pYt8Ip50os4b6iv-qKWKhr2WBgDcB07G9JPzG0wBQgzGqjp-fu8ZedGgnkRlgNgKP2_ZvbbT_OZYQwgQBy-iovDcIDLCzBaTyEot6GOlqeMIu6X16gFP0e6duOVrzmpktJBfWLtsX4I150mhi2t7S0FUOAhp5CtBcXtR9PpwvV_ZmK_FrUCqD7MZUWkZYrDeIZtLyIXM_xNZBuFUhqjunTvpnArBCOrGexM4VLTs8ADZgvub_pq9-Rgk7lCx1bPINexLjFXMYL9K0nRqItieaa5HCLqjYocqb2_c2Q6l5a8EdF4eUatuv2mA4omgXpmI3v6oFlwORPLa0d2vwendQqHp0Av3VDAHM3LttLU1fJ8jSy7IOD7NHxgDmAdGmwz-YEjxsp_qyXaL4_7j5zQcBRRMXKE9rlSOcDs4OKGzGpejPyMYjWPP9M2io4xITIIz9kdrXdodDf67wQFusnggLARh6d-WO-KStGIGyNTkk7JZ4fWaqWNMOXo9HumB-EalVhyurGUjLOTMDKIgbpTBdf4F5UaoFBssOokpCTmLMRWhPHRfrgTJeVljWpQ2b4XNiCt4T-dIWJXzt9urT7L4VThH8WOiCWSqLKYjVSlqx3kriTcC26D7osZoa6Gi0RBkDhCez9xKs5aWgZRlI_Hn2Qg2J9JNWOqpwZWWNG2Wgo2RiAiUGvkEINiwlz8510NUanU6qQZ0C5lcA6-Mb0NOkrS5Dq2SiYdoofFElRlofC4qUuBOp8lCtb8jVgwZ9F27CSdqMooVGzIs6KSZLLcy-bDK3COaL3Serrl_pgksS3tAINWGrnvBVgctXjxfK1VyocZAfZS912oATp-W9DEHtA4tl6yrgF8ZnqrphhFVjzRr0MQcokOGp9ZPmqy8MFdrKsGheLAq6Fn9XABi8DU" style="width: 100%;">
                        <p class="caption">Colorization 예시, 출처: Colorful Image Colorization paper</p>
                    </div>
                    <p>
                        <br><br><br><span style="font-size: 20px;"><a href="https://arxiv.org/pdf/1411.4555.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);"><b>Image Captioning</b></a></span>
                        <br>Image captioning은 이미지에 캡션을 다는 알고리즘입니다.
                        이 기법은 이미지를 해석하는 CNN, 캡션 문장을 생성하는 RNN, 성능을 높이기 위한 attention mechanism으로 구성되어 있습니다.
                        이를 위해 사용되는 데이터는 Flickr 8k, Flickr 30k, COCO 등이 사용됩니다.
                        자세한 내용은 <a onclick="pjaxPage('img2txt1.html');"><span class="highlight" style="color: rgb(0, 3, 206);">Image Captioning 글</span></a>을 참고하시기 바랍니다.
                    
                        <br><br><br><span style="font-size: 20px;"><b>Object Detection</b></span>
                        <br>Object detection은 현재 컴퓨터 비전 분야에 있어서 가장 중요한 기술이며, 지금까지도 계속 발전하고 있는 분야입니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">또한 물체 탐지에 걸리는 시간과 정확성의 trade-off 성격을 지닌 특성 때문에 빠르고 정확하게 물체 탐지가 필요한 object detection 기법의 특성상 아직 발전할 부분이 많은 분야이기도 합니다.</span>
                        <ul>
                            <li><a href="https://arxiv.org/pdf/1311.2524.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);"><b>Region based CNN (R-CNN) (2014)</b></a>: 이 모델은 인풋 이미지에 대해 물체가 있을 법한 영역에 region proposal를 하고, 각각 제안된 영역 모두를 CNN을 거쳐야하므로 연산량이 많아져서 병목현상이 생김. 따라서 한 이미지당 물체 탐지 시간이 50초가 걸린다는 문제가 있음.</li>
                            <li><a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);"><b>Fast R-CNN (2015)</b></a>: R-CNN을 보완하고자 나온 모델. Fast R-CNN은 한 이미지를 CNN에 한 번만 거치고 나온 feature map에서 region of interest (RoI)을 바로 projection하기 때문에 병목현상의 문제를 해결. 하지만 region proposal 하는 것이 neural net으로 이루어 지지 않고 외부 알고리즘에 의해 수행되므로 시간 한 이미지당 2초 물체 탐지하는 데 2초 정도 소요되며, 여전히 실생활에 적용하기에는 어려움.</li>
                            <li><a href="https://arxiv.org/pdf/1506.01497.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);"><b>Faster R-CNN (2016)</b></a>: Fast R-CNN의 속력을 향상 시키고자 등장. 이 기법은 region proposal network (RPN)이라는 물체가 있을 법한 영역 제안을 NN을 통해 하기 때문에 기존에 불가능했던 end-to-end 모델의 구현이 가능. 또한 RPN에 GPU 연산이 가능해짐 따라 그 한 이미지당 물체 탐지 시간이 0.2초로 속도가 Fast R-CNN에 비해 대폭 증가했다는 의의가 있음.</li>
                            <li><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);"><b>You Only Look Once (YOLO) (2016)</b></a>: YOLO는 Faster R-CNN 보다 10배나 빠르게 작동하는 알고리즘. 이는 이미지를 그리드로 나누고 확률을 통해 물체를 탐지. YOLO는 빠른 속도를 지녔지만 작은 물체에 대해 Faster RCNN에 비해 정확성이 떨어진다는 단점이 존재.</li>
                        </ul>
                        <span class="highlight" style="color: rgb(0, 3, 206);">위 기법들을 전이 학습 (transfer learning) 등을 통해 downstream task 로 활용할 수 있습니다.</span>
                        예를 들어 물체 인식 뿐 아니라, 번호판 인식(Optical Character Recognition, OCR)같은 경우, YOLO 기법 등을 사용하여 사진을 인식하고 번호를 해석할 수 있습니다.
                        또는 facebook의 사람 얼굴 인식, 사람 행동 캡처, 사람 행동 모니터링, 마스크 착용 유무 판단 같은 task도 앞서 말한 번호판 인식과 비슷한 방식을 통해 학습할 수 있습니다.


                        <br><br><br><span style="font-size: 20px;"><b>3D Perception</b></span>
                        <br>3D 인지 기술은 2D 이미지 속의 3D 정보를 찾아내는 기술입니다.
                        멀리 있는 물체와 가까이 있는 물체를 구분하고 그 거리를 기반으로 segmentation 하거나 disparity map을 그리는 기법입니다.
                        이러한 딥러닝 모델을 학습하기 위해서는 이미지의 모습의 위치가 살짝 다른 두 가지의 인풋 이미지가 필요합니다.
                        또한 이 기법을 통해 이미지의 일부의 모습만 주어졌을 때 그 전체의 모습을 재현할 수 있으며, 다른 각도에서 본 모습을 예측할 수 있습니다.
                        추가로 자율주행에 있어서 특정 물체와의 거리를 파악하는 것은 중요하기 때문에 자율주행에 사용되는 기법이기도 합니다.
                        <ul>
                            <li><a href="https://arxiv.org/pdf/1406.2283.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);"><b>Depth Map Prediction from a Single Image using a Multi-Scale Deep Network (2014)</b></a></li>
                        </ul>

                        <br><br><br><span style="font-size: 20px;"><b>Motion</b></span>
                        <br>3D Perception에서 설명한 이미지의 깊이 파악에서 더 나아가 영상의 속도(차량 블랙 박스 영상 등)까지 파악하여 움직인 거리와 속도를 계산하는 인공지능도 존재합니다.
                        이는 영상의 물체 이동 속력과 그 방향을 탐지하고 움직인 거리, 방향 및 경로를 계산하는 알고리즘입니다.
                        <ul>
                            <li><a href="https://www-robotics.jpl.nasa.gov/media/documents/howard_iros08_visodom.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);"><b>Stereo Visual Odometry (SVO) (2008)</b></a></li>
                            <li><a href="https://people.eecs.berkeley.edu/~pabbeel/cs287-fa09/readings/Durrant-Whyte_Bailey_SLAM-tutorial-I.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);"><b>Simultaneous Localization and Mapping (SLAM) (2006)</b></a></li>
                        </ul>

                        <br><br><br><span style="font-size: 20px;"><b>Others</b></span>
                        <ul>
                            <li><b>Dehazing</b>: 흐린 이미지를 선명하게 복구하는 기법. 자율주행 차량의 연구가 활발히 이루어지면서 각광받는 분야. 흐린날 이미지는 object detection의 성능이 급락하므로 dehazing 기술이 필수.</li>
                            <li><b>Visual Question Answering (VQA)</b>: 주어진 사진에 대해 자연어로 주어진 문장을 해석하여 알맞는 답을 내어주는 기법. Multimodal learning의 일종.</li>
                            <li><b>Deep Fake</b>: 다른 사람의 얼굴을 합성하는 기법.</li>
                            <li><a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Zhu_Unpaired_Image-To-Image_Translation_ICCV_2017_paper.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);"><b>Cycle GAN (2020)</b></a>: 이미지의 스타일을 바꾸는 기법.</li>
                            <li><a href="https://arxiv.org/pdf/1812.04948.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);"><b>StyleGAN (2019)</b></a>: PGGAN의 구조를 사용하였으며, 점진적으로 합성하는 이미지의 크기를 키워가는 기법. 두 가지 이상의 이미지를 섞어 새로운 높은 해상도의 이미지를 생성하는 기법. 성능 향상에 따라 StyleGAN2, 3이 존재.</li>
                        </ul>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemezmLvT-ilJ4xbN2QG1sy1pVkJEcpuMCPBw6DcxS5aCq1XIt4AeAR8yS33pkQ9bObf_K_XfM0WRWOUSl-YINzBGlyX1ON1uOrEr2YHzC5Y1xym5B8V5R9CA8FFfLVhV-b3_HeXlZGWJ7urcgnCJRUWKHPOkbClWzK4_m41Kvu4OO9V0h7Zox1vjPiHbEJXk1OY6wTYLkPj9EJvlaT-qp-xruBvtZpQxM5cBhfxqV0zndqBbW_K5MJZ_pLjj2RgwfyXPgFU6uKv5PnlCPaVlG17WqpJ2WNdft2EKedYYhuwiopJC-ChKQhsgzvLjnnjrfF84v6FvUvLMAMEQrIWdwKgxD7MIxerJ2RBB3LGcWlh2qxhD-YCzpFoTWzjHwNuLrT7kcbt3wV19IMQqYUTfPoLEBHC9-FOeLGQwXONZNwdwDETiVs0jIlbhMOZnVKgumoIq1nPbXItoJy5fn5fPgt8eaWB2l5VYypqGnafnMBAIposYRULoSIOCFKgd3SvaZh6zGjPIPopnagE2bFdku8lAe5MmDR7cGx-ACKtOsqmFyZBlJ4PUstWc3rasjByWrP0lYf43aOJHRJjWF-X2qqfZCSKytm6Gg0IuSm01Fo7pvCJ5T2E63eE0SY16HhHPcDJSqnE53MldLED9UVAbtYyTrApuuUHUvE40RYS9YAYCYVZ05XAD510N5bCc4OXUHja2SHy-WBIPMYTS81aZNRc0BhEhhNvbuLC2R_DPzhD-qL1gPp1yAcfmbawd-w0lzCHX2ei6ENHOu_o_TmeeYyw731npCNVfssHx-ZT4dVOXkBx_vL2CnsNYPrQ9nnPEQRd5zdglL00HB7FpFbLqFRFoHcMewPFvJrhDSLVsVmvcCMLR92nKJq9Gh_DpDD5ftOUvfyW1wckA-sdD-6tiRJFb6rHIL2BBmIdSgu5YwyTB7CyfMUZqauaCGz-83Lv9T0-8JVRbYGaWmGBwVqcHrG6AYQYwk-y4PP909HIVjBUwrVVmi5MpqSXA9KI-0MPmHTetkXXi6XXTqSou9GCFMAB9JHSjrCsGJIJtFBwBLH2Yf3DPM8HAyls3YYpaKVGWHwUdmUKzHhFCe2nVamMyZkm1FcxyZis6hdaDb2Z5NBxDDWAmrfQF2Tw_aIlnpO4IBsQBCnQF7A4TNq-RTe11DAGOwAi-cs8SuuiRTKIwg04tA9Shm2iqd7lSjaRXVL6oZY62su0bHIsSQqWKfEQtxAyrQsV5ut-Vyhseg7xrLS-OV3vxS-faI8jEq2tUNiehtG2hO4e0wSRyKgCtuxENpJQpbB6CxwnFMxGMY-UTV5nLvfeZ1JCP8byxSEC1EDp0fq3e3rTTJC0gTwY3v4bfDHsrBZhkGePYNU7DKbZA1iOXWJbtneQz91SgBZVLjic_6PvdRWRncePucwNPao4IEzV-gACGYD_zs7hTJi4SnCC_oMiokYrAHUhDy0ErrDyuRSBgn1NzPa332QgP9qfjZaY" style="width: 100%;">
                        <p class="caption">Cycle GAN 예시, 출처: Cycle GAN paper</p>
                    </div>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemdZaHuRvCZr34w5sr9I_GuojSjEAonCOZ4b-PbghwhtLoIwlXq6FRfD0BiASvpJV9PdhZ2xlHe64YrL9lhuclN6YQ1IKtVAEDTpzqHxOnBmPuvQu2sMR4ghRnvStbYUQ5BkqyQHz1FOeto0DfCDmrXBcPVWoqUZh0sqpOtcdQ3Ikri5OnAGLTr9tHhO0abasHpy5KyCfoAzcoU-Dm9if1jNAwwNVZuiXcjhEtZCTTB5fUkUgdPkLkZpVh0re2RbXuvPawIj1-2ig3mpkK8LTsDH7ihxuCpTZ_eYdQnbHW3UCWG9OmjAg9bDqIdGxR-526_ImzkJPQP_-sJymKOpi42MOp-xNyIotreego_RaPrv32YujAfhxFCdiEH5g737_arWEMY5t6K7aXXgIrSTSwp0IF6xNWfTVX9fHEnQg1dKINIiAasUFsOJBwXsWRanHVd6rqUEP_I1Yx7jr7O-HSG3yXNn72K4WffVbufgEji-P7Acut_BUkm5LzeMNERakiAYyztGdUwB4Q_2QMXpHrKSLm5aJi8SJ3gbKJz3srcN2wVPeKNVriee9lzhnFCqxxuFyBfIyKkKs7yMIcWpCoAPjq8B8wRcoYebQneP9TYhRcAODAu4hh9KDZ6Zem3VpVH76F78IgOvG7A3del7gM_S9mmJ35ylkUWrfzcTChpn2RwVy88-A_qqewdcGUBEbWlvgFlHfJeCTHB6Moe1aVOKNrFMyAo1bAdlqnBT3DnZK7wBsGmh5uhPxgYh1YVtaQTp76PtFrXCeLNFbDK5gLnzGKiwI0hDyXgtyIDvbSqQ57wxErel1TfocKO1_inC9p3p2qelHrfepQw1PuQH6yh6-4JbFBKcE_TK-DRhYVgPrHcci_9srjsmq8lxJ6lmDSpGNgGwVnkdbcRkJkdEzgk6TKZR1w2J9hoo8m7Oy2eNyil90xeRk42A7Uze_TbnVcGp8GaGqwlG06M1QASLchLdbIh5ikFCrdEf3DbxQjkXggePbfb62tne4FBLgLdYlGdJdKhx2N2cM8NZiTKV4T5oKkcPoxQ-R3y5U1Srh1lZ0aTiCyCMf8UaXbNF2MY1MgT3zO_H0dwtNTvJx_mfRiMNQUTauev02GiP2PNCKE6rIYUW4mvHShmkn4DYRx9wJUyV1JiewEx_5wSu8fxVOBXvKrpkT5K2QO2ESgQJCAU7nH3qiEs6ctZgW-xUekiOooeMkNi2_yKvlEqRpAu3Huj2xEiPHOL5zMSrvSsC-xz2qXwMi_qFo8-Oyx7K_aBb0efgaMokAHwmaN3Oom1ycbxAnQ6owQ7QbWyEfR50GOkUTRdr6G7NyGoycqX4zwzLgvkOm_KZxm_Y4ZdSmVWec66cUiLxm3R6np9bCkUJAZd3Av7PBiijK2SLchS6z1Sjeq4bC2lw2vq7pt5dbfet9U55SEJxyzBQPepqpzeQ40J5hKrtBsAGIswP8fi7Htt3ff4JDTP8ksEq1OEp-go-v04" style="width: 70%;">
                        <p class="caption">StyleGAN 예시, 출처: StyleGAN paper</p>
                    </div>
                    



                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>CNN의 한계</span>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        CNN 모델과 딥러닝을 바탕으로 컴퓨터 비전은 비약적인 발전이 일어났으며, 지금도 계속 연구되는 분야입니다.
                        하지만 CNN 모델 역시 여전히 해결하기 어려운 문제가 존재합니다.

                        <br><br><br><span style="font-size: 20px;"><b>이미지는 3D를 2D로 projection 한 결과물</b></span>
                        <br>이미지는 3D 세상을 2D로 projection 한 데이터입니다. 따라서 딥러닝 모델이 깊이, 3D의 맥락을 완벽히 이해하는 데 한계가 존재합니다.

                        <br><br><br><span style="font-size: 20px;"><b>착시 효과</b></span>
                        <br>인간은 뇌를 통해 이미지를 해석하지만, 딥러닝 모델은 이미지를 있는 그대로의 모습으로 해석하기 때문에 발생하는 문제점입니다. 아래 예시를 보겠습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">왼쪽 그림의 A 영역과 B의 영역의 색은 우리가 보기에 다른 색으로 보입니다. 하지만 실제로 픽셀 값으로 따져보았을 때는 이 둘은 완전히 같은 색입니다.
                        즉 컴퓨터는 픽셀 데이터로써 그림을 바라보기에 이 둘의 차이를 파악할 수 없게 됩니다.
                        오른쪽 그림의 두 괴물의 크기는 우리가 보기에 다른 다르게 보이지만 실제로는 같은 크기의 그림입니다. 이 또한 컴퓨터는 정학히 그림의 문맥을 파악할 수 없고, 같은 크기의 괴물로만 보게 되는 것이죠.</span>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemcc0cJQp4VyFpRKquMJOhAeupN3gQt8bHMf1o7smZWXxTjVMQQLaLmWvtuGDKXq-b7uxnORhHWHKv8__uH7LFH31eg3sIFvnxvrwz468PzllLrvKk498xwLcGMBF32U9wONJJstUx1zJLav4Uf49hFU90pLkyG9nDxY6nJ0HM1EX2ZXqWx61MFgzYaTlY9VE47EcIl5h4c5tNcWKsLkXsg4M-cb3bfG_ak3xVjIA9mduL5nsM5NWD9YaPimVmM0zrM57GHOFWJm1xrtFLG8QvB2piQdXuUXAt3yWg9VDYGBf6_bpJCav2OqMbDhxWh4h75_cwke0qLz2mBYFnbJzw6jjn5w8EElmUA8dZVzdBC37r0IBauSqBEjGyioeZrJIxiLJqub8JRBCGmYikzDKk9NRcfERbg75v9zU_PmK2n3Vv8zXvTReCXW01JTW1mNL0Jkca9bJT0tdunfWr_KHpxg9MlTZOqy635gGoMdBFPSf3Xb5-vXtzdZ70NAyEcSBeswO_5Hhphjrg5RY57Q6LLuYfwkSsHcjPLmbdLnxVIRPtSr8IbAuqiv12xwYGNYKaMXboxUgM2oBMJGC6RQH2hm6jPbfiXBPKTNnJXui_dx4mKEUOfTyxAPcVbGiXXqRfpwsU96QgZWoZ_f-CzimEWlCHguNc-hMUzZNDKugsJYqWXGirpqlSi3Cma0iriabMres3FDNsDllbTKzb-jOdjAEr3Zc-CvNdOyXwaXhPK9BojDgVUJsefIKVAdMsvRlacCavyhvOjKBXif5hZYSHzcCJQ0eLsXscgvTt7l3PMwwOWIYTfo8-uNx3M6fYT3eaR4DZGpeCc7LS8R7pt2VFbrlmrecdPNfmu0Sxr0SvM2Z7japxBLwTVM5MmZf0CCP_GNsXUprBnOMIZHh6qCpQP47JitdHwZx3y-189bIMJREYnKD-vs-hvtpYN0LISiyMvOdlSv2CrKeYO3GfcIPtEY161vYWVavO0JVMvpTmAPedtGRmMf7EaDe_HxEsYF2u6JLog31X5NNyXrMenJs8riixxmSXCtb0NoprLQBJbXEitWh8Y5mNAHBeQHfAC8BVIPb41RbeNqyixrL9Rbv-RB5ccHRZQo7K_-izcF03uwcLb0abOPjJDqSQg5BOXczsiWK5k1iGNyAN6DF-SnCc0BMNLWhttqDW5ARFofZTi5uRTi9SvbCELF25jdzX9V0y52EZNIedTNmJ8jQBk_Unfa37BV8B8psuqZ-lhGpRnKp3Rwmo7a9XFHomKbwvL9rVBjlZzAorJTcuhL-hSZ8eMv5G2zPrno4reXDOIN22p2pO8uxwyolzdefrGFClLCEtrFnVSuGHmq2h3bVa0Tk_HC0eWgJttn2mevbxT_wNpnStd4Nhd1AaVTrjSMl30h-ZzANZGInqaXqddfPossh79xcBpdKQwB9t-H3YNqJnFs-YUZiHMEPSJ6RzYYCWQpl7qnf6OsY_XMRP_w708S3qU" style="width: 100%;">
                        <p class="caption">착시 예시</p>
                    </div>
                    <p>
                        <br><br><br><span style="font-size: 20px;"><b>이미지 데이터의 문제</b></span>
                        <br>마지막으로 이미지 데이터 자체의 문제가 있습니다.
                        이미지는 데이터 양도 많지만 그 형태가 매우 다양합니다.
                        하지만 대부분의 딥러닝 모델은 일정한 크기의 벡터를 input으로 받기때문에 이미지의 형태 변형이 불가피합니다.
                        하지만 이미지의 형태를 변형하게 되면 이미지 내의 물체 위치 정보, 형태 정보 등이 손실되기 때문에 딥러닝 모델이 부정확한 정보를 습득하게 되고 모델의 강건성이 떨어지게 된다는 문제점이 있습니다.
                    </p>
                    <p>
                        <br><br><br>다음에는 기본 CNN의 구조를 이용하여 MNIST 데이터를 분류하는 실험을 해보도록 하겠습니다.
                    </p>


                    
                </div> 
                <div class="tag">
                    <b>태그</b>&emsp;#CNN&emsp;#TransposedCNN
                </div>
                <div class="pageTurner">
                    <div class="pageTurnerLeft">
                        <span><a style="position: absolute; left: 0;" onclick="alert('CNN 첫 게시물 입니다.\n\nThis is the first post of CNN.')" onmouseover="colorOn(this);" onmouseout="colorOff(this);">&lang; 이전글</a>
                        <br></span>
                    </div>
                    <div class="pageTurnerRight">
                        <span><a style="position: absolute; right: 0;" onclick="pjaxPage('CNN2.html');" onmouseover="colorOn(this);" onmouseout="colorOff(this);">다음글 &rang;</a>
                        <br>CNN을 이용한 MNIST 분류</span>
                    </div>
                </div>
                <span id="readNum"></span>
                <div id="disqus_thread"></div>

                <script>
                    headHighlightColorChanger();
                    (function() { // DON'T EDIT BELOW THIS LINE
                    var d = document, s = d.createElement('script');
                    s.src = 'https://novicetraveler.disqus.com/embed.js';
                    s.setAttribute('data-timestamp', +new Date());
                    (d.head || d.body).appendChild(s);
                    })(); 
                </script>
                <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </article>
        </div>

        <div id="menuRelated">
            <div class="menuButton">
                <img id="menuImg" src="init/index_img/menu_black.png" onclick="openMenu(this);">
            </div>
            <div class="menu">
                <img id="menuExtension" title="메뉴를 확장합니다." src="init/index_img/extension_black.png" onclick="extendMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
            <div class="bigMenu">
                <img id="menuCompression" title="메뉴를 축소합니다." src="init/index_img/compression_black.png" onclick="compressMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
        </div>

        <script>
            detectScroll();
            pushFunc();
            detectSize();
        </script>
    </body>
</html>