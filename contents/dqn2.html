<!DOCTYPE html>
<html>
    <head>
        <title>DQN을 이용한 Cart Pole 세우기</title>
        <meta name="description" content="DQN을 통해 cart pole 세우는 모델을 학습합니다.">
        <meta charset="utf-8">
        <link rel="stylesheet" href="init/index.css">
        <link rel="stylesheet" href="init/contents.css">
        <link rel="stylesheet" href="init/index_img/icons/css/fontello.css">

        <link rel="preconnect" href="https://fonts.googleapis.com"> 
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> 
        <link href="https://fonts.googleapis.com/css2?family=Dongle:wght@300&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Gowun+Batang&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic&display=swap" rel="stylesheet">

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        <script src="init/index.js"></script>
        <script src="init/jquery.pjax.js"></script>
        
        <meta name="viewport" content="width=device-width, initial-scale=0.8, max-width=1">

        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-219110982-1"></script>
        <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-219110982-1');
        </script>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7745178886614102"
        crossorigin="anonymous"></script>

        <meta property="og:url" content="https://ljm565.github.io/contents/dqn2.html" />
        <meta property="og:title" content="DQN을 이용한 Cart Pole 세우기" />
        <meta property="og:type" content="website">
        <meta property="og:description" content="DQN을 통해 cart pole 세우는 모델을 학습합니다." />
        <meta property="og:image" content="https://lh3.googleusercontent.com/fife/AMPSemdp1d3w1fEfom247Eq3VXYU9cN-nLE6tCDkStmS-1p-m47oQKI5etp7MYHa8aL_r42QnAeMdXv_7Q7O5rXoVGu7D_hDuczdmjLXsU1vmDkB5lHM6UH4A3CIbuW96eL2RAM99GtphG8-uhKb6O5N-IA_MV5Cw385usKUhl6zpiwCCVaUyGZbQpA9JOUKJxr4LdxmTwS52yrsEtTNw_WlSniPeFInydpM8A0lqqMQD6ft9uFqXaJf5F5o40Qeyyrlq9qDBouaD_E08ALxvPcfF_HHr7G3JuTreCG9hbITVoIh2S33h8fPARDeWiQCMgQlXH2Nbe2FlNyfk4aAh_r6fmzocnL3SISWseKY_CAWkxMlMNdp9xX4Kym3SMd95SdJBPCbuO5yaiAysouWP8gKmFzz6xnJYqG9Gc_OKkZOMUezoF6lAf-Ek5iAatS4Kc6uWAbS-HZwRjuLJ_XFYei5FXkCH3cL1k6epii3uGJV3PflizFkijGGB2VLpLDQPYESkfQ5ukGIcaz2R-GdqItabAtS1koxOD1nc_0ttrIM5KQ0jpewUVzqBfDRg-mdc2EnmnOaFbrRYzFat9YrB104-8gTD0SsAuwCyfDTAz40vzbs9iGEGyZl_l1dJrzGqJzwaOpbkRzdsIzhRF8mvu3cCAPuZ9EdQL49Ca6_SieT3dB_rbjyCp_NxollLhhw4k9f5qVHQwmfp2WCRpMtqNf5nP5-wcm_78iqroa3-GAqqJTJz1-6MjJNeXRhUukVlh8csvjAuoRqgy5BWiREO0C00UgNgXlgFmpEcqOPE_D9fG_lNV15xHBaH2SUTzn7i_FyfC-PbpsGQwa8QEQcM1hYBPuc5TKe1Y-Cm04AyLrLraFRNIymjaiLxXhCleSEqnMUFgO1psTd9BgMlADbNA_bWpvLsZg2SBZcZ1CvvHQImjcHSJCPQNp9SRnyrH6_figjw4bGynabDCxbZxEKAZaJ62pIRMSEuanZUZov0PI3nm-K0NiFs1OXteXlIeN1_8Dav2MdB73UPUpjPIr5PXqVh8tL3b2r_ymXnnu6npid-dWOo00nAmYRJXK7C7B4NwVHMgpqS5HZEtmptIUZK4GV9rHA-ul3o7vJQxBeyneAmsCmm2QdtShw9jeCD6PhXAhHnlrZ9XCTdHUpd1vh5aBwoMdWvDB6bCPRxpeIlCkidSl63dy0JrGwTKuMmDhYaLxeOe-wIKMzmp5DHVuwqy_VjvN6ggQuhuHg1-fa3_7RSfq0gY8TU9eG8k1Ga8fuSXvJ9ka44-sRXdJqC9Yio7BUdaAczftddaS3AjKTG2REflBJZc-LmQftoGI1TNXcvbe6tnCzdsnkIiyHKCJw1jz3Gs7C2pwL-dapwssBw9UV0rdHOuqyEQI94ViPzW9HD_sIlydpQEoeCK0rR53Z4qnRSgvGy8bvaUAf8zT7ztEHs7zhiwapALXp8lBxXZn0fJfe_SRQk53ijQ5aMVWBUvI" />
    </head>   
    <body>
        <div id="modeButton">
            <button type="button" value="dark" onclick="darkMode(this)" onmouseover="hoveringOn(this)" onmouseout="hoveringOff(this)">
                <div class="modeImg"><img id="modeImg" src="init/index_img/moon_off.png"></div>
                <div id="modeState">다크 모드로 보기</div>
            </button>
        </div>

        <div id="container" onclick="reload();">
            <article>
                <script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
                <script>
                    initMathJax();
                </script>
                <div id="mainHeadWrapper">
                    <div id="mainHead">
                        <h1 class="contentHead">딥러닝 이야기 / Deep Q Learning (DQN) / 2. DQN을 이용한 Cart Pole 세우기</h1>
                    </div>
                </div>
                
                <div class="title" style="background-image:url(https://lh3.googleusercontent.com/fife/AMPSemdp1d3w1fEfom247Eq3VXYU9cN-nLE6tCDkStmS-1p-m47oQKI5etp7MYHa8aL_r42QnAeMdXv_7Q7O5rXoVGu7D_hDuczdmjLXsU1vmDkB5lHM6UH4A3CIbuW96eL2RAM99GtphG8-uhKb6O5N-IA_MV5Cw385usKUhl6zpiwCCVaUyGZbQpA9JOUKJxr4LdxmTwS52yrsEtTNw_WlSniPeFInydpM8A0lqqMQD6ft9uFqXaJf5F5o40Qeyyrlq9qDBouaD_E08ALxvPcfF_HHr7G3JuTreCG9hbITVoIh2S33h8fPARDeWiQCMgQlXH2Nbe2FlNyfk4aAh_r6fmzocnL3SISWseKY_CAWkxMlMNdp9xX4Kym3SMd95SdJBPCbuO5yaiAysouWP8gKmFzz6xnJYqG9Gc_OKkZOMUezoF6lAf-Ek5iAatS4Kc6uWAbS-HZwRjuLJ_XFYei5FXkCH3cL1k6epii3uGJV3PflizFkijGGB2VLpLDQPYESkfQ5ukGIcaz2R-GdqItabAtS1koxOD1nc_0ttrIM5KQ0jpewUVzqBfDRg-mdc2EnmnOaFbrRYzFat9YrB104-8gTD0SsAuwCyfDTAz40vzbs9iGEGyZl_l1dJrzGqJzwaOpbkRzdsIzhRF8mvu3cCAPuZ9EdQL49Ca6_SieT3dB_rbjyCp_NxollLhhw4k9f5qVHQwmfp2WCRpMtqNf5nP5-wcm_78iqroa3-GAqqJTJz1-6MjJNeXRhUukVlh8csvjAuoRqgy5BWiREO0C00UgNgXlgFmpEcqOPE_D9fG_lNV15xHBaH2SUTzn7i_FyfC-PbpsGQwa8QEQcM1hYBPuc5TKe1Y-Cm04AyLrLraFRNIymjaiLxXhCleSEqnMUFgO1psTd9BgMlADbNA_bWpvLsZg2SBZcZ1CvvHQImjcHSJCPQNp9SRnyrH6_figjw4bGynabDCxbZxEKAZaJ62pIRMSEuanZUZov0PI3nm-K0NiFs1OXteXlIeN1_8Dav2MdB73UPUpjPIr5PXqVh8tL3b2r_ymXnnu6npid-dWOo00nAmYRJXK7C7B4NwVHMgpqS5HZEtmptIUZK4GV9rHA-ul3o7vJQxBeyneAmsCmm2QdtShw9jeCD6PhXAhHnlrZ9XCTdHUpd1vh5aBwoMdWvDB6bCPRxpeIlCkidSl63dy0JrGwTKuMmDhYaLxeOe-wIKMzmp5DHVuwqy_VjvN6ggQuhuHg1-fa3_7RSfq0gY8TU9eG8k1Ga8fuSXvJ9ka44-sRXdJqC9Yio7BUdaAczftddaS3AjKTG2REflBJZc-LmQftoGI1TNXcvbe6tnCzdsnkIiyHKCJw1jz3Gs7C2pwL-dapwssBw9UV0rdHOuqyEQI94ViPzW9HD_sIlydpQEoeCK0rR53Z4qnRSgvGy8bvaUAf8zT7ztEHs7zhiwapALXp8lBxXZn0fJfe_SRQk53ijQ5aMVWBUvI);">
                    <div>
                        <span class="mainTitle">DQN을 이용한 Cart Pole 세우기</span>
                        <br><br>
                        <div style="display: table-cell; margin: 0;">
                            <img src="init/index_img/profile.png" style="width: 30px; cursor: pointer;" onclick="pjaxPage('/');">
                        </div>
                        <span class="subTitle" style="display: table-cell; text-align: left; vertical-align: middle; padding-left: 20px; line-height: 125%;">작성자: 여행 초짜<br>작성일: 2023.03.02</span>
                    </div>
                </div>

                <div id="content">
                    <p>
                        시작하기 앞서 틀린 부분이 있을 수 있으니, 틀린 부분이 있다면 지적해주시면 감사하겠습니다.
                        
                        <br><br><a onclick="pjaxPage('dqn1.html');"><span class="highlight" style="color: rgb(0, 3, 206);">이전글</span></a>에서는 강화학습 딥러닝 모델의 시초격인 Deep Q Learning (DQN)에 대해 설명하였습니다. 이번글에서는 DQN을 이용한 cart pole 세우는 모델을 학습해보도록 하겠습니다.
                        본 글에서는 DQN cart pole 학습 방법에 중점을 두었습니다.
                        실제 학습된 모델을 평가하여 gif로 이미지를 만들거나, scheduler 등의 전체 코드는 GitHub에 올려놓았으니 아래 링크를 참고하시기 바랍니다.
                        
                        <br><br><span class="highlight" style="color: rgb(0, 3, 206);">본 DQN의 코드는 PyTorch와 Gym 라이브러리를 이용하여 구현되었습니다.</span>
                        <br><br>오늘의 컨텐츠입니다.
                        <ol>
                            <li>재현 메모리</li>
                            <li>DQN 모델</li>
                            <li>DQN 학습</li>
                            <li>DQN 학습 결과</li>
                        </ol>
                    </p>
                    <div class="link">
                        <a href="https://github.com/ljm565/cartpole-DQN" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);">DQN cart pole GitHub 코드</a>
                    </div>



                    <h1 class="subHead">DQN 구현</h1>
                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center;">&ldquo;</span>
                        <span>재현 메모리</span><br>
                        <span>Replay Memory</span>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        여기서는 DQN의 핵심 아이디어 중 하나인 재현 메모리를 살펴보겠습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">기존 Q-table을 딥러닝으로 대체하려는 시도는 불안정한 경향이 있었기에 이를 해결하기 위해 도입한 것이 바로 재현 메모리 버퍼의 개념입니다.</span>
                        이렇게 즉각적으로 모델이 선택한 action과 그에 대한 next state를 학습에 반영하지 않고 재현 메모리라는 버퍼에 담아둔 후 랜덤으로 batch 만큼 추출하여 학습하기 위한 코드입니다.
                    </p>

<pre>
<div class="codeWrapper">
<div class="lineNo">
<pre id="code1">
</pre>
</div>
<div class="code">
<pre>
<span class="return">import</span> <span class="clazz">torch</span>
<span class="return">import</span> <span class="clazz">random</span>
<span class="return">from</span> <span class="clazz">collections</span> <span class="return">import</span> <span class="clazz">deque</span>


<span class="reserved">class</span> <span class="clazz">ReplayMemory</span>(<span class="clazz">object</span>):
    <span class="reserved">def</span> <span class="method">__init__</span>(<span class="var">self</span>, <span class="var">capacity</span>):
        <span class="var">self</span>.<span class="var">memory</span> = <span class="clazz">deque</span>([], <span class="var">maxlen</span>=<span class="var">capacity</span>)

    <span class="reserved">def</span> <span class="method">push</span>(<span class="var">self</span>, <span class="var">state</span>, <span class="var">action</span>, <span class="var">reward</span>, <span class="var">next_state</span>):
        <span class="var">self</span>.<span class="var">memory</span>.<span class="method">append</span>((<span class="var">state</span>, <span class="var">action</span>, <span class="clazz">torch</span>.<span class="clazz">FloatTensor</span>([<span class="var">reward</span>]), <span class="clazz">torch</span>.<span class="var">FloatTensor</span>([<span class="var">next_state</span>])))

    <span class="reserved">def</span> <span class="method">sample</span>(<span class="var">self</span>, <span class="var"><span class="var">batch</span>_size</span>):
        <span class="return">return</span> <span class="clazz">random</span>.<span class="var">sample</span>(<span class="var">self</span>.<span class="var">memory</span>, <span class="var"><span class="var">batch</span>_size</span>)

    <span class="reserved">def</span> <span class="method">__len__</span>(<span class="var">self</span>):
        <span class="return">return</span> <span class="method">len</span>(<span class="var">self</span>.<span class="var">memory</span>)


    
<span class="var">memory</span> = <span class="clazz">ReplayMemory</span>(<span class="num">10000</span>)
</pre>
</div>
</div>
</pre>
<script>
lineMaking("code1", 21);
</script>
                    <p>
                        <ul>
                            <li>8번째 줄: 재현 메모리 버퍼의 크기 설정.</li>
                            <li>10 ~ 11번째 줄: 모델이 선택한 action, action을 선택한 시점의 state, 이로 인해 계산되는 next state, reward를 저장하는 함수.</li>
                            <li>13 ~ 14번째 줄: 학습을 위해 랜덤으로 데이터를 샘플링할 때 사용하는 함수.</li>
                            <li>21번째 줄: 재현 메모리 버퍼 설정.</li>
                        </ul>
                    </p>







                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px">&ldquo;</span>
                        <span>DQN 모델</span><br>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        이제 DQN의 모델을 구성하는 코드입니다.
                        Cart pole 세우는 task는 그리 복잡하지 않기때문에 아주 간단한 MLP 모델로 구성합니다.
                    </p>

<pre>
<div class="codeWrapper">
<div class="lineNo">
<pre id="code2">
</pre>
</div>
<div class="code">
<pre>
<span class="reserved">class</span> <span class="clazz">DQN</span>(<span class="clazz">nn</span>.<span class="clazz">Module</span>):
    <span class="reserved">def</span> <span class="method">__init__</span>(<span class="var">self</span>, <span class="var">config</span>, <span class="var">case_num</span>, <span class="var">device</span>):
        <span class="clazz">super</span>(<span class="clazz">DQN</span>, <span class="var">self</span>).<span class="method">__init__</span>()
        <span class="var">self</span>.<span class="var">hidden_dim</span> = <span class="var">config</span>.hidden_dim
        <span class="var">self</span>.<span class="var">case_num</span> = <span class="var">case_num</span>
        <span class="var">self</span>.<span class="var">device</span> = <span class="var">device</span>
        <span class="var">self</span>.<span class="var">model</span> = <span class="clazz">nn</span>.<span class="clazz">Sequential</span>(
            <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="num">4</span>, <span class="var">self</span>.<span class="var">hidden_dim</span>),
            <span class="clazz">nn</span>.<span class="clazz">ReLU</span>(),
            <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="var">self</span>.<span class="var">hidden_dim</span>, <span class="var">case_num</span>)
        )


    <span class="reserved">def</span> <span class="method">forward</span>(<span class="var">self</span>, <span class="var">x</span>):
        <span class="var">x</span> = <span class="var">x</span>.<span class="method">to</span>(<span class="var">self</span>.<span class="var">device</span>)
        <span class="var">x</span> = <span class="var">self</span>.<span class="var">model</span>(<span class="var">x</span>)
        <span class="return">return</span> <span class="var">x</span>
</pre>
</div>
</div>
</pre>
<script>
lineMaking("code2", 17);
</script>
                    <p>
                        <ul>
                            <li>4번째 줄: 모델의 hidden dimension.</li>
                            <li>5번째 줄: 모델이 취할 수 있는 action의 종류 수. Cart pole에서는 좌, 우 2개.</li>
                            <li>7 ~ 11번째 줄: DQN 모델의 MLP. <span class="highlight" style="color: rgb(0, 3, 206);">4라는 숫자는 모델이 현재 state [cart position, cart velocity, pole angle, pole angular velocity]의 4가지 종류의 상태를 받기 때문임.</span></li>
                            <li>14 ~ 17번째 줄: 모델이 학습할 때 거치는 부분.</li>
                        </ul>
                    </p>




                

                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>DQN 학습</span><br>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        이제 DQN을 학습하는 코드입니다.
                        아래 코드의 config.의 부분은 <a href="https://github.com/ljm565/cartpole-DQN" target="_blank"><span class="highlight" style="color: rgb(0, 3, 206);">GitHub 코드</span></a>에 보면 src/config.json이라는 파일에 존재하는 변수 값들을 모델에 적용하여 초기화 하는 것입니다.
                        그리고 self. 이라고 나와있는 부분은 <a href="https://github.com/ljm565/cartpole-DQN" target="_blank"><span class="highlight" style="color: rgb(0, 3, 206);">GitHub 코드</span></a>에 보면 알겠지만 학습하는 코드가 class 내부의 변수이기 때문에 있는 것입니다.
                    </p>

<pre>
<div class="codeWrapper">
<div class="lineNo">
<pre id="code3">
</pre>
</div>
<div class="code">
<pre>
<span class="reserved">def</span> <span class="method">select_action</span>(<span class="var">self</span>, <span class="var">state</span>, <span class="var"><span class="var">phase</span></span>=<span class="str">'train'</span>):
    <span class="var">eps_threshold</span> = <span class="var">self</span>.<span class="var">config</span>.eps_end + (<span class="var">self</span>.<span class="var">config</span>.eps_start - <span class="var">self</span>.<span class="var">config</span>.eps_end) * <span class="clazz">math</span>.<span class="method">exp</span>(<span class="var">-1</span> * <span class="var">self</span>.<span class="var">steps_done</span> / <span class="var">self</span>.<span class="var">config</span>.eps_decay)
    <span class="var">self</span>.<span class="var">steps_done</span> += <span class="num">1</span>

    <span class="annot"># choose bigger action between left and right</span>
    <span class="return">if</span> <span class="clazz">random</span>.<span class="var">random</span>() &gt; <span class="var">eps_threshold</span>:
        <span class="return">with</span> <span class="clazz">torch</span>.<span class="clazz">no_grad</span>():
            <span class="return">return</span> <span class="clazz">torch</span>.<span class="method">argmax</span>(<span class="var">self</span>.<span class="var">q_net</span>(<span class="var">state</span>), <span class="var">dim</span>=1, <span class="var">keepdim</span>=<span class="reserved">True</span>)
    
    <span class="annot"># random action between left and right</span>
    <span class="return">return</span> <span class="clazz">torch</span>.<span class="method">tensor</span>([[<span class="clazz">random</span>.<span class="var">randrange</span>(<span class="var">self</span>.<span class="var">case_num</span>)]], <span class="var">dtype</span>=<span class="clazz">torch</span>.<span class="var">long</span>).<span class="method">to</span>(<span class="var">self</span>.<span class="var">device</span>)


<span class="reserved">def</span> <span class="method">train</span>(<span class="var">self</span>):
    <span class="return">if</span> <span class="method">len</span>(<span class="var">self</span>.<span class="var">memory</span>) &gt;= <span class="var">self</span>.<span class="var"><span class="var">batch</span>_size</span>:
        <span class="var">batch</span> = <span class="var">self</span>.<span class="var">memory</span>.<span class="var">sample</span>(<span class="var">self</span>.<span class="var"><span class="var">batch</span>_size</span>)
        <span class="var"><span class="var">state</span>s</span>, <span class="var">actions</span>, <span class="var"><span class="var">reward</span>s</span>, <span class="var"><span class="var">next_<span class="var">state</span></span>s</span> = <span class="clazz">zip</span>(*<span class="var">batch</span>)

        <span class="annot"># batch data and current q</span>
        <span class="var"><span class="var">state</span>s</span> = <span class="clazz">torch</span>.<span class="method">cat</span>(<span class="var"><span class="var">state</span>s</span>).<span class="method">to</span>(<span class="var">self</span>.<span class="var">device</span>)
        <span class="var">actions</span> = <span class="clazz">torch</span>.<span class="method">cat</span>(<span class="var">actions</span>).<span class="method">to</span>(<span class="var">self</span>.<span class="var">device</span>)
        <span class="var"><span class="var">reward</span>s</span> = <span class="clazz">torch</span>.<span class="method">cat</span>(<span class="var"><span class="var">reward</span>s</span>).<span class="method">to</span>(<span class="var">self</span>.<span class="var">device</span>)
        <span class="var"><span class="var">next_<span class="var">state</span></span>s</span> = <span class="clazz">torch</span>.<span class="method">cat</span>(<span class="var"><span class="var">next_<span class="var">state</span></span>s</span>).<span class="method">to</span>(<span class="var">self</span>.<span class="var">device</span>)

        <span class="annot"># finding current q and max q values</span>
        <span class="var">curr_q</span> = <span class="clazz">torch</span>.<span class="method">gather</span>(<span class="var">self</span>.<span class="var">q_net</span>(<span class="var"><span class="var">state</span>s</span>), <span class="var">dim</span>=<span class="num">1</span>, <span class="var">index</span>=<span class="var">actions</span>)
        <span class="var">max_next_q</span>, _ = <span class="clazz">torch</span>.<span class="method">max</span>(<span class="var">self</span>.<span class="var">target</span>(<span class="var"><span class="var">next_<span class="var">state</span></span>s</span>), <span class="var">dim</span>=<span class="num">1</span>)

        <span class="annot"># target q</span>
        <span class="var"><span class="var">target</span>_q</span> = <span class="var"><span class="var">reward</span>s</span> + <span class="var">max_next_q</span> * <span class="var">self</span>.<span class="var">config</span>.gamma
        <span class="var"><span class="var">target</span>_q</span> = <span class="var"><span class="var">target</span>_q</span>.detach()
        
        <span class="annot"># training</span>
        <span class="var">self</span>.<span class="var">optimizer</span>.<span class="method">zero_grad</span>()
        <span class="var">loss</span> = <span class="var">self</span>.<span class="var">criterion</span>(<span class="var">curr_q</span>.<span class="method">squeeze</span>(), <span class="var"><span class="var">target</span>_q</span>)
        <span class="var">loss</span>.backward()
        <span class="var">self</span>.<span class="var">optimizer</span>.<span class="method">step</span>()



<span class="annot"># deine memory class</span>
<span class="var">self</span>.<span class="var">memory</span> = <span class="clazz">ReplayMemory</span>(<span class="num">10000</span>)

<span class="annot"># environment define</span>
<span class="var">self</span>.<span class="var">env</span> = <span class="clazz">gym</span>.<span class="method">make</span>(<span class="str">'CartPole-v1'</span>)
<span class="var">self</span>.<span class="var">case_num</span> = <span class="var">self</span>.<span class="var">env</span>.<span class="var">action_space</span>.n

<span class="annot"># model define</span>
<span class="var">self</span>.<span class="var">q_net</span> = <span class="clazz">DQN</span>(<span class="var">self</span>.<span class="var">config</span>, <span class="var">self</span>.<span class="var">case_num</span>, <span class="var">self</span>.<span class="var">device</span>).<span class="method">to</span>(<span class="var">self</span>.<span class="var">device</span>)
<span class="var">self</span>.<span class="var">target</span> = <span class="clazz">DQN</span>(<span class="var">self</span>.<span class="var">config</span>, <span class="var">self</span>.<span class="var">case_num</span>, <span class="var">self</span>.<span class="var">device</span>).<span class="method">to</span>(<span class="var">self</span>.<span class="var">device</span>)
<span class="var">self</span>.<span class="var">target</span>.<span class="method">load_state_dict</span>(<span class="var">self</span>.<span class="var">q_net</span>.<span class="method">state_dict</span>())
<span class="var">self</span>.<span class="var">target</span>.<span class="method">eval</span>()

<span class="annot"># optimizer and loss function define</span>
<span class="var">self</span>.<span class="var">criterion</span> = <span class="clazz">nn</span>.<span class="clazz">SmoothL1Loss</span>()
<span class="var">self</span>.<span class="var">optimizer</span> = <span class="clazz">optim</span>.<span class="clazz">Adam</span>(<span class="var">self</span>.<span class="var">q_net</span>.<span class="var">parameters</span>(), <span class="var">lr</span>=<span class="var">self</span>.<span class="var">lr</span>)
<span class="var">self</span>.<span class="var">steps_done</span> = <span class="num">0</span>

<span class="annot"># training</span>
<span class="var">self</span>.<span class="var">q_net</span>.<span class="method">train</span>()
<span class="return">for</span> <span class="var">episode</span> <span class="return">in</span> <span class="clazz">range</span>(<span class="var">self</span>.<span class="var"><span class="var">episode</span>s</span>):
    <span class="var">state</span> = <span class="var">self</span>.<span class="var">env</span>.<span class="method">reset</span>()
    
    <span class="return">for</span> <span class="var">t</span> <span class="return">in</span> <span class="clazz">count</span>():
        <span class="var">state</span> = <span class="clazz">torch</span>.<span class="clazz">FloatTensor</span>([<span class="var">state</span>])
        <span class="var">action</span> = <span class="var">self</span>.<span class="method">select_action</span>(<span class="var">state</span>)

        <span class="var">next_<span class="var">state</span></span>, <span class="var">reward</span>, <span class="var">done</span>, <span class="var">_</span> = <span class="var">self</span>.<span class="var">env</span>.<span class="method">step</span>(<span class="var">action</span>.<span class="method">item</span>())

        <span class="return">if</span> <span class="var">done</span>:
            <span class="var">reward</span> = <span class="num">-1</span>
        
        <span class="annot"># push to memory</span>
        <span class="var">self</span>.<span class="var">memory</span>.<span class="method">push</span>(<span class="var">state</span>, <span class="var">action</span>, <span class="var">reward</span>, <span class="var">next_<span class="var">state</span></span>)

        <span class="annot"># update Q networks</span>
        <span class="var">self</span>.<span class="method">train</span>()

        <span class="annot"># update state</span>
        <span class="var">state</span> = <span class="var">next_<span class="var">state</span></span>                

        <span class="return">if</span> <span class="var">done</span>:
            <span class="return">break</span>
        
    <span class="return">if</span> <span class="var">episode</span> % <span class="var">self</span>.<span class="var">config</span>.target_update_duration == <span class="num">0</span>:
        <span class="var">self</span>.<span class="var">target</span>.<span class="method">load_state_dict</span>(<span class="var">self</span>.<span class="var">q_net</span>.<span class="method">state_dict</span>())
        <span class="var">self</span>.<span class="var">target</span>.<span class="method">eval</span>()


<span class="var">self</span>.<span class="var">env</span>.<span class="method">render</span>()
<span class="var">self</span>.<span class="var">env</span>.<span class="method">close</span>()
</pre>
</div>
</div>
</pre>
<script>
lineMaking("code3", 91);
</script>
                    <p>
                        <span style="font-size: 20px;"><b>Action 선택 함수</b></span>
                        <ul>
                            <li>1 ~ 11번째 줄: DQN 모델 결과로 action을 선택하는 코드.</li>
                            <li>2 ~ 8번째 줄: <span class="highlight" style="color: rgb(0, 3, 206);">steps_done이라는 변수를 바탕으로 학습이 많이 진행 되었을 때(학습이 많이 되어 DQN 모델의 신뢰도가 높을 때) threshold를 계산하여 모델이 선택한 action을 내어줌.</span></li>
                            <li>10 ~ 11번째 줄: <span class="highlight" style="color: rgb(0, 3, 206);">steps_done이라는 변수를 바탕으로 학습 초기일 때(학습이 덜 되어 DQN 모델의 신뢰도가 낮을 때) threshold를 계산하여 random 선택을 더 많이 하게 함. 즉 학습 초기에 random으로 여러가지 케이스 탐색을 하게 함.</span></li>
                        </ul>

                        <br><span style="font-size: 20px;"><b>DQN 모델 파라미터 업데이트 함수</b></span>
                        <ul>
                            <li>14 ~ 37번째 줄: 모델의 파라미터가 실질적으로 업데이트 되는 함수.</li>
                            <li>15 ~ 17번째 줄: 재현 메모리에 저장된 데이터들을 batch size만큼 랜덤으로 추출.</li>
                            <li>19 ~ 23번째 줄: 리스트로 된 데이터를 torch tensor로 변경.</li>
                            <li>26번째 줄: <span class="highlight" style="color: rgb(0, 3, 206);">추출된 데이터 중 그 당시의 state에 대한 action 값(float value)을 가져오기 위해 현재 0, 1로 이루어진 이산 action 값을 바탕으로 위치 파악 후 action value를 가져옴.</span></li>
                            <li>27번째 줄: <span class="highlight" style="color: rgb(0, 3, 206);">Next state에 대한 action value를 가져옴.</span></li>
                            <li>30 ~ 31번째 줄: <span class="highlight" style="color: rgb(0, 3, 206);">학습에 사용하기 위한 target value를 만들어줌.</span></li>
                            <li>34 ~ 37번째 줄: Q network를 loss를 바탕으로 업데이트.</li>
                        </ul>
                        
                        <br><span style="font-size: 20px;"><b>DQN 에피소드 부분</b></span>
                        <ul>
                            <li>42번째 줄: 최대 10,000의 데이터를 저장할 수 있는 replay memory 클래서 정의(재현 메모리에서 설명한 class).</li>
                            <li>45 ~ 46번째 줄: gym 환경 정의 및 action case 개수 정의(좌우 2).</li>
                            <li>49 ~ 52번째 줄: Q network와 target network를 정의. <span class="highlight" style="color: rgb(0, 3, 206);">target network는 Q network와 동일하게 초기화</span></li>
                            <li>55 ~ 57번째 줄: Optimizer, loss function 정의.</li>
                            <li>60 ~ 91번째 줄: 학습 Episode가 일어나는 부분.</li>
                            <li>62번째 줄: 학습 환경 초기화. 어느 수준 랜덤으로 cart pole 위치 및 각도가 초기화 되는 부분.</li>
                            <li>65 ~ 66번째 줄: 현재 상태에 대한 다음 취할 action을 선택하는 부분.</li>
                            <li>68번째 줄: 선택한 action을 취했을 때 나타나는 next state, reward, done (cart pole이 넘어졌는지 여부) 데이터를 내어주는 부분.</li>
                            <li>70 ~ 71번째 줄: Cart pole이 넘어졌으면 reward를 -1로 설정(gym 라이브러리에서는 모든 reward가 1로 설정되어있기 때문).</li>
                            <li>74번째 줄: 이렇게 얻은 데이터를 재현 메모리에 저장.</li>
                            <li>77번째 줄: 재현 메모리에 쌓인 데이터를 바탕으로 Q network 학습.</li>
                            <li>82 ~ 83번째 줄: 만약 cart pole이 넘어졌으면 episode 중단.</li>
                            <li>85 ~ 87번째 줄: 일정 주기마다 target network를 최신화 해주기 위해 Q network의 파라미터로 clone.</li>
                        </ul>
                    </p>








                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>DQN 학습 결과</span><br>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        아래는 학습 episode별로 cart pole이 버틴 step (duration) 수입니다.
                        Episode가 50보다 작을 때는 20 duration도 버티기 버거웠지만 학습이 진행될 수록 오래 버티는 것을 알 수 있습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">그리고 gym 라이브러리의 최대 duration 상한선이 500으로 설정 되어있어서, 그 보다 더 버텼더라도 학습이 조기 종료 됩니다.
                        따라서 최대 duration이 500을 넘어가지 못하는 것을 아래 그래프에서 확인할 수 있습니다.</span>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemdfNrGWBAS4RTF7xDv8SXNTKZ3BTaGFX_id3BtFQEkL49EnIh4S_minuOEO7ZWrMiR-FQV5nHyhsgUhks6LGNsJvl9PoFMNCNyybMRE0Dc9hgrdRGaCz8lidCeBssHnKJVpilAIVTnAO7AtNN8ebV1SF4QI68wxrfOyrixzcCFRtId4qJFL40eyR_O-8TfWGoan_8PtYCQJtemMBguE9lNvd6-0HY9W3QjEsy9OKBrMiTNyMXHoZU5nBwjdHKZeYlSUMZyeduf4isOvk9eSso1wrqJk3hlulu0FF_Pz6cBTF4R269rAUmRYdXzjIEfL-OFy83IoPAE2mv_kRitJ3x5G9yEErnJydDLYmK9Ven9evEwiepVI5DS3f2HW6tkePx02dPjZcfURPegl124NywjCijN1yiNnKYR0ewbuXkGTkYlW9QP47JjLd4LBpFtGSVUZNVlN9_cNPPsuxt4M3-KW32ZCwYd_XMm1GRJQ1oftGKZbTJljljVOKvSMkbBPfpC1IBfuKvTh0ZgNT0wDyba8kDKCQ_6EuTeDDncHSj2YY45x7kf7QnAa9TE_r-02BWWVu1Q6ElSuoGP4JQDZXy_rO4rTubXFsPSgeLGsUeRDhGo2ln-i3SBNacJCVu2gHXHRsZizjrQqCT5bQOB6X4APwMi9vYt0IbepKX3BpkHjnuz89P0Ias4PP7trQShTk7FmTx_Q0jzlU9OmMpWuEkK0xGaJZ8kVzSvpNsT_jZx3YMb2Ce4-ZGDVIacnJoU74ILmoHgSQ5GNPunB3UvUdNCbSqhrPozleDwAedF-EjOvvSYaTuK9AwT_REHAp0MOAJnKSBqJdqhnxNULHQjXAVCpTap_cRULAwkdrdxSl_ngTKUPLDUyvoE7AKl6vwGJ6NFsqnZfx11irVB1Lkp0JWlr2AL6I2DpUjNiHiZTemcLtZ6CM7_TKD8jJRwfCCcskBvtAxfCYJPIrT-6f7M1Qeb3__oXqPf2KXbod1psZY03t0HNxJoqwU1JHvxEg3tlkQo4c_faIybYNQ1TmL5R5VJVbhQhFhTLDylHyuVXSgSvVvmPjVsqM-T9kUqvit8fFNpmuR5143HukrFJ1wbbqT9FAxqf-xK4omD7lBXuq7mICdBRyhGoxe8Jo71LN2scADNtloLmUlXlkfV5Y3pXss6J8CuqbvDvlXGYBrh6Spt2Yx7s-G6lf5ncJV-r_igwVqmcjgRreKloPWm4rj57hA758FaIbHLi89OSaFc3tOioP78MQ9WBE6c85Vqphaq9clIQyfWdlIPlbiAoPFLzOo78OzmNKQ3709G4v2cdszMLAMGzzWxhlqkbn-be10qnQXGvpMfyijlpxBO5VFTLpwa1QxInu0f3yT-hp-gT91uGEG7yYNeb44QUsKiJSi6KevIsJEcqaBsQE11EWhxlYxaKyJYHmsPi9Bs1nUJkEATLBVqGoSE0zAo4AvxoA7HVIAZff0fqMSqVQ1VLHwM" style="width: 100%;">
                        <p class="caption">학습 에피소드별 cart pole 버틴 duration 수</p>
                    </div>
                    <p>
                        <br>아래는 episode 중 500 step을 버틴 cart pole 강화학습 결과입니다.
                        학습이 잘 된 것을 확인할 수 있습니다.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemdp1d3w1fEfom247Eq3VXYU9cN-nLE6tCDkStmS-1p-m47oQKI5etp7MYHa8aL_r42QnAeMdXv_7Q7O5rXoVGu7D_hDuczdmjLXsU1vmDkB5lHM6UH4A3CIbuW96eL2RAM99GtphG8-uhKb6O5N-IA_MV5Cw385usKUhl6zpiwCCVaUyGZbQpA9JOUKJxr4LdxmTwS52yrsEtTNw_WlSniPeFInydpM8A0lqqMQD6ft9uFqXaJf5F5o40Qeyyrlq9qDBouaD_E08ALxvPcfF_HHr7G3JuTreCG9hbITVoIh2S33h8fPARDeWiQCMgQlXH2Nbe2FlNyfk4aAh_r6fmzocnL3SISWseKY_CAWkxMlMNdp9xX4Kym3SMd95SdJBPCbuO5yaiAysouWP8gKmFzz6xnJYqG9Gc_OKkZOMUezoF6lAf-Ek5iAatS4Kc6uWAbS-HZwRjuLJ_XFYei5FXkCH3cL1k6epii3uGJV3PflizFkijGGB2VLpLDQPYESkfQ5ukGIcaz2R-GdqItabAtS1koxOD1nc_0ttrIM5KQ0jpewUVzqBfDRg-mdc2EnmnOaFbrRYzFat9YrB104-8gTD0SsAuwCyfDTAz40vzbs9iGEGyZl_l1dJrzGqJzwaOpbkRzdsIzhRF8mvu3cCAPuZ9EdQL49Ca6_SieT3dB_rbjyCp_NxollLhhw4k9f5qVHQwmfp2WCRpMtqNf5nP5-wcm_78iqroa3-GAqqJTJz1-6MjJNeXRhUukVlh8csvjAuoRqgy5BWiREO0C00UgNgXlgFmpEcqOPE_D9fG_lNV15xHBaH2SUTzn7i_FyfC-PbpsGQwa8QEQcM1hYBPuc5TKe1Y-Cm04AyLrLraFRNIymjaiLxXhCleSEqnMUFgO1psTd9BgMlADbNA_bWpvLsZg2SBZcZ1CvvHQImjcHSJCPQNp9SRnyrH6_figjw4bGynabDCxbZxEKAZaJ62pIRMSEuanZUZov0PI3nm-K0NiFs1OXteXlIeN1_8Dav2MdB73UPUpjPIr5PXqVh8tL3b2r_ymXnnu6npid-dWOo00nAmYRJXK7C7B4NwVHMgpqS5HZEtmptIUZK4GV9rHA-ul3o7vJQxBeyneAmsCmm2QdtShw9jeCD6PhXAhHnlrZ9XCTdHUpd1vh5aBwoMdWvDB6bCPRxpeIlCkidSl63dy0JrGwTKuMmDhYaLxeOe-wIKMzmp5DHVuwqy_VjvN6ggQuhuHg1-fa3_7RSfq0gY8TU9eG8k1Ga8fuSXvJ9ka44-sRXdJqC9Yio7BUdaAczftddaS3AjKTG2REflBJZc-LmQftoGI1TNXcvbe6tnCzdsnkIiyHKCJw1jz3Gs7C2pwL-dapwssBw9UV0rdHOuqyEQI94ViPzW9HD_sIlydpQEoeCK0rR53Z4qnRSgvGy8bvaUAf8zT7ztEHs7zhiwapALXp8lBxXZn0fJfe_SRQk53ijQ5aMVWBUvI" style="width: 100%;">
                        <p class="caption">Cart pole 학습 결과, 500 duration</p>
                    </div>
                   

                    <p>
                        <br><br><br>지금까지 DQN을 이용하여 cart pole을 강화학습 해보았습니다.
                        이렇게 간단한 task는 DQN만 사용하더라도 상당히 잘 작동하지만 복잡한 task에 대해서는 여전히 불안정한 감이 있습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">여담으로 OpenAI에서 개발한 강화학습 알고리즘인 Proximal Policy Optimization (PPO)는 간단하고 성능도 좋아 최근에 가장 많이 쓰는 기법 중 하나입니다.</span>
                    </p>

                    
                </div> 
                <div class="tag">
                    <b>태그</b>&emsp;#DQN&emsp;#CartPole&emsp;#gym
                </div>
                <div class="pageTurner">
                    <div class="pageTurnerLeft">
                        <span><a style="position: absolute; left: 0;" onclick="pjaxPage('dqn1.html');" onmouseover="colorOn(this);" onmouseout="colorOff(this);">&lang; 이전글</a>
                        <br>Deep Q Learning (DQN)</span>
                    </div>
                    <div class="pageTurnerRight">
                        <span><a style="position: absolute; right: 0;" onclick="alert('DQN 마지막 게시물 입니다.\n\nThis is the last post of DQN.')" onmouseover="colorOn(this);" onmouseout="colorOff(this);">다음글 &rang;</a>
                        <br></span>
                    </div>
                </div>
                <span id="readNum"></span>
                <div id="disqus_thread"></div>

                <script>
                    headHighlightColorChanger();
                    (function() { // DON'T EDIT BELOW THIS LINE
                    var d = document, s = d.createElement('script');
                    s.src = 'https://novicetraveler.disqus.com/embed.js';
                    s.setAttribute('data-timestamp', +new Date());
                    (d.head || d.body).appendChild(s);
                    })(); 
                </script>
                <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </article>
        </div>

        <div id="menuRelated">
            <div class="menuButton">
                <img id="menuImg" src="init/index_img/menu_black.png" onclick="openMenu(this);">
            </div>
            <div class="menu">
                <img id="menuExtension" title="메뉴를 확장합니다." src="init/index_img/extension_black.png" onclick="extendMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
            <div class="bigMenu">
                <img id="menuCompression" title="메뉴를 축소합니다." src="init/index_img/compression_black.png" onclick="compressMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
        </div>

        <script>
            detectScroll();
            pushFunc();
            detectSize();
        </script>
    </body>
</html>