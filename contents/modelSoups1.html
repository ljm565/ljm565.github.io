<!DOCTYPE html>
<html>
    <head>
        <title>Model Soups</title>
        <meta name="description" content="모델의 성능을 높이기 위한 방법 중 하나인 model merging 기법의 model soup를 소개합니다.">
        <meta charset="utf-8">
        <link rel="stylesheet" href="init/index.css">
        <link rel="stylesheet" href="init/contents.css">
        <link rel="stylesheet" href="init/index_img/icons/css/fontello.css">

        <link rel="preconnect" href="https://fonts.googleapis.com"> 
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> 
        <link href="https://fonts.googleapis.com/css2?family=Dongle:wght@300&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Gowun+Batang&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic&display=swap" rel="stylesheet">

        <link rel="stylesheet"
            href="init/highlight/styles/github-dark.min.css">
        <script src="init/highlight/highlight.min.js"></script>
        <script>hljs.highlightAll();</script>
        <script src="init/highlight/highlights_line.js"></script>
        <script>initNumber(window, document);</script>
        <script>hljs.initLineNumbersOnLoad();</script>

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        <script src="init/index.js"></script>
        <script src="init/jquery.pjax.js"></script>
        
        <meta name="viewport" content="width=device-width, initial-scale=0.8, max-width=1">

        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-219110982-1"></script>
        <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-219110982-1');
        </script>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7745178886614102"
        crossorigin="anonymous"></script>

        <meta property="og:url" content="https://ljm565.github.io/contents/modelSoup1.html" />
        <meta property="og:title" content="Model Soups" />
        <meta property="og:type" content="website">
        <meta property="og:description" content="모델의 성능을 높이기 위한 방법 중 하나인 model merging 기법의 model soup를 소개합니다." />
        <meta property="og:image" content="https://lh3.googleusercontent.com/fife/ALs6j_H2Avelwmv_HovZ-VRiNpMXklUv8N4guqcm2XYAR4M4Z0WOLhjS2lXZU8xkdTRhcGsfBnoGfI7tOwKiYeE0y673rWxRw5Rk1FaRiVxz2BWlY5jwQXEEHbwG9dD6DK352-ZkU5svf-dZvJ1uFg5HerT38Usv4Nqem2pc9z3PGaRfnPICpfS94_gaJubkKk-r3oarGTxOmU9Ue2D1JKBLgTzW8HRlOaUNUiVUf5T6yI8olNXy6qIKkLya3yuaWx5DcVkIL_tsDiPUmBjbQv7VyNZrb_8oEfnhRnjoFDngcGfi0LsqJWGh_inXqCzIGTq0nCHEmtw2YE4CKolGCv_qN43z3ZL7jfydmGfZsM8EPv5VNRI2v72_AEibcKGpuVy3RdlXrc-Sbhgk2vDAAbAlcUDEY5VEibYpMhWyl-VBFSLNrKkFaLyTg-R0m0cViJLL9g_YaY3kDuTckhKLhYU4dWyNHZ6tSnZ_oRlv_AzckaYOcPpq68W8ehUfTfmwIoG6XmPRx1KXJqvSr9tdHOSATir0zOQSX4TPNOxYNi9qAucxA7psh3PjHH1SAGFT3yPxvNCFTGem6M7xd2wblYPZcTcY6i-E4ClwkjBuCGNMjqt0ahB7Gix-MfY0_BzBjPBLgTb30OxjsWHKlwdYVQVM_jujOkyrIO4yfE51qwacEUtVNZ1i8lRcZjnpvVYbT5w3vlVYIPHG3PC3h9uy17sj0szicWf70HwYoBjGkhMiMauvxqbp3FRCJbzrc479GpUWu7ZB1jImJpVA-6i-IIcksOkr71hPj_EPFMCinxAJCsa3ts5gFlupUrxCsBF0sk-Rjo6VbjOcCZWccdGGr2n7aA1cblvw6YMm41K_OHvOB0qEaD3In9kSIZfxfvgZDIDXHhPi8fBMfBjNXXEh46RKA3Lmguk9YxIQoC214MaUjvaxZmtHM399VhGEImmzNt8cSSnY9th725iy3-UKvq3AwlKJTM0LB_cVGW9bzHBK8gbwjsrMmBfFiGHAhbE5H1kOgA5vp-CdR3IRvwwyRQxMNSDJXJVrfViFDw0-LpgM21P6X5r2ldKrZxZlxVV970ho4FgEDrVZo076I3MppDn34QOf6X9drk5PpBmOCo8EEaNowZ5Gpsrs2HKJ4aFa-KQaANfPCp08824mZlSLrL3AaxhdDJouVCc3qfQ0OiOK6HzfxEq_7J_B2i99EbWs1r7ZH7C8HIvJurhm4PgevGPtiZVWCPmbtd9kWjC5t_Msjsy4ZWt-cenBlt1pGMEN1baFI_hJ6LMwuLXRx5QzS-hXsZlQ7ZJroxv_0vPSBd4E2Xorrb2kOi7MG8ue90RXYqBT5qlUgY_jncvE2Xv2T7ZrB15F-p8YOiy_u9UalxSIYExburnJkm8uYYYFObuCFRI8WxxoEmBYQ6mVLnkbDUhllqVoeFyiHFzPm2-E2I51hgms4yMM-ekOUGMhZVOc4_mG0daBqf6Y4CPok7S4X9YfPbK-SAp0oVX2Bsjih-JacJdL84hYi6pQV_g_zkRYtMA4tDWzs4jPHQ" />
    </head>   
    <body>
        <div id="modeButton">
            <button type="button" value="dark" onclick="darkMode(this)" onmouseover="hoveringOn(this)" onmouseout="hoveringOff(this)">
                <div class="modeImg"><img id="modeImg" src="init/index_img/moon_off.png"></div>
                <div id="modeState">다크 모드로 보기</div>
            </button>
        </div>

        <div id="container" onclick="reload();">
            <article>
                <script src="init/highlight/highlight.min.js"></script>
                <script>hljs.highlightAll();</script>
                <script src="init/highlight/highlights_line.js"></script>
                <script>initNumber(window, document);</script>
                <script>hljs.initLineNumbersOnLoad();</script>
                <script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
                <script>
                    initMathJax();
                </script>
                <div id="mainHeadWrapper">
                    <div id="mainHead">
                        <h1 class="contentHead">딥러닝 이야기 / Deep Model Fusion / 1. Model Soups</h1>
                    </div>
                </div>
                
                <div class="title" style="background-image:url(https://lh3.googleusercontent.com/fife/ALs6j_H2Avelwmv_HovZ-VRiNpMXklUv8N4guqcm2XYAR4M4Z0WOLhjS2lXZU8xkdTRhcGsfBnoGfI7tOwKiYeE0y673rWxRw5Rk1FaRiVxz2BWlY5jwQXEEHbwG9dD6DK352-ZkU5svf-dZvJ1uFg5HerT38Usv4Nqem2pc9z3PGaRfnPICpfS94_gaJubkKk-r3oarGTxOmU9Ue2D1JKBLgTzW8HRlOaUNUiVUf5T6yI8olNXy6qIKkLya3yuaWx5DcVkIL_tsDiPUmBjbQv7VyNZrb_8oEfnhRnjoFDngcGfi0LsqJWGh_inXqCzIGTq0nCHEmtw2YE4CKolGCv_qN43z3ZL7jfydmGfZsM8EPv5VNRI2v72_AEibcKGpuVy3RdlXrc-Sbhgk2vDAAbAlcUDEY5VEibYpMhWyl-VBFSLNrKkFaLyTg-R0m0cViJLL9g_YaY3kDuTckhKLhYU4dWyNHZ6tSnZ_oRlv_AzckaYOcPpq68W8ehUfTfmwIoG6XmPRx1KXJqvSr9tdHOSATir0zOQSX4TPNOxYNi9qAucxA7psh3PjHH1SAGFT3yPxvNCFTGem6M7xd2wblYPZcTcY6i-E4ClwkjBuCGNMjqt0ahB7Gix-MfY0_BzBjPBLgTb30OxjsWHKlwdYVQVM_jujOkyrIO4yfE51qwacEUtVNZ1i8lRcZjnpvVYbT5w3vlVYIPHG3PC3h9uy17sj0szicWf70HwYoBjGkhMiMauvxqbp3FRCJbzrc479GpUWu7ZB1jImJpVA-6i-IIcksOkr71hPj_EPFMCinxAJCsa3ts5gFlupUrxCsBF0sk-Rjo6VbjOcCZWccdGGr2n7aA1cblvw6YMm41K_OHvOB0qEaD3In9kSIZfxfvgZDIDXHhPi8fBMfBjNXXEh46RKA3Lmguk9YxIQoC214MaUjvaxZmtHM399VhGEImmzNt8cSSnY9th725iy3-UKvq3AwlKJTM0LB_cVGW9bzHBK8gbwjsrMmBfFiGHAhbE5H1kOgA5vp-CdR3IRvwwyRQxMNSDJXJVrfViFDw0-LpgM21P6X5r2ldKrZxZlxVV970ho4FgEDrVZo076I3MppDn34QOf6X9drk5PpBmOCo8EEaNowZ5Gpsrs2HKJ4aFa-KQaANfPCp08824mZlSLrL3AaxhdDJouVCc3qfQ0OiOK6HzfxEq_7J_B2i99EbWs1r7ZH7C8HIvJurhm4PgevGPtiZVWCPmbtd9kWjC5t_Msjsy4ZWt-cenBlt1pGMEN1baFI_hJ6LMwuLXRx5QzS-hXsZlQ7ZJroxv_0vPSBd4E2Xorrb2kOi7MG8ue90RXYqBT5qlUgY_jncvE2Xv2T7ZrB15F-p8YOiy_u9UalxSIYExburnJkm8uYYYFObuCFRI8WxxoEmBYQ6mVLnkbDUhllqVoeFyiHFzPm2-E2I51hgms4yMM-ekOUGMhZVOc4_mG0daBqf6Y4CPok7S4X9YfPbK-SAp0oVX2Bsjih-JacJdL84hYi6pQV_g_zkRYtMA4tDWzs4jPHQ);">
                    <div>
                        <span class="mainTitle">Model Soups</span>
                        <br><br>
                        <div style="display: table-cell; margin: 0;">
                            <img src="init/index_img/profile.png" style="width: 30px; cursor: pointer;" onclick="pjaxPage('/');">
                        </div>
                        <span class="subTitle" style="display: table-cell; text-align: left; vertical-align: middle; padding-left: 20px; line-height: 125%;">작성자: 여행 초짜<br>작성일: 2024.01.17</span>
                    </div>
                </div>

                <div id="content">
                    <p>
                        시작하기 앞서 틀린 부분이 있을 수 있으니, 틀린 부분이 있다면 지적해주시면 감사하겠습니다.
                        
                        <br><br>이번에 소개할 논문은 모델 merging 기법으로 소개된 Model Soup의 논문입니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">현재 LLM이 각광받고, LLM open leader board에서 SOTA를 차지하기 위해 최근 model merging 기법을 많이 사용하는데, 그중  model soup는 시초가 되는 방법입니다.</span>

                        <br><br>실제로 model merging을 하는 기법은 간단하기 때문에 쉽게 따라올 수 있을 듯 합니다.

                        <br><br>아래는 Model Soups 논문 링크입니다.
                    </p>
                    <div class="link">
                        <a href="https://arxiv.org/pdf/2203.05482.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);">Model Soups 논문</a>
                    </div>
                    <p>
                        <br><br>오늘의 컨텐츠입니다.
                        <ol>
                            <li>Model Soups의 동기</li>
                            <li>Model Soups의 방법</li>
                            <li>Model Soups의 결과</li>
                        </ol>
                    </p>



                    <h1 class="subHead">Model Soups</h1>
                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center;">&ldquo;</span>
                        <span>Model Soups의 동기</span><br>
                        <span>Motivation of Model Soups</span>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        Model Soups의 동기는 fine-tuning process로부터 비롯되었습니다.
                        먼저 우리가 어떤 특정 domain의 모델을 학습하기 위해서 보통 pre-trained model을 fine-tuning하여 사용하는 것이 일반적이며, 아래와 같은 과정을 거칩니다.
                        <ol>
                            <li>Pre-trained model을 다양한 hyperparameter로 여러 fine-tuned 모델을 확보.</li>
                            <li><span class="highlight" style="color: rgb(0, 3, 206);">그후 validation set에서 가장 높은 accuracy를 보인 모델을 선택 후, 나머지 모델들은 모두 버림.</span></li>
                        </ol>

                        <br><span class="highlight" style="color: rgb(0, 3, 206);">저자들은 이렇게 fine-tuning하는 과정 중, 위의 2번의 방법에 문제를 제기합니다.
                        2번 방법의 문제점과 이 문제점을 해결하기 위한 ensemble (앙상블) 과정을 아래와 같이 주장합니다.</span>
                        <ul>
                            <li>Out of distribution dataset에 대한 성능이 보장 안 됨.</li>
                            <li>여러 model을 ensemble하여 성능을 높일 수 있지만, inference cost가 \(n\) 모델일 경우 \(\mathcal{O}(n)\)으로 증가.</li>
                        </ul>
                        
                        <br>따라서 저자들은 위에서 설명한 fine-tuning의 두 단계 중, 2단계를 개선합니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">저자들은 여러 hyperparameter로 fine-tuned 모델들을 merging하는 방법으로 개선할 수 있다고 생각하는데, 이에 대한 근거는 아래와 같습니다.</span>
                        <ul>
                            <li>같은 pre-trained model에서 파생된 fine-tuned model들은 비슷한 loss basin (landscape)를 가짐.</li>
                            <li>Ensemble, weight averaging은 좋은 성능을 보여준 사례가 많음.</li>
                        </ul>

                        <br>그리고 저자들은 model soups를 사용하면 추가적인 학습이 필요없고, inference cost도 \(\mathcal{O}(1)\)이라서 추가적인 inference cost가 필요없다고 주장합니다.


                        <br><br><br><span style="font-size: 20px;"><b>Intuition</b></span>
                        <br>먼저 저자들은 다양한 hyperparameter로 모델들을 학습한 후 아래의 loss landscape를 그렸습니다.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_G89x218VM7w_VrFYGCOm5tJrt9w3sKhr0-4juqLCWYDxsiJHNTLa5d6GgSjtdnrxvuhDI-_Ugl51flYCXajbW8Oe9hNjvioTx38359MI4fXJHrTGvTKJ5oVSXIVRodEWncqUDIAPGXz6Axo42n14Vxvv9iOihhhCzdbun-i1Q5gqVpJ4sEKVY8j6SDVSK7g8NzzmVW3VSlNddMwW5CZxMQeIeUQR1zQ1d5BCDi3S_8R1VGfKgQH3fWdJ73DqXySsMDwoxhcEB9az9IhImL4FXZFfR_kq-kNfUJ6UOGO77J9oO3ck4AMantt5QWoOyA5D1L0QJQNxE7x4rTXLQtu9ltkzaVvSTXdBcq8h-y4CeQvb3x-0hPi7DVZttoTPGYcWd4VBjpFgtFU69IN4O7ln24XADdJg_wHQfXloKzwp3k5Rcbk1YJ5OtbzAFjDT2p797WJiCByb7AYmCUbXcY1inlR4R8Tvb6r--PH0BB_i_3t3JH5QF00vb9MTdR3GBFXCw-cKsCxPhg2R6x89cCX9U7Mkv7ivoPygu4POdoEHVxqMf8zYQeiJaQIuBJDAiOZcWdbNV48dQ1kHI8r1Ujga9Mo1dhf_Kj4DuTv7zoyqtpXWdd2hMhvEv4_0kXEI-Ltz1XJd2D52PhYXrLK6S2oTcOYRHp6PVblJzG39yKGSN1jq3W6AzyEVU5dwrkOjiILwUV5eX6dvsCi0Obq6Etd3VzP3QNkzfdBmPtW5oekJ2uHDQSL-L56MMdgH91sEQX_t9-le6A664IS2lqw9RnzzoMLRedYA5Hq-gR--H0OuVGUNBx5PXyjZEeD0mw76B8GHdYrjur0HhgJpQjWmY8N4tngMMCeRpf6gAycS4Wlw3EOg85FP9fTN4cnMGUOih_YNUSiO8pWIw8mdK-5ZODnpIRItNGb8pppgJbt35280AKtbillKhlKHGvG29JoFLutddj17xmCsN1ny9qO2S7W-FramlAWk5-2am2UQ0NRa8ho234Yrzb09JAI1ULk-nI6iX3GfE_D0yuBY9nxixgWijxc029cXmah5J4V3Wn0Y7SdzkugLrLpYBfiPOMkzO9xJx2_aJ9VeiZN1OHFXEYaSJ66bTjqpYsRgSld61zSexXkRugv5QszEu_9puzPH63VWS8nuF_LIsbm-1jgVOfCDctaWdxVfe7cw-9UU0tNaT1YkJIq-ljmcy7AP4CMzDuR5QTJW1oTjGIRp78X9hGPArX_BrqUkLN9NEemec3_ec3GsiuufEXIAw73x3ZhNdmTbTePeNkiyjrL6BY2V80j2n6gSJhR6bjXi81Tw6GpYTN5lkSUNWx9IFqLtupwnqT11qcYpunphiOUAyRQIJ1SSPOD3PK96Cod56R7K1rJKc_U93kSE7_L_FPr8IqWU6tAXPMnYq6vYzyBKt76yhX53UHhxEdesRuuKBwQbI2czOduWdOu_221KpLVMDLO15n919Z7vqqze-O3kdZ-bGwvMMTbxO21gTwf0aLKSaPuccBRAIqGHxX2qbUgvHE9LRAn17KSg4lOa1u" style="width: 100%;">
                        <p class="caption">Loss Landscape, 출처: Model Soups 논문</p>
                    </div>
                    <p>
                        <br><span class="highlight" style="color: rgb(0, 3, 206);">위 그림에서는 3가지의 다른 방법으로 학습하는 방식을 가지고 학습한 모델의 loss landsacpe로 그린 것인데, 빨간색의 부분이 오차율이 가장 낮고 loss가 가장 적은 좋은 지점으로 볼 수 있습니다.</span>
                        따라서 저자들은 저렇게 optimal하지 않은 두 모델 사이의 가중치를 interpolation하면 정확도가 향상될 수 있음을 시사합니다.
                        
                        <br><br><span class="highlight" style="color: rgb(0, 3, 206);">그리고 모델의 loss landscape에서 보여주는 각도 \(\phi\)가 90도에 가까울수록 uncorrelate하다고 볼 수 있습니다
                        따라서 저자들은 각도에 따라서 실제로 가중치를 merging 했을 때 정확도가 얼마나 향상될 수 있는지 경향성의 그래프를 보여줍니다.</span>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_GfhEJsGOfaYM2DxgwMejfZGaFidHBwOShr6tnPw6Irsh5zfYmwrFWwWRxgt9uod6z4NYdh_vDyHNo_53RM7RDNwh4cqR9UMuMgstUX5NrDS3yBiv6PKhQeP9mUTxImkray7qZhuB_5bVibktHNGTsnTiHCGl5HmMx5adJ6Cz9BnMSrfje31LqadbmctcuGz3jkCEpEmtVI1W4iRMEjpMCx-YQvWf_DjaDSxhg1GBb9t6SpCRdpp_Vl3Xwr4WkHAA_e6cRU9oa_OxonuJHu3kLDsbqFo95KSaKMQqsusofKQQJlh4so3gA6gFswuGSqp2d10p98V87oJQ4eZZrdJeCSuPJEO6qfo7LnUNvv1YeV0yiwlipfmJxjUXyXkPygTu-vIgd_7ymxYNJo152dyhO27N04FXe1k-4fFzjJvlCliEzQjtcI0ko2rqQJ27mF6pm_3Jay7TLMHeqt0WdMCHcS9ynN-Sg4FJquAEN4i17TnwWshK803qsD7wFzNmoyFlCwLeZ08HWdYgBUhOUPyqI-9vfEsUqY-2uOsaNwxL-BCqE9FFDrq76K1IyL6TR1GLeXDQeDLmgF3dEZGzcO4m2Hn7Nxugp_-kBNQgm3bicKTj1BEV1BicYVzceaohRYi07WX__A4J94q37STLmmdXDGq42CbD-rQQnHV2ISukrfy8xDGZJDYPs3_sdx46ZnQ5T8MWe582dTZaJmISCRZKqHD1kCnKq5PnT12sLKkD7-Lmsc7zep1GeATfGqm7oe7NjSLQLXkEhbASCDxtsOXlEKFZ0MFh1wq6kInfBgCsbL8AmZUmLzSpdGhbNq1OjZc4s84CBnjM06gmK7DI_ReSbegaY35jFd0o91sRNDZFxo4m8g2GaqqhUABVm297lw7K2VW4fxE2kdiTC895DhE03ka7I2-SuwLGf8P7ez8xQW1N0sJLLf-YxJxGD_sjqZX9iSgpruRtUpcKQlcH8y5SEwoNJ2obUETZVwTm2wVKdgrGmMB9FvKyGijEdHs-g1oORTFqBZiEICGmi6peaTcywfFtFl-rRGVeAHt5UmN10V-e9NPUsNJnTpvavL9_89N8Q9yuv9mWben5A1Dakd-ldMRYwB4vWJwclr2RWGqE1YoiorTLuCsRSxuiGncxq230rpIM8ocJOmz4sYXyD6uMfBnC2PrgSoN69nSo0BNsN8zwbYiwK6ZWY2MStKQT1wkbaEw-BwtxCwWtlOJLJYW5Zkm5kusMuFCDUS6WzzWs-8LXt6_Y0dHNnNCp7U9WI-7ZP0v4N9CjdQXxxd8NwsJXskBT4t-5fjUPMZ3UcFpX3iiyKIhyiZ2-ji2T5x0QDSs22c27FBXfn71XzRGia14IBzeRAMr344E2WeDbhQ7OrM7U5a3CWxSuw4QeqxvMUBXlu8_pNEg6F9TuyoacoVhsZJmVUtacIQfqv2iN5ThUTb_kxGECVEIf6sJgyl2EaHjt3hF9oFlLUR6vjaoy3wIYLwhlKTssXhBw0F4qamHHvppGBGV_9c8UDqgzBRrYz9H_-GAuXWiXn6" style="width: 80%;">
                        <p class="caption">Loss Landscape 모델 각도에 따른 가중치 merging 시 개선률, 출처: Model Soups 논문</p>
                    </div>
                    <p>
                        <br>위 그래프의 y축을 보면 두개의 모델의 가중치를 평균내어 merging 했을 때의 정확도가 각각의 모델의 정확도를 평균냈을 때 정확도 차이를 의미합니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">즉 y축 값이 커질수록 모델의 가중치가 합쳐졌을 때 정확도 개선이 큰 것이죠.</span>
                        결론적으로 그래프를 보면 두 모델이 이루는 각도 \(\phi\)가 커질수록 모델 가중치를 merging 했을 때 개선이 많이 일어난다는 것을 시사합니다.

                        <br><br><br>위와 같은 이유 때문에 저자들은 model의 가중치를 merging하는 기법들을 제시합니다.
                    </p>
         


                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>Model Soups의 방법</span><br>
                        <span>Methodology of Model Soups</span>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        먼저 논문에서는 아래와같이 표현을 정의합니다.
                    </p>
                    <div class="equation">
                        \[f(x, \theta) = Neural\,Network\]
                        \[\theta_0: pre\mbox{-}trained\,model\,parameters\]
                        \[h_i: i\mbox{-}th\,hyperparameter\,configuration\]
                        \[\theta_{i}=FineTune(\theta_0, h_i)\,model\,parameters\]
                    </div>
                    <p>
                        <br>그리고 아래 표는 우리가 일반적으로 fine-tuning하는 과정, ensemble, 논문에서 제안하는 방법 3가지를 제시합니다.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_FY4rrVAwF0kB04dH_Y_0sGDmWkTTLyZXP7ocMdAzPLhnhBRJgK96DYTNfhS-DRPsORFGqQ9H-MU4521R4Iua5JOu9B7uyILxEAr8GNqNjzmmU4USziZpb-wS-JiNEtaSbnkqODNW9_ahJzz4i449Hn_ilOQn7fKcDUABru7DoePZV8ryt7JlRwjMo_ZJpB7dQ6CIEjXKK-WLsZUPvxUI-5fxkXUeYdfFdzusoPcMYvbA1-OL9fEsXfqlz_gsmvMf0CYJBZBln-6Am9p6JEFo3CvTomMCXJXd5ESlfTBOFqTzRp6I66YE49UW2hEAs1GIdAwMjJ_SOGo5GppgeO1tf78ftIAHqgu2L8TBZa0vyU7AX1R6xfpXthT0hmS6ZqoMqQ8bd4ELIHe6FXy1FlQQC0OpVZoLVm4KtkWxGn3Y3xS6J5_-KyutSw7cTKLP2taQ4uUfCYleXWOGCu0Fse9SuXV9xpuYjsETJYUoxfpSzX2LNb9dVOdRZhOoVNYFt2fsMMsQIK8imydu5ij7I_vtcSFjzZPWCEHhQqyhqBBctL6R3PLqnCK9-gj3jYK7wR_sDzFGKU_af9ws-JzrombD1hGOTCselHDirES2k_A-YY82D7q6kkBpavDuWETB4UR8Tghb8h-PlHKkBno2y38LADB3TlxmInb3wjlO44Cags-n3dSFALw9D1mdzyCcE0EuF3qCM6WqXP49f9oLq7ubGE1ZbxuchzgetBqStGINex3FCQvbZOV2mOKSwu6SR6R2tIRvw0sTgqP5Pf7oO6y-GqBLikTg8JfxD3xkR1Zb4O51k_lo-GyEy8j0_A77JmZARXivk9Z3HqfWlKeo3SDx3Ku8BhLQjjNSVZdzWStPm4_xChcTCMdPyi7Boe2UgDZFQEnVusLs_Sf-wwp_I4lR8hso6Xcf8B62Qk4AnyONQNihCbapzZFfbRWaxTiIpPFrB8MCmfEzulfptlYRhUr3ROi_0-45tUocn9hCnTNaFfO2971O6XHwoawMPH-4toL3QIB4GeVMQ27TbXIbOQsIEyvXEucdhOHJKjG2S4Xh4UJcU0L5NkKft9UYI4hi3nQXmx5ULVclvgKXQsCgGa7BZ4eyum34idqfU8oj5F7ZL7ZrPYipKENi1GcmbmTnf2BoQbMpPd9y7iA9rpyEagTmujH8cefJy6QgeR8B24M-Hg-2t5loeicYiaRIddy5V1YMzjd-lK5Uy4e_5Y848FOJojGqYarDZl7vkzBxfMwQ3p55d_UlJdEZNeUtcUlVI16QTx8m7WxaOzsR0oSTe-CN8pZ5rHC2efF_WSaS_aigjY5UNsv8QzFDs5dQqzcswzUR2QNRDV_u3rMDmDrbOHv_grbwr7M92mXFdhX7u1DjOsDa-BexG_Yn8wPCa2unLs_4PAvSMAN5-qTKmHNrVtzdadvDIw7xjO268knisWD2PwWu21-z6kvJ9-eXRAvYUKxJ5gYEB0LfTqFNFrBoG9QB8NxPAB16FYgKbLxRNsZzx4hF96J5CHzLPKP9WuIK0HbX4eLXHOkls7" style="width: 80%;">
                        <p class="caption">Fine-tuning 후 모델을 선택하는 다양한 방법론, 출처: Model Soups 논문</p>
                    </div>
                    <p>
                        <br><span class="highlight" style="color: rgb(0, 3, 206);">위 표에서 가장 첫 번째 방법은 우리가 흔히 사용하는 validation accuracy가 가장 높은 모델 1개를 선택하는 방법입니다.</span>
                        그리고 표의 두 번째 방법론은 \(f(x, \theta)\)로 표현되는 tuning 된 모델들을 voting하는 방식등의 앙상블 방식이며, 이는 여러개의 모델이 필요하다는 단점이 있습니다.
                        마지막으로 나머지 3개의 방법론은 이 논문에서 실험을 수행한 방식들입니다.

                        <br><br><span style="font-size: 20px;"><b>1. Uniform Soup</b></span>
                        <br>이 방법은 아주 간단합니다. 같은 pre-trained 모델에서 fine-tuning된 모델들은 그 구조가 같을 것입니다. 따라서 각 fine-tuning 된 모델의 parameter들을 모두 평균을 내는 방법입니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">하지만 이 방법론은 n개의 모델을 평균을 내다보니까, 오히려 성능 하락을 내는 모델이 많이 있어서 greedy soup의 방법을 제안합니다.</span>

                        <br><br><span style="font-size: 20px;"><b>2. Greedy Soup</b></span>
                        <br>Greedy soup의 방법도 아주 간단합니다. 이 방법은 아래와같이 수행합니다.
                        <ol>
                            <li>Validataion set에 대한 accuracy에 대해 model들을 내림차순으로 정렬.</li>
                            <li>연속된 모델을 하나씩 parameter의 평균을 내면서 성능이 하락하는 모델을 버림.</li>
                        </ol>
                        이 과정에 대한 pseudocode는 아래와 같습니다.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_HfoXH4Q-U5bk-6H2YUvVXIZDsJC5t2U5ykE-obOsdA0wlC0YeipJhndXGKJ1kyJPcoXuXrNbIjOrkQOy8z8xSuNX8hsObNpmXXra8n27uqyM2sHLNHZQ2PR3Ldn8N4O82KtK14-JwiLOcy-tJNQ_qG_MdRWcd1a2JffYl6er5beX4yFH6wmsWxKRL8HES1KbgD9wdFm46eIqWBKRc1vbm4axDMf1WEuSm8aRjnQXJw4Jcodkn6scEdWlJ6iM9ruZbDLyp__Y8uN2aSpRNy5wrqnw3gXqHF19dLWFxk7kNmDv2qH5Pej9o2yFE5mYTijunX0Rw13RNxXBgZqWJ2dGS7cqtlOReg9R1vZO0I1gzP9kh9fKFoZhKUYKO290JXc7K4S6oscG_6W_LEEOGzQlQOqNSxDP6Jbxm78Mo75tAjRlb1mq6EOMeLrxark77NQmDcAsJLkMZRrHea2DXht8cTb2dJ9NGB5IgmYB5D-gABywJrGiZxt087SkpWXHRSj2Sa25IRP0-3cvqmm9bhCFqgO8diHrNHo_bJ6H2phv87R8EYSxtzzqr7zcv5sc7n0-TJUtsq4wwy-u5a8EEdzeNaUv6ndTnWUZ32Il_VXxdxhEpbxngxCGqmiHIYiFbojF8yx066UOp4chS-CteaDukPrIkgF_qQ5ZraLFgh1di3SsEcTGhsLOnk8QF61MPuBLgmE_9XOdHDo7bavpqafubh3KsWWGAhEIxN6BL5SqK0zHGUkKisM7F3c9V5qAEpyWgbVFLTxZEscKk_Cw26QcDvzsOPeD2PBinXeOM5UMeSJfMQ1GzFp34dzZYoFD8fuDYS62HslycByoAySnGRbTkoJa2TAC9I10N7gAdQ0vm8R3bsBB9G0NzmWTsC5Wd5_fGydjvrHmByKNFHMs6iPlTGh7FO1gC5Eh-hRaQdbpbLQnMrBLE036GghoyY4SUi-INqXoApv6kUOY3EcCNyPON1ya8Kx6Cii0mw9OmQRZr63EDzRSlQB7ZAZMzHcX1JgmzyhTHueCgwFVWlXes1by-iHJVW3tTkdFvagVvx1Y1Z0CextRJxgr4WmGMKa0dI2_ThHwcqibwAH04I-pWQzKP6RNOPVj1biVE4W8B78YOCsE6Vl59vOQeu1txgUTocOnpx4MRrW3xl7pas_yrh-G-DmGvRaewhaiIBDSZF8wrSBvF9T0YMyqcPHzyaNT4QLlolgM63YicYMwGLJ1bIPIr86crY3JJJ4JLXNTiwoFiVQL1bkHQUl7lfE6zeKzwS5MriJ5Be9Lcuq5rBajToHm_fuQ9zfqrMaDeTrpPrsmEW5JI4FSMu-Wztx3rV2ETVc_F6_V0ZWaNU7K55HaytsWgqXk49-AtVvvpTCFNPGORtwTVJjitx2CglwgSRDztfrEpDjqws4VpPhOt0G8A_16ytvqFmipptPDX4RweTnO2HJzYWcGltbXMJPQtSxacH3Ikowa0g3yxRD3iVwAIL7IlVgBNU8bg7csu4HQCKnOy1rSFVV037ofAeBYZuo_aGUcfDa24SJubf" style="width: 80%;">
                        <p class="caption">Greedy Soup Pseudocode, 출처: Model Soups 논문</p>
                    </div>
                    
                    <p>

                        <br><br><span style="font-size: 20px;"><b>3. Learned Soup</b></span>
                        <br>Learned soup는 greedy soup에서 순차적인 실행을 제거한 방법론입니다.
                        이 방법은 gradient-based mini-batch를 이용하여 각 모델의 parameter가 merging 될 때 coefficient를 학습을 통해 정하는 방식입니다.
                    </p>
                    <div class="equation">
                        \[ argmin_{\alpha \in \mathbb{R}^k, \beta \in \mathbb{R}} \sum^{n}_{j=1} l \Big(\beta \cdot f(x_j, \sum^k_{i=1} \alpha_i \theta_i), y_j \Big) \]
                    </div>
                    <p>
                        <br><span class="highlight" style="color: rgb(0, 3, 206);">하지만 이 방법론은 n개의 모델을 모두 메모리에 올려야하기 때문에 현재 나오는 거대 모델들에게 적용하기에는 한계가 있어서 저자들은 논문에서 greedy soup를 중점적으로 다룹니다.</span>
                    </p>
                    




                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>Model Soups의 결과</span><br>
                        <span>Results of Model Soups</span>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        이제 실제로 위에서 소개한 merging 기법들을 적용했을 때의 결과를 보여드리겠습니다.

                        <br>아래는 ViT-B/32 모델을 fine-tuning한 결과와 merging의 결과입니다.
                        저자들은 greedy soup을 적용했을 때 72개의 fine-tuned 모델 중 5개가 merging 되었다고 합니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">아래 그림을 봤을 때 x축의 ImageNet 결과와 y축의 ImageNet의 distribution shifted 된 5개의 데이터의 평균 결과가 두루두루 좋은 것이 greedy soup인 것을 볼 수 있습니다.</span>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_GSU8HgvSMZe0DdxKWIltaRtsg1u_tkEo7lv7Kn9PPcgl6HHa399v8fMQNKEqjYCdm1-dncnTAZkregittP8xh3EmcCYAWYYcKsRMRz2I6xqY-wW6nHy1-GzuY90j3f1f6mwBxDiAZy6bphXOj0IawJC1BVS4jZTggunuyGxtDutgISZpxklzCnkZeL7zeQ-JBL7EA9aTUgIpeHMQtsvRZtm2C1o7oAJI7qLsr6iZgQL5uE5pxZclC0DCfz3NaFHyohsB19Kzo3cTsfz8ACObhnAWbkNETuz0arsvArJpsZ6GDNJ9_6If7025dSF8EeS_fJwO10_EK-3ClNCgQmkEA15tYBjI-0lt-XJpRsLDdyFa5FwLbJy_bHex1N7WTraUoMEg_R2qKfsOfrDq4ThNHSLDn1N53hVu_irHCjDFxidD0Vx7-Pa_VPuWbh3tY0GEZ2m8SEasSmP86Jlj8IpORaqHS1vqlUpmZ8sgvilcIjyhAaRqZcoZpiPkUhtloCsyJRaTgLCGK-sTcweF2v4lGKir9FQLJrP_35z95I2jKAul2bj5H_XwOO13GIv291fY84aNwv93s6kbpp_83a3pzHGMPP_mrC2ivYJolMwgu28xxWJQjHdnjtEoep5SQz8c8oOVFaq-qYIltM8B5JFue5CllrjeD6LOXHdI-QlYcsBDb7Y3jpWYhltl_IPgLsrwSe9a_BOchwgk5Q-N46CFr0O6qBb-OLkm5f9Fp_sFCj9VPd63HgUHTSBuKXO8Kw60VeAXnLuU89NXctgwHVTvPyMeOnZMW9tog7PXOpyEEsoreS6XcC4sX2HzqsQNKLtR1eajmiqmJv-XNxgfJUbfxAxbsUAD06FgWq6EFJeNv1nZNXxQwaAbDVpCr6t5nBfTEcytObhI_x_9b0BZRbwIZI-7gkC8nM_QXmHAg4WOIfGNitP9JHtezn5Vs2tpXRWoxfO3tZzPoou7nHfcKbjrULcDIAu5ESpoF0Hrp5tkOsXOjEAxUipaDU5Rb321Q87gICYTq3MUMTd4AaCK3r30sBykx2V1C9igYneXmTMB6pexDN1pYhWjADVd7POqXCHEPX_jBvVQi1wknMyXWQTQEN0zTDcStNw68MAgxpxic3bCn_M4qeNPeteSFEB4B_s2O-fuw9MM7U9nKy9OnPGh1Yfr42wo09QRuWybvRq8PNmllNS35lpZpiCtaU6WIEAy_pKgUBX2uIS7VnvOFAZe1mzRe-go0R3BAGqzV-pxZYaMw_iQzL4eqUJgB9vsGsGRTWmFW6P_m9X-VlB27cGKFxAlDln9j3Bbx2ny6HZwBKXr5Gz8w8IVqI3I-Rdh_qx3gNx2OYmiAOywfJSzCwQLVsoFnqcYEDkDUynyQM3nsHKKA6pf-cQYnaahAFy56YolW6m2jGIvvQQ_0778poLfn1G7y1yNa5THcBp-os7bIUxcIpiM6BZP6pWB8vb_DQd7kVNOL7zyB_iGkyhU3JdIr2NoAYml3rLfev3p_OCwhnnqRl9aEstFUi31ULZUPNjBNjNYuBcQ" style="width: 80%;">
                        <p class="caption">ViT-B/32 merging 결과, 출처: Model Soups 논문</p>
                    </div>
                    <p>
                        <br>아래는 ALIGN 모델을 fine-tuning한 결과와 merging의 결과입니다.
                        저자들은 greedy soup을 적용했을 때 12개의 fine-tuned 모델 중 5개가 merging 되었다고 합니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">아래 그림을 봤을 때 x축의 ImageNet 결과와 y축의 ImageNet의 distribution shifted 된 5개의 데이터의 평균 결과 모두 greedy soup이 높은 것을 볼 수 있습니다.</span>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_EzH7S_AAj_CMdVHPJijOMhcSIVKahyqCA2AKTj-aneszgSMc2TPFKzbfoBtpKnSaGpB8Kgode15SouAuUuzy7L5MGaNwRsL78zozRFAqIEJpicS-pZtrRDoXtVjF6ckqQXIieEf46ctAXn7vHkav8T8A-OQdmu9gWwfoyv8zn30UyD7Z3N3e5xGFL6t866Unl8ogxDR_EkTrGZlxNYpq-u0a-VgqgXx4rE3U29Bh0DQNvMPTm-6MH7Fdl10aYOfEbzu8ngxQheQwY4sap6FqkCe4-BGqfFkGeAWJsdYAdFdVl5XjiLrdi06t_G80IOfS-uGjx0TygxEyT3dK7QNbYA3Vzzi_m6x-yahJYNLoyAkXL27jNroTy25Mj9yxWH4wz-vOUQ52zI-yHgUbJwHZIxQ8idOnUevWU43rA0aysPDNhy0gKyjOXWfeMQIMdcWH6c23R0REgSoGQANSrdvWfRIINgjXBQdC_QMrXCNzJEhKXLg1qUez3ewCDD8fRW3mTCkbd62QVPgMClhSR78ISqAUSaXonypixM2125BaFhCLw-D96dmkPPIu1mw0-ndg3pVvnzBeBBBs3gMMA81SQujAnJIBwc1KwmqO4a_NsYyj_ocwq5Y7MOKyYr9H7bNQhWUnxMO7zk_v6sdwHDJS125u6VNJsimHgv5UYFF8Hu3nta1Ng9GMNk4gnyBnsyTJYEoUJHCp7_bjIcNpJnbfU4JSEG2z4vbB502IZnMPdygpMu-qm7j2BQ-IjPK07dvjZkWCkQ0pI-_QuwcdOv6Q0S3wvDUquq9RaiZ8T3KRh1ovu0drr5xMboGf0Bgy7JM7YWjlEmw0Tw_9hPPWrv2OnlLsiCtYvUAdkfBvxSHFeriTTtkQbGFnwumuT1Nijg73AyrnxTXWw4F9Ix3fAj8vFBZL-qCAjEOXlo5xFBBeMvJXOISMvYtSaxkeA_a6F2v4_Sd7hP0tpnl9TtvPJu0rxU1_yHmSBzVggSYSWzdV0HdveWutJ9NgegO9HQDArs_RVYRxQdHCZoRM5iXlb4-gx9g9wVZIcd-NRCkx87QZ3eLW9Rdknn023ZCS449COf3noJY4BMG5-BMyWalazsze-MUwviCt2nwk_S4hJ0hnijHVNRpEFPslOHElp5pq9xzh87_b3pFIUuiQAcVhXpw9danaW1YolvOud6Xnp_RS1HPwfBpdQ5hgzGnq7QiqsaviGhZt71xgeHtg3eCbdqW5AhHb4JACu1SFAwdpVVuqjaQgOnLnREHbArbJ0Qs-5qIjb1G-4fAkKsv78a0ztKuScL5Ns0yXUly6C8a8J2aS8YqT1k6-Txn8cY8pV8Ee5SqXm1mTTdqGPkoOHx8GaW1DiG8SOrXp3bOovCJot9Bj8FXN-NatL8jNTISRzJTcylyDX5m5fCprvNWWOTJxNgWoEtarvxVf_vx5ZyszYrITdXF9Pfy12dSxOVI7Qjau7DRqylWoYaevuIG383bKjxeqJE7ilz8f2KkKFwSMQYLXcFCC5USnF6DfEYZ6QRhadonl7fV2AHBPcc" style="width: 80%;">
                        <p class="caption">ALIGN merging 결과, 출처: Model Soups 논문</p>
                    </div>
                    <p>
                        <br>아래는 ViT/G-14 모델에 대한 결과이고 greedy soup을 사용했을 때 58개의 모델 중 14개가 merging 되었다고 합니다.
                        실제로 greedy soup 결과가 ImageNet과 distribution shifted ImageNet 데이터에서 가장 좋은 결과를 보여줍니다.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_H1qRQ01ppazoFg8naT4dREfXpsGHCljCayYAMc1wLz7JD7vDQGxDNgwQeFMnUq7njamwakZzL0IYwWYJNFL3IPkLJRkc2rNH_xcqpzIaj3Xyfr4zHc3mByB9CtCbZ_5W6rqJ2PuSer4Sa2QN2eN7pVR8w_7mdUZTyemIxX1ulj9Uab_MGmlDRXeroHHsO_x2LqZ1hqPgO-ZFeHKx3ag4WVvAGJJIEX5xiZ_4b1c1vRhjzlB0_g5LZHoGukx4gqXmXPCY69GfmckAFl8LRhurgfXSA7IM2cI8DCUjEU4tmxTpvqZbg_wHOsfspkbJvLq5gxtULIFk8TkwuakYtNcYE6UGB3rBaAUn2T3yY4_IJBjlCwGVmdZYyXBnDekIu6HW0Ws9PrBMCq0TUeAlac1nfBBmLfvIu8cdAfPEyhqBqPkmoT8IPZU1TgZdFr5ZTjsxJkhkwyarJxFy3Tfk03WXzw5xQ57SnZmZGnkJeiofMQDAYp_E_7xe8vw983MUBtSMKfJXSYpCpR565RdglT0S1esYrMOzrJkjAE0yX1HSaEsGNhkaKbAfwPAZqLxJP7x1_Eo0HMY5fVi9tzM2DlbXkMSQZifSdiqrbBdCZ4Tc7_3pNOWYPInnxZCX1eSmISgmCcecEnsnRfBSSnsdbUIQIZC5KrabMSBtcROfhrglpnmpLumm0R-7eMb4S5BXHBOv5s3CF4Ol2ndEsTVm6a-YAe09B4OkkFLd8-sglsQCqqtvc7IEYjodoqywqBOv3pwr-9LwGNd29wEqG-jJocYokssr19i33evtQEI8t4OrxGL6ihk0qkR_4dqKG191czy1tDnUL9x8n0XEako4ATsjerCGHsdhmaSek1XIfsmlkfQIaZ87xpebW6NyuznX6i7mfrz5zRjIoKBoq5-d2r0DIngBJiwxFTIEfo8yY6uYwuwGYxeZJT113W109PZFq4zafpcogB8gEYgrQsRHBemIeVBCJzt7avxBU8TtVnYmlJfNtJB5hJlbEbvZKIx6kt43MZxiwfeTHT-NHzu1PcGRWo4J2HrzJZlaSAVH0ZnlP3CrSFSkfelHr6FXTWcrrT0W-D1Jkzhom9IA5xNuruoavt_kDK-zktD0IjU4z3XrptnuDuh17T839Drts6U4k07mUjR3x9LrWK3QAcCCgpfJ-iKjokbRde3fYEP1gtCBIlFKm3o7Vgw3D6zA2jHxOkP5_jbhzHXb-Xz4y3USxUELsPuqBuLEJepdOFgR1KE3MMbRgJGLcKqIusVVPCg9BnlBTxbHKXxYuz5bliG-ISnihtWVXcls8rnGoQpeUxy7nkGgVSqGtfq18LB7Qn02CcH2KaeAZxZiVT0ufTs58Ij0C6pBhqeSXnHFPc9aJuWYg-U8AcQdPG5mxeA7652MayYGYdXYSD6kKC0pBKJcY_U6INawQAGxGUN07HDj5AlCEimSInZHmogk1-jWYR1sg3YvXhtOK5mnrZSOxlB8l1zwoOH9QxgTNa6DuZ4p7FaMm9XMmlzB4rvmzYZKqXRoeNxwGvoNy8dg" style="width: 100%;">
                        <p class="caption">ViT/G-14 merging 결과, 출처: Model Soups 논문</p>
                    </div>
                    <p>
                        <br>마지막으로 BERT와 T5의 text classification 결과인데, GLUE benchmark의 4개의 데이터셋을 fine-tuning한 후 greedy soup으로 merging 했을 때 두 모델 모두 기존 fine-tuning 한 모델보다 좋은 결과를 보여줍니다.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_HuQnDJpqTiFoOEXcL_ZrnpJJQSiOHVKHFW08RPdSFbWgl8MAqbc8Uava5KQgWdcyF-9wSFyEFXUT-0grTTFyCzQ4oVSQPK6kOtLvO4IGOu124pIzgebs2fgfa4amI6xcvKqGlHgR8lihnyfdSP1slGtjPMtRRm29aGpAq6Y4JgooS7lnIRGNyRloAoBCr62czBwwYOQpuEAZfu30Ce_z73IbyIqi87remu3vGGFaAR5o6qdhwewqJTcF8MlClUY6NSiWap0jj25tJL2hDHfnrW-N47NFHctoIdhkJZuXPFNEMAfb6oU7e3SXzINrw994Jt_tThrNb7p1T-nFKdvZ3WjNSHVVn48oNCRlOhD1DdOHiQOnJAtFIsLY2SnLPcn3d2eqom_gR3PfZoKjf6dlTq5zJNUIickCwQnhnEGitjzbKxBqU3VZ2Hd5bV-uHCoxR1RQBk-lgQPuhmLHxf9guLTUm9H4e2mwq4kV9r5UdkfhswmtP8UDEi3Wn-ybPPsxexrpuAWKZ9oCSzi-gU-lCF33-kWgBe9RNB_XEb6I3j-1jANhrBe2zQp7CNgJRmYAcQlKoUwlepLvSXPSfqr2B3VNFbPEmguHZCu5dxjKsrb8VHgJxtBGS5Gt0hqMJ3d206q5F67tf0Sye9GibY91d_-kyKD-Rcu6coQwIwrnyMN1wiDmYeNNi7TkN4Z_7Vft1h5_sMqTFPGr8HZUYpW3WMehPVxR_3Hz19aDaDnSEptgkB8yUT4XSL3ygJ8yg9TJNc6GKA_94JMc-yjm-9vDIuc36oYuK9cP_SDDNslHlsWoOkg8kC5F8UPBgxzKlZ5RDv90ucmFpCrV4pHa_Y5-onuNpV9H3aXhpSOgKuAT3shy2AT0Z14tNV3OhesYBlD2aYEwg9QHnfWc1k_cyDushljl_K1tpENalOLpJi5U6dC48wXf1AplG3uFlHiD6Ww1nTE2eKGYmnT4ijl4Tak6-O0g-lA2K-bZOanvvbiwIZbZVtWYnPZxvCWviJxyQXYk_egi1U87OpIgPtOpeTAIpWki6yAWejvXtGjUoMeNlBtNS9KyzI2CWrZIwwbXAlm4DPYSjgihR8lPWCFsId2WE68dgE6_sNYa-wdbC-b3UOidMbP0SADSb7MBcdn4agbvSiWwilsrVrUx5vv29igSRiGENrfOoVfVzRR1b1UpZ_0zFjAqvRyWaxZjtbwqvWa9dOUnDGRASFjEAe2MrAb_qmDxl5R02K0_-EtWAhASOkEnuK5Xcwym_fyqvC7Sma8vsPK3IgpugHcpvNsARwUsyUFMOTpVOCVui-IrPstk4sjhIBvYHFyiBST8vEGAT-JOko5kQMkh0zVhF4FvJIpCUVAANwWY9-q2TZLFgpCz_K7kF291p2JGoUTw4iPx2rYW4dK5YPQVUduUlAcUrAtX9se_vaVckaUl8ZnRGgh7kSWr5JVVkFhKyeyKKrwiqTwdVE5McABA7oP9YfF8cuX_RW34OjZ-dxYF9qm15fxN4suZvhZkzvQjnyYHQeitkmdNzZXWtG2Eyi" style="width: 100%;">
                        <p class="caption">BERT, T5 merging 결과, 출처: Model Soups 논문</p>
                    </div>





                    
                    <p>
                        <br><br><br>이번에는 model merging 기법 중 model soups를 소개했습니다.
                        다음에는 실제로 LLM leader board에서 1등을 차지한 기법 중 하나인 LLM TIES merging 기법에 대해 소개하겠습니다.
                    </p>


                    
                </div> 
                <div class="tag">
                    <b>태그</b>&emsp;#ModelSoups
                </div>
                <div class="pageTurner">
                    <div class="pageTurnerLeft">
                        <span><a style="position: absolute; left: 0;" onclick="alert('Deep Model Fusion 시리즈 첫 게시물 입니다.\n\nThis is the first post of Deep Model Fusion series.');" onmouseover="colorOn(this);" onmouseout="colorOff(this);">&lang; 이전글</a>
                        <br></span>
                    </div>
                    <div class="pageTurnerRight">
                        <span><a style="position: absolute; right: 0;" onclick="pjaxPage('ties1.html');" onmouseover="colorOn(this);" onmouseout="colorOff(this);">다음글 &rang;</a>
                        <br>TIES-merging (TrIm, Elect Sign &amp; Merge)</span>
                    </div>
                </div>
                <span id="readNum"></span>
                <div id="disqus_thread"></div>

                <script>
                    headHighlightColorChanger();
                    (function() { // DON'T EDIT BELOW THIS LINE
                    var d = document, s = d.createElement('script');
                    s.src = 'https://novicetraveler.disqus.com/embed.js';
                    s.setAttribute('data-timestamp', +new Date());
                    (d.head || d.body).appendChild(s);
                    })(); 
                </script>
                <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </article>
        </div>

        <div id="menuRelated">
            <div class="menuButton">
                <img id="menuImg" src="init/index_img/menu_black.png" onclick="openMenu(this);">
            </div>
            <div class="menu">
                <img id="menuExtension" title="메뉴를 확장합니다." src="init/index_img/extension_black.png" onclick="extendMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
            <div class="bigMenu">
                <img id="menuCompression" title="메뉴를 축소합니다." src="init/index_img/compression_black.png" onclick="compressMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
        </div>

        <script>
            detectScroll();
            pushFunc();
            detectSize();
        </script>
    </body>
</html>