<!DOCTYPE html>
<html>
    <head>
        <title>ResNet, LSTM을 이용한 Flickr8k 이미지 캡션 생성</title>
        <meta name="description" content="ResNet과 LSTM을 바탕으로 이미지 캡션을 생성하고, decoding 단어별로 이미지의 어떤 부분에 attention이 이루어졌는지 가시화합니다.">
        <meta charset="utf-8">
        <link rel="stylesheet" href="init/index.css">
        <link rel="stylesheet" href="init/contents.css">
        <link rel="stylesheet" href="init/index_img/icons/css/fontello.css">

        <link rel="preconnect" href="https://fonts.googleapis.com"> 
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> 
        <link href="https://fonts.googleapis.com/css2?family=Dongle:wght@300&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Gowun+Batang&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic&display=swap" rel="stylesheet">

        <link rel="stylesheet"
            href="init/highlight/styles/github-dark.min.css">
        <script src="init/highlight/highlight.min.js"></script>
        <script>hljs.highlightAll();</script>
        <script src="init/highlight/highlights_line.js"></script>
        <script>initNumber(window, document);</script>
        <script>hljs.initLineNumbersOnLoad();</script>

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        <script src="init/index.js"></script>
        <script src="init/jquery.pjax.js"></script>
        
        <meta name="viewport" content="width=device-width, initial-scale=0.8, max-width=1">

        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-219110982-1"></script>
        <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-219110982-1');
        </script>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7745178886614102"
        crossorigin="anonymous"></script>

        <meta property="og:url" content="https://ljm565.github.io/contents/img2txt2.html" />
        <meta property="og:title" content="ResNet, LSTM을 이용한 Flickr8k 이미지 캡션 생성" />
        <meta property="og:type" content="website">
        <meta property="og:description" content="ResNet과 LSTM을 바탕으로 이미지 캡션을 생성하고, decoding 단어별로 이미지의 어떤 부분에 attention이 이루어졌는지 가시화합니다." />
        <meta property="og:image" content="https://lh3.googleusercontent.com/fife/ALs6j_EFKOD_onEkHAAxzjXFIg6f7XDIcW17_a9hWMUL5taWdxEsDzsiCkTVuzKDGrSZS5_F7ue6QYKV6nwlLnuyTA2gyQO1R2TyrY7VDo4NjEcJCnbN-PKlxXfwOFnDSW7CVLhyRX44UsKKtM50P6pHxnsgMluoq8Ex8-QdNithzewHMEAipbuy_imk8DgMQsPOqPQMTj9t5X2_n9HWG9usxptSIe1-MgWnZ7hpZl-bi-oABRizGfMa5ebbo7_qIIbG5tcAjO9Oz2ix4uRTD971wvOvwhzv9JOg952yLzyVgL_B-OWmtX2QgAn5Eqb4k2Jk2vHR464rSglEI5K3F5ldXTe04uvla2YovvLPtHg5VaUD9DCahK1KIfChiVJmxfC6V2UvkMFLD9Vr3uSF_H2lwityE6597o5bLHdJ9x6SSPvZM8dGHNZi1tthjhypr_KKpyMWZPI_fAePUX2cz7yLb1Oa0-23Z-JJPUcQLWc2hGTMu6PTHeVsLntLa4vB9teRYZ5JC9BHHWYawellKUlCs3OauD6ntiWjHZ_NKDMnWTB0TD2Cv4MQEqhmWUD6igafc_2KDQg1ZuhywaRB3ZVT2yE4RgUtWYXYUqOUYVrvNIBZdhtCVV95SaBjaiZBkGRdXkoy5tciR-pcE9tXMXKF3hjUBh-UcktDFgA2BUac1VhiurCN8JkeymDr8LUizMg9X82LIEW9PnJDZX6Kc-gFW9doN2P233ey4w9w7GsP9j1ZgPd2Se_IVtkn9MXXHz8Pq1g_OTU5-DrZLKpvo5jC0hroqi90B36dD_pQapAdhLW2oi1R2cH1nffe56q_NX28atWxzE7x6wESIiC6lwgaX6Ob15TmqKzJkuNMVesWOgHq7f8C6yaqfRj5rzIWuIinTwPKoQ23F2EVqfvpvSXjeZ-uPrYHFJBziANJse2j6n3KPTrWUsxl9IpEC0Vp5TkXKzvLMAh6hQRP0D7CaFZ6bjtFl99B47tsPHiDKFYiBZUVfABEVHO-BppOLnxFG3jgE-n-vph3AggBjMT6u32z82YSFKg18ugCmB8d07RD83-rJFCTVU8JUgaaSXiKpijLbotvkgTnkRLWPpnJpW8fY_SZ3yXZe_TMzeNLoD0f3guJLLEqsgPYCR1e-TTTR00XEsI6A1uRvd5YMGWpMczT9Em02h4jmG8HhxTbIID9Gu4DFi1bJMdKz69uv5Q1ibCfiWy_nWp_oxXf8yUyDVlYOOmohjUN4nsz61FpWK66Z8nJSrKsbO1uh8h8wMU46Vvc_POcAw-kKFozSbUY3JQnsoIKCH5tbHU7oMbLtP1rOZL1ngyghPuBJLDnw-V6t9N5SHlOzwWFjUSpw3tL2CCdn_YTqqmVCoNy2AKVAJyMFzPQFnWSG5Z9q_c1nFM5KnaAtMEahRfiXG6pnfycUR-5ilG7zDybgxDXEGAGIkImttPR6x_vXItKOstoU-D93uwebz-YMT66YBiCag95xnNPMaL_Wc1Sp0OEZo_tGebrlYNhGSS_ADCi2_RIKleBQOAxf4tLMixomWFy" />
    </head>   
    <body>
        <div id="modeButton">
            <button type="button" value="dark" onclick="darkMode(this)" onmouseover="hoveringOn(this)" onmouseout="hoveringOff(this)">
                <div class="modeImg"><img id="modeImg" src="init/index_img/moon_off.png"></div>
                <div id="modeState">다크 모드로 보기</div>
            </button>
        </div>

        <div id="container" onclick="reload();">
            <article>
                <script src="init/highlight/highlight.min.js"></script>
                <script>hljs.highlightAll();</script>
                <script src="init/highlight/highlights_line.js"></script>
                <script>initNumber(window, document);</script>
                <script>hljs.initLineNumbersOnLoad();</script>
                <script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
                <script>
                    initMathJax();
                </script>
                <div id="mainHeadWrapper">
                    <div id="mainHead">
                        <h1 class="contentHead">딥러닝 이야기 / Image Captioning / 2. ResNet, LSTM을 이용한 Flickr8k 이미지 캡션 생성</h1>
                    </div>
                </div>
                
                <div class="title" style="background-image:url(https://lh3.googleusercontent.com/fife/ALs6j_EFKOD_onEkHAAxzjXFIg6f7XDIcW17_a9hWMUL5taWdxEsDzsiCkTVuzKDGrSZS5_F7ue6QYKV6nwlLnuyTA2gyQO1R2TyrY7VDo4NjEcJCnbN-PKlxXfwOFnDSW7CVLhyRX44UsKKtM50P6pHxnsgMluoq8Ex8-QdNithzewHMEAipbuy_imk8DgMQsPOqPQMTj9t5X2_n9HWG9usxptSIe1-MgWnZ7hpZl-bi-oABRizGfMa5ebbo7_qIIbG5tcAjO9Oz2ix4uRTD971wvOvwhzv9JOg952yLzyVgL_B-OWmtX2QgAn5Eqb4k2Jk2vHR464rSglEI5K3F5ldXTe04uvla2YovvLPtHg5VaUD9DCahK1KIfChiVJmxfC6V2UvkMFLD9Vr3uSF_H2lwityE6597o5bLHdJ9x6SSPvZM8dGHNZi1tthjhypr_KKpyMWZPI_fAePUX2cz7yLb1Oa0-23Z-JJPUcQLWc2hGTMu6PTHeVsLntLa4vB9teRYZ5JC9BHHWYawellKUlCs3OauD6ntiWjHZ_NKDMnWTB0TD2Cv4MQEqhmWUD6igafc_2KDQg1ZuhywaRB3ZVT2yE4RgUtWYXYUqOUYVrvNIBZdhtCVV95SaBjaiZBkGRdXkoy5tciR-pcE9tXMXKF3hjUBh-UcktDFgA2BUac1VhiurCN8JkeymDr8LUizMg9X82LIEW9PnJDZX6Kc-gFW9doN2P233ey4w9w7GsP9j1ZgPd2Se_IVtkn9MXXHz8Pq1g_OTU5-DrZLKpvo5jC0hroqi90B36dD_pQapAdhLW2oi1R2cH1nffe56q_NX28atWxzE7x6wESIiC6lwgaX6Ob15TmqKzJkuNMVesWOgHq7f8C6yaqfRj5rzIWuIinTwPKoQ23F2EVqfvpvSXjeZ-uPrYHFJBziANJse2j6n3KPTrWUsxl9IpEC0Vp5TkXKzvLMAh6hQRP0D7CaFZ6bjtFl99B47tsPHiDKFYiBZUVfABEVHO-BppOLnxFG3jgE-n-vph3AggBjMT6u32z82YSFKg18ugCmB8d07RD83-rJFCTVU8JUgaaSXiKpijLbotvkgTnkRLWPpnJpW8fY_SZ3yXZe_TMzeNLoD0f3guJLLEqsgPYCR1e-TTTR00XEsI6A1uRvd5YMGWpMczT9Em02h4jmG8HhxTbIID9Gu4DFi1bJMdKz69uv5Q1ibCfiWy_nWp_oxXf8yUyDVlYOOmohjUN4nsz61FpWK66Z8nJSrKsbO1uh8h8wMU46Vvc_POcAw-kKFozSbUY3JQnsoIKCH5tbHU7oMbLtP1rOZL1ngyghPuBJLDnw-V6t9N5SHlOzwWFjUSpw3tL2CCdn_YTqqmVCoNy2AKVAJyMFzPQFnWSG5Z9q_c1nFM5KnaAtMEahRfiXG6pnfycUR-5ilG7zDybgxDXEGAGIkImttPR6x_vXItKOstoU-D93uwebz-YMT66YBiCag95xnNPMaL_Wc1Sp0OEZo_tGebrlYNhGSS_ADCi2_RIKleBQOAxf4tLMixomWFy);">
                    <div>
                        <span class="mainTitle">ResNet, LSTM을 이용한 Flickr8k 이미지 캡션 생성</span>
                        <br><br>
                        <div style="display: table-cell; margin: 0;">
                            <img src="init/index_img/profile.png" style="width: 30px; cursor: pointer;" onclick="pjaxPage('/');">
                        </div>
                        <span class="subTitle" style="display: table-cell; text-align: left; vertical-align: middle; padding-left: 20px; line-height: 125%;">작성자: 여행 초짜<br>작성일: 2022.09.18</span>
                    </div>
                </div>

                <div id="content">
                    <p>
                        시작하기 앞서 틀린 부분이 있을 수 있으니, 틀린 부분이 있다면 지적해주시면 감사하겠습니다.
                        
                        <br><br>이전글에서는 image captioning 모델 중 Show, Attend and Tell 논문 모델에 대해 살펴보았습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">이번글에서는 ResNet, LSTM을 이용하여 Flickr8k 데이터를 가지고 image captioning 모델을 제작해보겠습니다.
                        본 코드의 구현은 python의 PyTorch를 이용하였습니다. 그리고 모델을 학습하면서 training set과 validation set의 loss의 변화와 더불어, 각종 지표 (BLEU, NIST, top-k accuracy), attention 영역과 캡션 생성 결과도 살펴보겠습니다.</span>

                        <br><br>그리고 Show, Attend and Tell 논문의 설명은 <a onclick="pjaxPage('img2txt1.html');"><span class="highlight" style="color: rgb(0, 3, 206);">이전글</span></a>을 참고하시기 바랍니다.
                        그리고 학습을 위한 코드는 GitHub에 올려놓았으니 아래 링크를 참고하시기 바랍니다(본 글에서는 모델의 구현에 초점을 맞추고 있기 때문에, 데이터 전처리 및 학습을 위한 전체 코드는 아래 GitHub 링크를 참고하시기 바랍니다).

                        <br><br>그리고 텍스트를 토큰화 하기 위해 사용한 토크나이저는 word tokenizer를 구현하여 사용하였습니다.
                        물론 현재는 unknown 토큰 문제를 해결하기 위해 <a onclick="pjaxPage('word2vec1.html');"><span class="highlight" style="color: rgb(0, 3, 206);">Word2Vec 글</span></a>에서 설명한 byte-pair-encoding (BPE) 같이 subword 기반의 토크나이저가 많이 사용되지만, <span class="highlight" style="color: rgb(0, 3, 206);">본 글에서는 attention 모델이 각 단어를 예측할 때 이미지의 어떤 부분에 attention을 했는지 살펴보기 위해서 단어 기반의 토크나이저를 선택하였습니다.</span>
                        
                        <br><br>여담으로 PyTorch의 유명한 image captioning 튜토리얼이 있습니다. 본 코드의 모델 initialization은 튜토리얼을 참고하였습니다.
                        하지만 튜토리얼의 캡션 길이 기준으로 sorting 후 decoding 하는 과정이 비효율적이라 판단하여, 한 번에 max length를 모두 decoding 하는 방법으로 모델을 훈련하였습니다.
                        마지막으로 원래의 논문에서 소개한 Tanh를 이용하는 Bahdanau attention 기반의 soft attention을 구현하였습니다(시간이 된다면 hard attention과 beam search 코드도 추가할 예정입니다). 
                    </p>
                    <div class="link">
                        <a href="https://github.com/ljm565/image-captioning-show-attend-and-tell" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);">"Show, Attend and Tell" Image Captioning 구현 GitHub 코드</a>
                    </div><br>
                    <div class="link">
                        <a href="https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);">PyTorch Image Captioning 튜토리얼</a>
                    </div>
                    
                    <p>
                        <br><br>오늘의 컨텐츠입니다.
                        <ol>
                            <li>Image Captioning 모델</li>
                            <li>Attention 모듈</li>
                            <li>Image Captioning 모델 학습</li>
                            <li>Image Captioning 모델 학습 결과</li>
                        </ol>
                    </p>
                    
                    <p>
                        <br>본 코드에서 구현한 Show, Attend and Tell 논문 링크는 아래에 달아놓겠습니다.
                    </p>
                    <div class="link">
                        <a href="https://arxiv.org/pdf/1502.03044.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);">Show, Attend and Tell 논문</a>
                    </div>



                    <h1 class="subHead">Attention을 이용한 Image Captioning</h1>
                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center;">&ldquo;</span>
                        <span>Image Captioning 모델</span><br>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        여기서는 image captioning을 위한 encoder, decoder 모델에 대해 살펴보겠습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">코드는 PyTorch로 작성 되었으며, source 이미지를 encoder를 통해 represent 한 후, 이를 바탕으로 decoder의 <span class="var">hidden</span> state로 넣어 target caption으로 decoding 합니다.</span>
                    </p>

<pre><code class="python"><span class="reserved">class</span> <span class="clazz">Encoder</span>(<span class="clazz">nn</span>.<span class="clazz">Module</span>):
    <span class="reserved">def</span> <span class="method">__init__</span>(<span class="var">self</span>, <span class="var">config</span>):
        <span class="clazz">super</span>(<span class="clazz">Encoder</span>, <span class="var">self</span>).<span class="method">__init__</span>()
        <span class="var">self</span>.<span class="var">enc_hidden_size</span> = <span class="var">config</span>.enc_hidden_size
        <span class="var">self</span>.<span class="var">dec_hidden_size</span> = <span class="var">config</span>.dec_hidden_size
        <span class="var">self</span>.<span class="var">dec_num_layers</span> = <span class="var">config</span>.dec_num_layers
        <span class="var">self</span>.<span class="var">pixel_size</span> = <span class="var">self</span>.<span class="var">enc_hidden_size</span> * <span class="var">self</span>.<span class="var">enc_hidden_size</span>

        <span class="var">base_model</span> = <span class="method">resnet101</span>(<span class="var">pretrained</span>=<span class="reserved">True</span>, <span class="var">progress</span>=<span class="reserved">False</span>)
        <span class="var">base_model</span> = <span class="clazz">list</span>(<span class="var">base_model</span>.<span class="method">children</span>())[:<span class="num">-2</span>]
        <span class="var">self</span>.<span class="var">resnet</span> = <span class="clazz">nn</span>.<span class="clazz">Sequential</span>(*<span class="var">base_model</span>)  <span class="annot"># output size: B x 2048 x H/32 x W/32</span>
        <span class="var">self</span>.<span class="var">pooling</span> = <span class="clazz">nn</span>.<span class="clazz">AdaptiveAvgPool2d</span>((<span class="var">self</span>.<span class="var">enc_hidden_size</span>, <span class="var">self</span>.<span class="var">enc_hidden_size</span>))

        <span class="var">self</span>.<span class="var">relu</span> = <span class="clazz">nn</span>.<span class="clazz">ReLU</span>()
        <span class="var">self</span>.<span class="var">hidden_dim_changer</span> = <span class="clazz">nn</span>.<span class="clazz">Sequential</span>(
            <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="var">self</span>.<span class="var">pixel_size</span>, <span class="var">self</span>.<span class="var">dec_num_layers</span>),
            <span class="clazz">nn</span>.<span class="clazz">ReLU</span>()
        )
        <span class="var">self</span>.<span class="var">h_mlp</span> = <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="num"><span class="num">2048</span></span>, <span class="var">self</span>.<span class="var">dec_hidden_size</span>)
        <span class="var">self</span>.<span class="var">c_mlp</span> = <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="num"><span class="num">2048</span></span>, <span class="var">self</span>.<span class="var">dec_hidden_size</span>)

        <span class="var">self</span>.<span class="method">fine_tune</span>(<span class="reserved">True</span>)


    <span class="reserved">def</span> <span class="method">fine_tune</span>(<span class="var">self</span>, <span class="var">fine_tune</span>=<span class="reserved">True</span>):
        <span class="return">for</span> <span class="var">p</span> <span class="return">in</span> <span class="var">self</span>.<span class="var">resnet</span>.<span class="method">parameters</span>():
            <span class="var">p</span>.<span class="var">requires_grad</span> = <span class="reserved">False</span>

        <span class="return">for</span> <span class="var">c</span> <span class="return">in</span> <span class="clazz">list</span>(<span class="var">self</span>.<span class="var">resnet</span>.<span class="method">children</span>())[<span class="num">5</span>:]:
            <span class="return">for</span> <span class="var">p</span> <span class="return">in</span> <span class="var">c</span>.<span class="method">parameters</span>():
                <span class="var">p</span>.<span class="var">requires_grad</span> = <span class="var">fine_tune</span>


    <span class="reserved">def</span> <span class="method">forward</span>(<span class="var">self</span>, <span class="var">x</span>):
        <span class="var">batch_size</span> = <span class="var">x</span>.size(<span class="num">0</span>)

        <span class="var">x</span> = <span class="var">self</span>.<span class="var">resnet</span>(<span class="var">x</span>)
        <span class="var">x</span> = <span class="var">self</span>.<span class="var">pooling</span>(<span class="var">x</span>)
        <span class="var">x</span> = <span class="var">x</span>.view(<span class="var">batch_size</span>, <span class="num">2048</span>, <span class="num">-1</span>)

        <span class="return">if</span> <span class="var">self</span>.<span class="var">dec_num_layers</span> != <span class="num">1</span>:
            <span class="var">tmp</span> = <span class="var">self</span>.<span class="var">hidden_dim_changer</span>(<span class="var">self</span>.<span class="var">relu</span>(<span class="var">x</span>))
        <span class="return">else</span>:
            <span class="var">tmp</span> = <span class="clazz">torch</span>.<span class="method">mean</span>(<span class="var">x</span>, <span class="var">dim</span>=<span class="num">2</span>, <span class="var">keepdim</span>=<span class="reserved">True</span>)
        <span class="var">tmp</span> = <span class="clazz">torch</span>.<span class="method">permute</span>(<span class="var">tmp</span>, (<span class="num">2</span>, <span class="num">0</span>, <span class="num">1</span>))
        <span class="var">h0</span> = <span class="var">self</span>.<span class="var">h_mlp</span>(<span class="var">tmp</span>)
        <span class="var">c0</span> = <span class="var">self</span>.<span class="var">c_mlp</span>(<span class="var">tmp</span>)
        <span class="return">return</span> <span class="var">x</span>, (<span class="var">h0</span>, <span class="var">c0</span>)



<span class="reserved">class</span> <span class="clazz">Decoder</span>(<span class="clazz">nn</span>.<span class="clazz">Module</span>):
    <span class="reserved">def</span> <span class="method">__init__</span>(<span class="var">self</span>, <span class="var">config</span>, <span class="var">tokenizer</span>):
        <span class="clazz">super</span>(<span class="clazz">Decoder</span>, <span class="var">self</span>).<span class="method">__init__</span>()
        <span class="var">self</span>.<span class="var">pixel_size</span> = <span class="var">config</span>.enc_hidden_size * <span class="var">config</span>.enc_hidden_size
        <span class="var">self</span>.<span class="var">dec_hidden_size</span> = <span class="var">config</span>.dec_hidden_size
        <span class="var">self</span>.<span class="var">dec_num_layers</span> = <span class="var">config</span>.dec_num_layers
        <span class="var">self</span>.<span class="var">dropout</span> = <span class="var">config</span>.dropout
        <span class="var">self</span>.<span class="var">is_attn</span> = <span class="var">config</span>.is_attn
        <span class="var">self</span>.<span class="var">pad_token_id</span> = <span class="var">tokenizer</span>.pad_token_id
        <span class="var">self</span>.<span class="var">vocab_size</span> = <span class="var">tokenizer</span>.vocab_size
        <span class="return">if</span> <span class="var">self</span>.<span class="var">is_attn</span>:
            <span class="var">self</span>.<span class="var">attention</span> = <span class="clazz">Attention</span>(<span class="var">self</span>.<span class="var">dec_hidden_size</span>)
        <span class="var">self</span>.<span class="var">input_size</span> = <span class="var">self</span>.<span class="var">dec_hidden_size</span> + <span class="num">2048</span> <span class="return">if</span> <span class="var">self</span>.<span class="var">is_attn</span> <span class="return">else</span> <span class="var">self</span>.<span class="var">dec_hidden_size</span>

        <span class="var">self</span>.<span class="var">embedding</span> = <span class="clazz">nn</span>.<span class="clazz">Embedding</span>(<span class="var">self</span>.<span class="var">vocab_size</span>, <span class="var">self</span>.<span class="var">dec_hidden_size</span>, <span class="var">padding_idx</span>=<span class="var">self</span>.<span class="var">pad_token_id</span>)
        <span class="var">self</span>.<span class="var">lstm</span> = <span class="clazz">nn</span>.<span class="clazz">LSTM</span>(<span class="var">input_size</span>=<span class="var">self</span>.<span class="var">input_size</span>,
                            <span class="var">hidden_size</span>=<span class="var">self</span>.<span class="var">dec_hidden_size</span>,
                            <span class="var">num_layers</span>=<span class="var">self</span>.<span class="var">dec_num_layers</span>,
                            <span class="var">batch_first</span>=<span class="reserved">True</span>)
        <span class="var">self</span>.<span class="var">dropout_layer</span> = <span class="clazz">nn</span>.<span class="clazz">Dropout</span>(<span class="var">self</span>.<span class="var">dropout</span>) 
        <span class="var">self</span>.<span class="var">relu</span> = <span class="clazz">nn</span>.<span class="clazz">ReLU</span>()
        <span class="var">self</span>.<span class="var">beta</span> = <span class="clazz">nn</span>.<span class="clazz">Sequential</span>(
            <span class="clazz">nn</span>.<span class="clazz">ReLU</span>(),
            <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="var">self</span>.<span class="var">dec_hidden_size</span>, <span class="num">2048</span>),
            <span class="clazz">nn</span>.<span class="clazz">Sigmoid</span>()
        )     
        <span class="var">self</span>.<span class="var">fc</span> = <span class="clazz">nn</span>.<span class="clazz">Sequential</span>(
            <span class="clazz">nn</span>.<span class="clazz">ReLU</span>(),
            <span class="clazz">nn</span>.<span class="clazz">Dropout</span>(<span class="var">self</span>.<span class="var">dropout</span>),
            <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="var">self</span>.<span class="var">dec_hidden_size</span>, <span class="var">self</span>.<span class="var">vocab_size</span>)
        )

        <span class="var">self</span>.<span class="var">embedding</span>.<span class="method">apply</span>(<span class="var">self</span>.<span class="method">init_weights</span>)
        <span class="var">self</span>.<span class="var">fc</span>.<span class="method">apply</span>(<span class="var">self</span>.<span class="method">init_weights</span>)

    
    <span class="reserved">def</span> <span class="method">init_weights</span>(<span class="var">self</span>, <span class="var">m</span>):
        <span class="return">if</span> <span class="method">isinstance</span>(<span class="var">m</span>, <span class="clazz">nn</span>.<span class="clazz">Linear</span>):
            <span class="var">m</span>.<span class="var">bias</span>.<span class="var">data</span>.<span class="method">fill_</span>(<span class="num">0</span>)
            <span class="var">m</span>.<span class="var">weight</span>.<span class="var">data</span>.<span class="method">uniform_</span>(<span class="num">-0.1</span>, <span class="num">0.1</span>)
        <span class="return">if</span> <span class="method">isinstance</span>(<span class="var">m</span>, <span class="clazz">nn</span>.<span class="clazz">Embedding</span>):
            <span class="var">m</span>.<span class="var">weight</span>.<span class="var">data</span>.<span class="method">uniform_</span>(<span class="num">-0.1</span>, <span class="num">0.1</span>)


    <span class="reserved">def</span> <span class="method">forward</span>(<span class="var">self</span>, <span class="var">x</span>, <span class="var">hidden</span>, <span class="var">enc_output</span>):
        <span class="var">x</span> = <span class="var">self</span>.<span class="var">embedding</span>(<span class="var">x</span>)
        <span class="var">score</span> = <span class="reserved">None</span>

        <span class="var">gate</span> = <span class="var">self</span>.<span class="var">beta</span>(<span class="var">hidden</span>[<span class="num">0</span>][<span class="num">-1</span>])
        <span class="return">if</span> <span class="var">self</span>.<span class="var">is_attn</span>:
            <span class="var">enc_output</span>, <span class="var">score</span> = <span class="var">self</span>.<span class="var">attention</span>(<span class="var">self</span>.<span class="var">relu</span>(<span class="var">enc_output</span>), <span class="var">self</span>.<span class="var">relu</span>(<span class="var">hidden</span>[<span class="num">0</span>][<span class="num">-1</span>]))
            <span class="var">enc_output</span> = <span class="var">gate</span>*<span class="var">enc_output</span>
            <span class="var">x</span> = <span class="clazz">torch</span>.<span class="method">cat</span>((<span class="var">x</span>, <span class="var">enc_output</span>.unsqueeze(<span class="num">1</span>)), <span class="var">dim</span>=<span class="num">-1</span>)
        <span class="var">x</span>, <span class="var">hidden</span> = <span class="var">self</span>.<span class="var">lstm</span>(<span class="var">x</span>, <span class="var">hidden</span>)
        <span class="var">x</span> = <span class="var">self</span>.<span class="var">fc</span>(<span class="var">x</span>)
        <span class="return">return</span> <span class="var">x</span>, <span class="var">hidden</span>, <span class="var">score</span>
</code></pre>
                    <p>
                        위 코드에서 나오는 config 부분은 <a href="https://github.com/ljm565/image-captioning-show-attend-and-tell" target="_blank"><span class="highlight" style="color: rgb(0, 3, 206);">GitHub 코드</span></a>에 보면 <span class="var">config</span>.json이라는 파일에 존재하는 변수 값들을 모델에 적용하여 초기화 하는 것입니다.<br><br>
                        <span style="font-size: 20px;"><b>Encoder</b></span>
                        <ul>
                            <li>4번째 줄: Encoding 된 이미지 feature의 width, height 값 설정.</li>
                            <li>5번째 줄: LSTM decoder 모델의 hidden dimension.</li>
                            <li>6번째 줄: LSTM decoder 모델의 레이어 수.</li>
                            <li>7번째 줄: Encoding 된 이미지 feature의 전체 픽셀 수(가로x세로).</li>
                            <li>9 ~ 11번째 줄: <span class="highlight" style="color: rgb(0, 3, 206);">Encoder backbone model, pretrained 된 모델의 마지막 2개의 pooling, fully-connected 레이어는 제외.</span></li>
                            <li>12번째 줄: 위에서 설정한 encoding feature 가로, 세로 크기를 맞춰주기 위한 pooling layer.</li>
                            <li>19 ~ 20번째 줄: Encoding된 이미지의 feature를 LSTM decoder의 hidden, cell state로 만들어주기 위한 레이어.</li>
                            <li>22번째 줄: Pre-trained 된 모델의 첫 5개 레이어를 제외한 레이어만 학습(high level feature 레이어만 학습).</li>
                            <li>34 ~ 48번째 줄: 이미지가 학습 시 거치는 부분</li>
                            <li>41 ~ 42번째 줄: Decoder layer 수가 1이 아닐 때, hidden, cell state 차원을 맞춰주기 위함.</li>
                        </ul>

                        <br><span style="font-size: 20px;"><b>Decoder</b></span>
                        <ul>
                            <li>55번째 줄: 7번째 줄과 동일한 값.</li>
                            <li>56번째 줄: 5번째 줄과 동일한 값.</li>
                            <li>57번째 줄: 6번째 줄과 동일한 값.</li>
                            <li>59번째 줄: 모델의 attention 여부.</li>
                            <li>60번째 줄: 토크나이저의 pad token id.</li>
                            <li>61번째 줄: 토크나이저의 vocab size.</li>
                            <li>62 ~ 63번째 줄: Attention 사용하는 경우 Attention 모듈 정의.</li>
                            <li>64번째 줄: Attention을 사용할 경우 decoder input 차원은 사용안할 때 비해 2048이 커짐(Attention 결과를 다음 decoder input에 대해 concatenate하여 들어가기 때문).</li>
                            <li>66 ~ 71번째 줄: Embedding 레이어, LSTM 모델, dropout layer 선언.</li>
                            <li>73 ~ 77번째 줄: 논문에서 언급한 beta 레이어.</li>
                            <li>78 ~ 82번째 줄: 다음 단어를 예측해야하므로 vocab size의 크기만큼 내어주는 fully-connected layer 선언.</li>
                            <li>84 ~ 93번째 줄: Decoder weight 초기화.</li>
                            <li>96 ~ 107번째 줄: Target 캡션이 학습 시 거치는 부분.</li>
                            <li>107번째 줄: Attention score도 결과와 같이 반환.</li>
                        </ul>
                    </p>




                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>Attention 모듈</span><br>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        위의 image captioning 모델에서 attention을 사용할건지 여부를 선택할 수 있었습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">만약 attention을 선택하게 된다면 아래의 attention 모듈에 ResNet encoder의 output과 deccoder의 이전 output의 결과가 들어가게 됩니다.</span>
                    </p>

<pre><code class="python"><span class="reserved">class</span> <span class="clazz">Attention</span>(<span class="clazz">nn</span>.<span class="clazz">Module</span>):
    <span class="reserved">def</span> <span class="method">__init__</span>(<span class="var">self</span>, <span class="var">hidden_size</span>):
        <span class="clazz">super</span>(<span class="clazz">Attention</span>, <span class="var">self</span>).<span class="method">__init__</span>()
        <span class="var">self</span>.<span class="var">hidden_size</span> = <span class="var">hidden_size</span>
        <span class="var">self</span>.<span class="var">enc_wts</span> = <span class="clazz">nn</span>.<span class="clazz">Sequential</span>(
            <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="num">2048</span>, <span class="var">self</span>.<span class="var">hidden_size</span>),
            <span class="clazz">nn</span>.<span class="clazz">ReLU</span>(),
            <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="var">self</span>.<span class="var">hidden_size</span>, <span class="var">self</span>.<span class="var">hidden_size</span>)
        )
        <span class="var">self</span>.<span class="var">dec_wts</span> = <span class="clazz">nn</span>.<span class="clazz">Sequential</span>(
            <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="var">self</span>.<span class="var">hidden_size</span>, <span class="var">self</span>.<span class="var">hidden_size</span>),
            <span class="clazz">nn</span>.<span class="clazz">ReLU</span>(),
            <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="var">self</span>.<span class="var">hidden_size</span>, <span class="var">self</span>.<span class="var">hidden_size</span>)
        )
        <span class="var">self</span>.<span class="clazz">score_wts</span> = <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="var">self</span>.<span class="var">hidden_size</span>, <span class="num">1</span>)
        <span class="var">self</span>.<span class="var">tanh</span> = <span class="clazz">nn</span>.<span class="clazz">Tanh</span>()
        <span class="var">self</span>.<span class="var">relu</span> = <span class="clazz">nn</span>.<span class="clazz">ReLU</span>()


    <span class="reserved">def</span> <span class="method">forward</span>(<span class="var">self</span>, <span class="var">enc_output</span>, <span class="var">dec_hidden</span>):
        <span class="var">enc_output</span> = <span class="clazz">torch</span>.<span class="method">permute</span>(<span class="var">enc_output</span>, (<span class="num">0</span>, <span class="num">2</span>, <span class="num">1</span>))
        
        <span class="var">score</span> = <span class="var">self</span>.<span class="var">tanh</span>(<span class="var">self</span>.<span class="var">enc_wts</span>(<span class="var">enc_output</span>) + <span class="var">self</span>.<span class="var">dec_wts</span>(<span class="var">dec_hidden</span>).unsqueeze(<span class="num">1</span>))
        <span class="var">score</span> = <span class="var">self</span>.<span class="clazz">score_wts</span>(<span class="var">score</span>)
        <span class="var">score</span> = <span class="clazz">F</span>.<span class="method">softmax</span>(<span class="var">score</span>, <span class="var">dim</span>=<span class="num">1</span>)

        <span class="var">enc_output</span> = <span class="clazz">torch</span>.<span class="method">permute</span>(<span class="var">enc_output</span>, (<span class="num">0</span>, <span class="num">2</span>, <span class="num">1</span>))
        <span class="var">enc_output</span> = <span class="clazz">torch</span>.<span class="method">bmm</span>(<span class="var">enc_output</span>, <span class="var">score</span>).<span class="method">squeeze</span>(<span class="num">-1</span>)
        <span class="return">return</span> <span class="var">enc_output</span>, <span class="var">score</span>
</code></pre>
                    <p>
                        <span style="font-size: 20px;"><b>Attention</b></span>
                        <br>위 코드에서 나오는 config 부분은 <a href="https://github.com/ljm565/image-captioning-show-attend-and-tell" target="_blank"><span class="highlight" style="color: rgb(0, 3, 206);">GitHub 코드</span></a>에 보면 <span class="var">config</span>.json이라는 파일에 존재하는 변수 값들을 모델에 적용하여 초기화 하는 것입니다.
                        <ul>
                            <li>4 ~ 14번째 줄: Encoder의 output과 decoder의 output이 거치게 되는 linear layer 선언.</li>
                            <li>15번째 줄: Encoder의 각 sequence 별 attention score를 내어줘야 하므로 차원을 hidden dim &rarr; 1로 바꿔주는 layer 선언.</li>
                            <li>20 ~ 29번째 줄: Attention 모듈 학습 시 거치는 부분.</li>
                            <li>28번째 줄: Attention score를 encoder output에 곱해주어 weighted sum 하는 부분.</li>
                        </ul>
                    </p>
                



                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>Image Captioning 모델 학습</span><br>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                       이제 기계 번역 모델 학습 코드를 통해 어떻게 학습이 이루어지는지 살펴보겠습니다.
                       아래 코드에 <span style="color:rgb(86, 155, 214);">self</span>. 이라고 나와있는 부분은 GitHub 코드에 보면 알겠지만 학습하는 코드가 class 내부의 변수이기 때문에 있는 것입니다.
                       여기서는 무시해도 좋습니다.
                    </p>
<pre><code class="python"><span class="var">self</span>.<span class="var">encoder</span> = <span class="clazz">Encoder</span>(<span class="var">self</span>.<span class="var">config</span>).<span class="method">to</span>(<span class="var">self</span>.<span class="var">device</span>)
<span class="var">self</span>.<span class="var">decoder</span> = <span class="clazz">Decoder</span>(<span class="var">self</span>.<span class="var">config</span>, <span class="var">self</span>.<span class="var">tokenizer</span>).<span class="method">to</span>(<span class="var">self</span>.<span class="var">device</span>)
<span class="var">self</span>.<span class="var">criterion</span> = <span class="clazz">nn</span>.<span class="clazz">CrossEntropyLoss</span>(<span class="var">ignore_index</span>=<span class="var">self</span>.<span class="var">tokenizer</span>.pad_token_id)
<span class="var">self</span>.<span class="var">enc_optimizer</span> = <span class="clazz">optim</span>.<span class="clazz">Adam</span>(<span class="var">self</span>.<span class="var">encoder</span>.<span class="method">parameters</span>(), <span class="var">lr</span>=<span class="var">self</span>.<span class="var">enc_lr</span>)
<span class="var">self</span>.<span class="var">dec_optimizer</span> = <span class="clazz">optim</span>.<span class="clazz">Adam</span>(<span class="var">self</span>.<span class="var">decoder</span>.<span class="method">parameters</span>(), <span class="var">lr</span>=<span class="var">self</span>.<span class="var">dec_lr</span>)

<span class="return">for</span> <span class="var">epoch</span> <span class="return">in</span> <span class="clazz">range</span>(<span class="var">self</span>.<span class="var">epochs</span>):
    <span class="return">for</span> <span class="var">phase</span> <span class="return">in</span> [<span class="str">'train'</span>, <span class="str">'test'</span>]:
        <span class="return">if</span> <span class="var">phase</span> == <span class="str">'train'</span>:
            <span class="var">self</span>.<span class="var">encoder</span>.<span class="method">train</span>()
            <span class="var">self</span>.<span class="var">decoder</span>.<span class="method">train</span>()
        <span class="return">else</span>:
            <span class="var">self</span>.<span class="var">encoder</span>.<span class="method">eval</span>()
            <span class="var">self</span>.<span class="var">decoder</span>.<span class="method">eval</span>()

        <span class="return">for</span> <span class="var">i</span>, (<span class="var">img</span>, <span class="var">cap</span>, _) <span class="return">in</span> <span class="clazz">enumerate</span>(<span class="var">self</span>.<span class="var">dataloaders</span>[<span class="var">phase</span>]):
            <span class="var">batch_size</span> = <span class="var">img</span>.size(<span class="num">0</span>)
            <span class="var">img</span>, <span class="var">cap</span> = <span class="var">img</span>.<span class="method">to</span>(<span class="var">self</span>.<span class="var">device</span>), <span class="var">cap</span>.<span class="method">to</span>(<span class="var">self</span>.<span class="var">device</span>)
            <span class="var">self</span>.<span class="var">enc_optimizer</span>.<span class="method">zero_grad</span>()
            <span class="var">self</span>.<span class="var">dec_optimizer</span>.<span class="method">zero_grad</span>()

            <span class="return">with</span> <span class="clazz">torch</span>.<span class="clazz">set_grad_enabled</span>(<span class="var">phase</span>==<span class="str">'train'</span>):
                <span class="var">enc_output</span>, <span class="var">hidden</span> = <span class="var">self</span>.<span class="var">encoder</span>(<span class="var">img</span>)
                
                <span class="var">decoder_all_output</span>, <span class="var">decoder_all_score</span> = [], []
                <span class="return">for</span> <span class="var">j</span> <span class="return">in</span> <span class="clazz">range</span>(<span class="var">self</span>.<span class="var">max_len</span>):
                    <span class="var">trg_word</span> = <span class="var">cap</span>[:, <span class="var">j</span>].unsqueeze(<span class="num">1</span>)
                    <span class="var">dec_output</span>, <span class="var">hidden</span>, <span class="var">score</span> = <span class="var">self</span>.<span class="var">decoder</span>(<span class="var">trg_word</span>, <span class="var">hidden</span>, <span class="var">enc_output</span>)
                    <span class="var">decoder_all_output</span>.<span class="method">append</span>(<span class="var">dec_output</span>)
                    <span class="return">if</span> <span class="var">self</span>.<span class="var">config</span>.is_attn:
                        <span class="var">decoder_all_score</span>.<span class="method">append</span>(<span class="var">score</span>)

                <span class="var">decoder_all_output</span> = <span class="clazz">torch</span>.<span class="method">cat</span>(<span class="var">decoder_all_output</span>, <span class="var">dim</span>=<span class="num">1</span>)

                <span class="var">loss</span> = <span class="var">self</span>.<span class="var">criterion</span>(<span class="var">decoder_all_output</span>[:, :<span class="num">-1</span>, :].<span class="method">reshape</span>(<span class="num">-1</span>, <span class="var">decoder_all_output</span>.size(<span class="num">-1</span>)), <span class="var">cap</span>[:, <span class="num">1</span>:].<span class="method">reshape</span>(<span class="num">-1</span>))
                <span class="return">if</span> <span class="var">self</span>.<span class="var">config</span>.is_attn:
                    <span class="var">decoder_all_score</span> = <span class="clazz">torch</span>.<span class="method">cat</span>(<span class="var">decoder_all_score</span>, <span class="var">dim</span>=<span class="num">2</span>)
                    <span class="var">loss</span> += <span class="var">self</span>.<span class="var">config</span>.regularization_lambda * ((<span class="num">1</span>. - <span class="clazz">torch</span>.<span class="method">sum</span>(<span class="var">decoder_all_score</span>, <span class="var">dim</span>=<span class="num">2</span>)) ** <span class="num">2</span>).<span class="method">mean</span>()

                <span class="return">if</span> <span class="var">phase</span> == <span class="str">'train'</span>:
                    <span class="var">loss</span>.backward()
                    <span class="var">self</span>.<span class="var">enc_optimizer</span>.<span class="method">step</span>()
                    <span class="var">self</span>.<span class="var">dec_optimizer</span>.<span class="method">step</span>()
</code></pre>

                    <p>
                        <span style="font-size: 20px;"><b>학습에 필요한 것들 선언</b></span>
                        <br>먼저 위에 코드에서 정의한 모델을 불러오고 학습에 필요한 loss function, optimizer 등을 선언하는 부분입니다.
                        <ul>
                            <li>1 ~ 5번째 줄: Loss function, encoder, decoder 모델 선언 및 각각의 optimizer 선언.</li>
                        </ul>

                        <br><span style="font-size: 20px;"><b>Image Captioning 모델 학습</b></span>
                        <br>다음은 기계 번역 모델 학습 부분입니다.
                        코드상에서는 7 ~ 43번째 줄에 해당하는 부분입니다.
                        <ul>
                            <li>26 ~ 31번째 줄: Decoding step별(토큰별)로 attention을 하기 위해서 for문으로 반복하여 돌림.</li>
                            <li>36 ~ 38번째 줄: 논문에서 언급한 regularization loss term.</li>
                            <li>35 ~ 43번째 줄: Loss를 계산하고 모델을 업데이트 하는 부분.</li>
                        </ul>
                    </p>




                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>Image Captioning 모델 학습 결과</span><br>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        <span style="font-size: 20px;"><b>Loss History</b></span>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_FEIKldchCHeCwTHgeUBhRBligLVc2mNXZHCF7igNxFojSoAisUzZ5XTNU3n-ea4qah4dKUL8QOlWHlKR4Euz-ngylYOVD0yBsBrE7gyHmCRPybSfnM-JeyY41X0a9PC61jinkmE-g6XhJAB0bH2O9LvNvOLny05h691mfd3nh5kT513T28GNRiekKUugOK0-0YC8mAUZ2PMg0OcMIprCzYHnZU_CAb_xUROwQl5oL7Nf-L8Ux4t0QySnQYC9v56fOCrUmzqDgXKHGYa1S7iw5Zpe-ARnE4bCc8WMFOaFcZW5gR1KAXIZhWrzsHAXtnQND61Y8Fbs-CdC9hi_iTWPByHw9d27fTvx2i0O5AoC3RPSYqc-MUaT7VO4fmseMnn6c2hAEjtjbrhfrG-zz_uvJeRnQAuHPlh1zFSndgkmi1FrDo8p7uldr_VAT3Us_lhUyVrQ85f8onbfZPzH3QyCyEoxc3lK8GrBzNxLWqOZvJqXThGBbMx9XdNwsEAPA1pJ3s4xRulNfF70EqMUEAm8jTeN596bgVIRCUZ86ZKzy2hszTGvQzEU7mYtj1zolF82sAS_yi1VRzG0fV5tnceuCkevgxw_J2cugz6sd2oleo1wyhF00DhZ3ebktIguRvavQ5d4i04Klnyfeyv8jLbvHgKsGGeZYoq0JYhkCpuT5ewissuTcGDsLrgNMqvtdOE5ibgmbcty2-qtqdzca5GvCCneBVXwC8ozkQ8zqi9-2CMhbrfVWxoW7hE8-OHAG6cNxdVkD_VYhY_dqN41qYMjAKGxHZRKy-cnDXpk60CXWVkTHAvS1qj-P4Fbg2Ie_bxbNCs9-2BJhsUjCdlAV17VD3q-L7w86X-gTVNYGwxK9OShFoIqK-c_clTYq0t3OvYAS-EVN3KI3HZJJK0qF__z5YIwuzhti3kZiYp8BWVRTT7n_KlYhb9LcSapvRYxldmou_6LTN7EyUP5nUH3RDIFxDNchYjHemWB8NSMQTDKbPtFjVPeVH9564ArXdOqmkKcIjdxtUggN75dm3CkSVzD6VJddPKX9aau6mDLLDX0OwEupWv3-2LSrYnJJMvNE1GrueuHHoQlu_81f5g13Cv06UGx5-t6CUiUKZkfTjWDIHT5X4tTFOEkZXHs_TxvExe9rfkXfy4b57WgghUrJca8PNPNkOmYke6mhlTOia0_PrqLVw-mv2ltymfyxjuby5oNbKVHo9KXJbqvfIKk0KCPzB1l-T5wWSPUwd_8tvaXCTAlS5XbXyaRAe1b9cTzMkFBXsiufwGRVkJINYSkY_8BaXFRCUQzXAfZbMq8xz-C4mFQsxYBbSvnH1jeNXsiub9XI21H_4v97UE7xKtOL-FWwJTYvpoMNjh5n6QLvOUT1fqMCJ6ljJDmES00wJnHkEeiTbXc7W7MkjIH5kjcXgcHlNcNnKFNKOgwlZHvERye1i6_6lPjxtfiiBmMj86mzFeEkxy-s4mFSCXJefD-exg2cON73YPuSM0K405NruqEVVPWYaYbdovvDEqTMxO20ScYh5wXby2D5S" style="width: 100%;">
                        <p class="caption">Loss History</p>
                    </div>
                    <p>
                        <br><span style="font-size: 20px;"><b>Validation Set BLEU Score History</b></span>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_GSy3R3H9WJkHOQQt0qfkuUWXwPEiGHy8uylnhLS-icR2QdJRGuvMj3wzr8GV1TIHlpx_kZe0BgipaL-7N-Qtqjbk11Qzv5BT2IHVMRz7Wb9NL1s-LIpX2RSCifTU5mDvmxg2evtW4HluCfq5PGD_CMYKCWIGQZ7r-UADTtEsMUKBX4oGSHJWBcBeh-SLBB0EtrDKoRiVF_crBRtoU7P7XCo1jpDciJ9JnJCblIE5HpVTOb0gQ1kfO67ynjns8FjH0bzpY0_o3-kpUZTPzwrTMBCYehlIQVZlSDknmXuI7NAKmWLjNCeozXNQN2Zd4QtIeCy0qgO5WmpLdpq2B-386r3gDxtxm1F7nVO3x61XUGIdtGoLEHIQVBe25Vrs-EbIvtCstT8P9tYb-zXDr9SlTFtOfVZaKTZ5JQ1KSqC09qAG11CfBcwQU68WCK8Xpt2Gb4x79rDa0am6QL7GHqM2aMeHzbcd0KEaP1MF4eKsCmwypxQ1Tw6vx6zlkOq5JNZFc8NYZ8i1KS21DCWxuDBANg7hueLBy_j0cDi0pd3zZWaiuhAGTcIWNH28Oxn_pXaBpOP7pnhXMG-eV67fZ3dL6ft8kpIcOhMwAMgPSLGpOz2bKsBwWPFpfhCg69FTcWC41z9UkaRM4NPjxzpAUwg1UsiwRm1vky3i-qtf2A7AtlZbqO-s-LQXyFz-4OK8-iiRPQP5U2xdXK-qz0MG1MPF5GVeF9b1oCvmQK-UgX_iMI_IBCNM0NIooPoIG1n_C708jwtyKI215IXCyx3M1N7Lwb7e6jIIFL-2Nz2s13W0vQYs_14FTE_V5fA8cEjWvINtGNOwkzDz6xLGq-M2e7f-qKdusVKa4c6NeKiQdpnkez2XIZnp7FiVgtxXolNPFnSUxpmzrQO6LmRd3F3j3jMDEGeqVOTBIkrEEJLbHN-yH_9Zo58850_MpGTcARQrCJC1XtHLVlEmcmy8K-eJCh8wopNgGeNKu9QYWwdKMD207D9Rpg2S6u7PXqgUyIn1LF35Yqs11zv8PQ6tPjBsIgaXKQ83DAYmXIsPkc1EA6HRkyqpAwPsx8sxkFm_EQblrvvvK1LlQ9AIY038g1RkJ8XZ8Sy4yjO-OZePN0sb1aItO6x-U5jAzrqb0PCUNrl9ENj1d7vGJbLWlGS0x3XceUc2nA7RtLbsmPZcuMrTZdnX2cXIXTwoZvRh4vjhY_FH1fbaS9cw5HPCC4cVty7giqMKS6htb0Wn0GFpIEH3pZ2UeprOPSC73HWDROBctb3sDKmwD6OPqu8m-pHphcGAlgGsNK8D-c8O6iHj9fRQlnNRUCIDJ3zJ4kU7e_jTJDH02iGlExwpKe-rp6bxEm7ssxiMjfSMge-s3p1V2SfuAjrouY9vodo0hPe73aEbkPO-oxmGoPy_5qw830XXVsRu6Wb96YnjA7nd0DPgkAru3zjJHUrvq85e0mWfkpYjrGGYK7DsiEJb7uDFzX5KAVg-SslaLFvohw10XNMZSry2tOTD6Ys8WNaYOxTzTxncZwOp1uPwxoBe45wXwh" style="width: 100%;">
                        <p class="caption">Validation Set BLEU Score</p>
                    </div>
                    <p>
                        <br>
                        <ul>
                            <li>Best BLEU-2: 0.3053 (22 epoch)</li>
                            <li>Best BLEU-4: 0.1402 (23 epoch), BLEU-4 기준으로 best model 저장.</li>
                        </ul>

                        <br><br><span style="font-size: 20px;"><b>Validation Set NIST Score History</b></span>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_FyMiV0Vj--pxJIU8PQ33998c6F3jy64ZlZDeQHGKFa6haZYd8oH6lyxETN50zr8VQcy9ODt_QEtdzqfkH32MIEq1KKOlKpCedjh5RJYg8WiirFct49PXi6qrhSEfs1kp0BYjPOKa8rWLWrTX3JEDvp3W7vz3m0MMdpI6enXb7MQtNevsdRyaJbTkF7UMDaf4U_QNCE7njmlwhYVJeeWN0dHCpEMw3WQlB4lsJN58rZ04SKnjqmnMi4kfM1WmuRzZKOVe5cikw17ofU8EbWsjuPXfVhqVLjefat_14AgF0wSSF93hx6hetEoZEWO4mGjIoReKlUOAi1ywqoOBe_Gq-JshlXab0105yXjJVOIYFj3Uuw6t4ztqQ1wbWEawGg1i-4giiOyfvferD0sx0_hnbhOdYj12YTpeaeZERlkN02gGoZTmgsSQJOAtPnucm2vHRmOdXXCCGDvzdyHO0WPCMlObJ72oMMkaWoESxBhHsrQY4nIzIS9mA7ofhJFmfQPh0ePBd2prCSyAEkcS8jDKfTGmjz_YqKOySdjw9-N2OEw4ac4ABcqUsOZRg4gwWA_a1Wi8yi8yt46Y5y_ebrIK995taGRI5tIVu3zXMxFV8XYq8LYltJMkk34JnJkkdbutj4pp9DuK0sUyJSF1lnRHhY4xicINm_l42g6Ig9oDui4L33kpD6rw6eriMkBonNKovWb7xq1fRQESN8-89A1zIhmIIcwcldUSfM_veJARHqjVQnDjZkkuWF6Yerwev4fzl5RkSbW_MfuV4WEdfNezytoKmWI-AD3zmMe4_xKH0vl-RctwJq1xrx3p1wBc-BuqMZmOLxivAhCYgoTGTJ1AWYkIexJ9Uob515Ty5FGv-tvZPCAQd4wo6XhLaDLhQIHDml43PpKRw3c_OKnmLjM6MuNiVYfIaE0k25mB6-m3KjtZa6lamPfTe_gaR-2G-v-2jbA65HP4cIrjF3S0CcvRD-mbE7wiKhZstFakpGgcNDbeTqtrzMp9Lpm64sH5NLPHL2VvkDKZTS0o3QHLCJ21KKNtmzfiyldWtUms2AsVFZdCJwn-zyZnOqIAXD5v_f9F7XbHbbXRExHfp1SWkP_DFpvFT9CXyVv2NKj4mbYnVn9APQwvttaxxP36NXbt28RXA1J_UNNwOLhA9WDFr7UJo8_h8a1bgsSzbEoimYqbUjlCth-ptCheFbAbLUUA0DKOWGso4q9cgpawBlHYZOkOU4JZ-1Fdh1qQQYn58Vdndb303PIqOYQCHaRpSVZSUyo8qRgaVQR3RpB46uQizZg38pBHy0cscUwuYgqHtWXJaTPLlUBYPQRaIZy9aGe-emEmG-MitmoDcjWeBAVy-RnmOUEhvrs29jSAzppJQFdndrgrj5_66KF1mbmVTBYBB80JJH90elgE8gDIHby7qt4Zyewsd4OV9h28p4Lg707RW3cIt_UkxctMeiwt08-j0K4UtSewoMTJYPG7ESADvccwhnuSuoXbIemFOkaXjq5kJKmWXPsnvtsbxQLB7LIa9hacabRl5l" style="width: 100%;">
                        <p class="caption">Validation Set NIST Score</p>
                    </div>
                    <p>
                        <br>
                        <ul>
                            <li>Best NIST-2: 3.9032 (22 epoch)</li>
                            <li>Best NIST-4: 4.1633 (22 epoch)</li>
                        </ul>

                        <br><br><span style="font-size: 20px;"><b>Validation Set Top-5 Accuracy History</b></span>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_HHl8mq_VtZkPDixWkSETa6cNaUoOPsfRLvj0hU9XOTDKwAdOkqgbXSBcwzjd1d58-FRzyKje3mPUuBeNI1DP0-ZZ72EPv1r7QkZymvVI7FJaEadq3PqquzyBU0CsXHbBwY8F-HQvd2oZborGJGXoXci5D-_N11K4Y7d7lHo-xuDRrXCHAwH4UHIF41RasW_hQFMD7r3RHuQhEx_Fij3JO3rlAyhBtAcRnR4Jzkqxc3JDELnkpPQfqlkcxPK9gjRNEgNVUchUWC8x3SHFPADjbkZnyIH9lo_46kl8OgkSJGcARtG_uXKry_Z8uBWVyRk-BmLPVgU1W03ZvaGg1RTgO1lCYeQyhYzUZpU8SksFLPYudVnewvcH-JdnA10BS4VjJiTij9GIZctGjCbSN1YXxk1YzCHyASrKm9_l0PdqN7ScfDMt2wlYJSG-W4fMfwoER1b7-J8Qx-UV11IlYpYSwc3bxI9bBSf-StDJ3Nbz6LY9EG3D45G4A1gh3lMWnW-oX9sfJBIje6KPVNvWYpKnpyjfl7ryVRDKNby_eL1nSvC4cNfqvDd3RX9dAVY-ARUfjF_xlLgaA3gxuZSJYsK8maLmAILY5feIKKIwJVVuXlJDOMtJEbcstK9QvoItZLOvvfgv98SOuC9f1ubLfiFDl-1itFaIffKHahxOv8z3IAfl8xRk7Qty5zJ7reaZm-mwWwua41hNKmEjQsj8Kk6Ot980h4MqpPfUciMQ7aQbHzTZusNYS3PqV_YVlmwbs0ONPy8mRjMchGUP4uRaaNnGY-lb9AeBsIK1P_dSWOq3y850q1wighLmb8st2RA0etsYPH7Yrjtlp3gygR-_zs9CqL2m-pHRVlG3GCJSwOLND2M5Xps0A4EBiB9leI7lbO_tGJLJIyn-sXxY6xL0ld4LI1GOjgztwrumfwRTwxTMIb6lmlh3Q8KdN8x85u_9A3kxnQX6uRgVrt3NlXkauQFJWMvnDmcqkIbD5Uvm3BK5RY1UAvd-6Gl89jVK7CajYcwWgGqi1K4-sUhyzOvL6gRXmrmBB35824ewlXlNAcc1RmZvq5a-TdIpvOuR7_5VgDAergfkjl3hcjSAxpC1sn-hIkCmXRQ1OH9xrOjdcgM76UhLnUf0ZCiQhCdN7fnghpZZ006YC0eFL9zGga6t-5Iksrsf2oQNii8LU060Y2krATB1AydqaFFc6ak-PA2OJNDemz-6ehtR4ioihbSuay0XT-KU7vWhZ8LSiCBJkxNtub5xvUGfUtvuGwSebsbJnrmXy4z1VyI9b6k1f38APvMaWYS1ah14oll8WaeXWdKSSrIKO_sYjEV5F-U90e4uytkXrv8ZcwjtFGtaJIRhMFkHVWBGEEB5Wma48tVk81-_uwYA2PkRXfFUFk9lGjgzIuRlqAv8cHMKkAigKiAeYhVuuMqfLs2y_O2lNjHgnY0BB0nANAisBESnlg3d1XegczFBt2mC9TovbBn1vz5_xi03IngTYiN8Tt_pmL9gREpW0JtbFOlnVywM8ovTQ-ZYilPbwpkpXLQkOb" style="width: 100%;">
                        <p class="caption">Validation Set Top-5 Accuracy</p>
                    </div>
                    <p>
                        <br>
                        <ul>
                            <li>Best top-5 accuracy: 73.3850 (16 epoch)</li>
                        </ul>

                        <br><br><span style="font-size: 20px;"><b>생성된 캡션 샘플</b></span>
                        <br><b>샘플 1</b>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_GvRg38oUTPWmaRiTyPAUvVE_4xUv_ZS5Ztf9dfq5nbmZmGSC9D2_jKjAiaJqrOoS5iFx8ECdFr44oGK5eSUgRWBijuXrz3i8jXnrEcDvVTz4WXl1yaBt9ZmA0szC8SGzXitkXc3kEnmbEugF40NadFfbS_mWA59SsIPOnVGQJHp97P4ec9Shqrd2QrBD7-SwbV9SIhVlakNFWeVbz3p1Mdum6PjgfpNYshV0Zfmx4YTfDkkcbnsuL9nManbml8zaIk8tLwsB-cKsNB3MpnLvoWzbv_riFo1XAwRjB4nSRJzQl-oapkk49RjwoM683PHIYBJpcdw_sz8zpB_sSoTfw0PFceGP3SzekX0jB3s27AItxs4Gz3VLn-31uNmOMnQcl8W8M0q57t6s21SNQqgUtiJVjtxi-ljTiKsZfb2EWJTwCNoZ_J7hY2wHylsdyAtpvv1mO4-q2EhhA4jqAVM9_XFV2tLj8qcW104sJ6Vtv4JBDcuEi3aZBsQuina6XX05Cmvj9dBa1WPbkKiuTh5mCu6EdCewCU8YFa8n5LgtWSM0g3lOAJnb4TVNR7ylUSbsYB_jbA00lP4Iax11vWU6h0W-s0SuempifsNmxvqq9dlOToBkes0Ruzb6Lt5slEg2kaNH_ziPdFBS-fwJZxSxbkF4PKlxWHQQh0KTmx08H-gQYCM2Aj__nJN9pX5pt8rQa85QMgoUbbl8d0pmQ5ElzJQd63YHASpDEZU0PGr5huABzjhhSscOj5eOFDq7S7Gcq5KHBmbZtwbrl0A_LQHLgMf91tvcFa59dfC4fk5S_unOwivkK9pkeLTI5KI61mtJ-BC4JYEqQBkyqgqvlvOgMmJJ6bLRUD_6L7rI5mQiUaGsEjYEy6etauIlDzfthqQDhsjHXeHRZiMUkDng7xKCtKH4_chBZ6V2_BAUcd_Sxil3mDmmmt4rXF5K6vQTY2JuCQQGFG55NaPdZnk-ITlqjzcPdzbe8pZ8jdvdrqavnQ9Gb6NeCqCSfBHu6X3BGZzJiZrEBt5ny4prLKsh0BgeYlKXjklihHp8LlP_iG7zhzUipMezhxMLfA7yQBzzX4iAeyXIWLbehDO2_3u4ohBkq4_yYgCFOrISlrbxLCMuJYdXHuKVPU57Sd4r2HFmdeMlNHZNxF_FSERFyNthOzKG5zSEzN-STrYxGdwluHAVSuVKOSNAVi3syqIiRFsuNjSbSCSHK3Hlu6i_yHpO5vVGdMaPdxGC0J044nV0r3IvFYR8UZjz1S_VqxKFa9O6z5_Kzr1zNaS21HUq4zf1CMiZM6Fyh7b7EUenjD_5xS6pVQG8aE1sJvaBQ3KJaL_NWrSuzqsQj01qsXcTuqVCfx0T-JeNEKHN-ojlKOZvF9LY2yA7YvHQIZSMcPt9OcKw0aqWACT679qMHQST6lwwDDOtYNcOZ6s7Cxp5Vr9C9allEnxOjPOloZjzx-Le0Fvs3-0-jyZx3dPWgfSVZQWWC9npEGz8JfK5qVr4m4iJkepCVBkwLtnkdiWdq9k3X0tuTrcuhcjAMZZQ" style="width: 100%;">
                        <p class="caption">샘플 1 캡션 생성 결과</p>
                    </div>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_H4sVM1QhQhu0bd2EnUSfcK6Mqh35IK6cYluABZKnbZr0L84Me-KOORVjyDoP2mwXMQ2OUAzN4BzoTd2w-tse5DuPSgmJEIOoNQPDOKylaCBt6PtUF1LPFJA23HzkW3Tba8UerixhnrcV33Gv9f-J_DEm-thPieVtF3rt5oOjc4oJaGM4znhSI0OVrI1BOiO41H4TMsuvhFFFPKwqbJuGT1CnQ1OqAEhR85kawx7Hps1RzaNxdfPjdkrnLbQ2rCDR_1qdFKMEuh6989AkhsE3DJhjQtR0cD4v_KK_A2MVEehnjWbQI2KrkS99vP_9hj7riHhEivyM0EAKsVfPylZ8kkfAhj4pc1AqY0tbtOTYzdAeZPgNrHuzuGcqtXm1qbAXKkjTcZr5Qm4eayywiWr91yOIkTDfAFLICYCd6iHhk1CITNkKsFEIEvBaBU6K8Hvr77cozgfMrMGnd01GVPGxxdmmiynH1IBYIGReGOvXfDX-jj4dCqmnWvmdIDR-rOJwRiJ9tcveDdHcYw4zRiaUT1chGJ-WosQa5D9El1ct7Na-TZKtX7t_H51h3TVJg5SJsBtSENKj_SNqdpDmxDlusj6saQtsPj870J-3kJxiSGnkFxyBvrvZ4eHiHrKddkZmJ5vnT1DHNJvuOBqF67r9okFQg_oEBUqf1tRIBKwTkX6wTnoRc-KivXCLZV2K9ZlBDyU_-dkTc3MkByQlO-d4VvDn1CEJgT6sqnzwF0rspwxj_7tijwPFRhk2AGB9tNf0i0eV6SQQBTsF734JuXUijvaNZ3SrhI1DIGhICirj8ro1DGS2yVtGKc72ZldcZKRf22Nl3BPAMPKXNKLNnlQ7aok0hKeOJI8pinLqMA7mYmXGL5hf9jnloLADFDRKHMU9KYJcA-sFJEUbvmOSLo7ky52-7zwnlHAp8gF02CzbDErGx8wPUZEn7dMsQXDUB46MPb8AiGF2YmS8nh3tepn9K17yGSn-67ySblkrAr0Vuts-ISru_FxpLPuKFOtYgCK8KLuJaZy_z7dTXIQ2qjYvx0Ocbi0dqV2UI3Y7g4Gye_pck93t1Ddlfbk_4DeDtdKGLKbqm-L9sE3bGe22Rvx9DXpLjIKs1PM_kT7N0cjI8TkDY6B8HPfUO23MzRCxqWQD7-FoB-5Uq62OcF6fniLodrWm_CXdxrDmXKse6J5Xk5b_y902suE2IKtKCKuGvqqyxBq79v5cBkZVcu81GLYnZkVjXWwgLForDnN1JDLgKqVE5dWutfm-lB4ZBg8EbXskmxnvA51Utx3SmxvL34gPOi-91Y7Ijg6QM0xzCiH-b3UW_5aS1kha62Lp4p3vIdCANQd62IYOY7c-oloqK1XdLBt5f_4AUZjrcJlZ3MH_QDJXu2Dq-UfuphbNs4MquAJrWG3gdBYvWF4RcvFOParDnxTF8JS9EDDlHCXCpD1ZgEdKc-h_sTcf6e8ndzVeX1DDYmCEY5MridGEuPCJVcZTh143oOwKIQRIJe66JQXARTxxsh1mv7heZ42UkjQ_BWQLtpz06UXapD" style="width: 100%;">
                        <p class="caption">샘플 1 attention 결과</p>
                    </div>
                    <p>
                        <br>캡션이 잘 생성 된 것을 확인할 수 있습니다.
                        그리고 boy, rock이란 단어를 생성할 때, 이미지의 적절한 위치에 모델이 attention 하는 것을 확인할 수 있습니다.

                        <br><br><br><b>샘플 2</b>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_GKi50PpafICLh5B7kc4ASXs4UsE_IITy9FY3Pv48mXDFqUZWVWJoCJNLXdTM3qVJniXMIfwqqHICbtT8nlEOO4A1rG13wpc40l4DO4wiWznmqMwTBWQC92_ylDmSpgxb1sCvKve6OFkF7ww1INhUN14AeHLBXReks27CTptf1D5MZBJM2ycIsZAdDJUqx1Y28jIGSD621WT5U3-1hoZPpfcSTZyRqANvHjd-uGBL2dhWidDBf8BoWg7wsVvSTgKCcQ_oAZ615kASu9Bv3i2_ycM2DaN7eYY8Rkq-WEhwKAXV0mzZecYi58jeg5Ievd3R0w-FgkOKGwieOdz_VdJM9pFv42H6pGh7H5xF7nHb-SHVrvQQ68izXXCwnJPy_bzq-6tpXz5s19B5VWSf86TKDhv_hy3qd7iv7U1NXzay8Z5QqsEVNjGOb_V6SdS-zWbZeVXrxyZ0lrlmTrXKOml0mSShrQjtOShRMfB-2H47zogqcR2snyTWvavbQT9D7I5Te6CBI_FJxnvoEDEvfpgc2noIPSSSiBUNleNYu38fro6U3qElVlBsrlrC9WsPEndatXMch16bmiwGvRXwKxzpggAmTVCZVPSUOytTaUHUkrS8S44Lk9MlV8ecdcFUun26LP5vVlozKTTh5ObF_Rzfx-BC91X_nenATKW9idcQSTUr11GEyWLrEE1WAtUbz4nZNKieOlkpTdwVj5HNpvBYK3wrtE5Ib6ekp7H0ZhG1hL5osrCMQ5y7CQMDNrzxFRycZ4zFu74pxCM8_hrFFA4jaFE0-Kx6pLfq31nl6LUfi2NzinBLfw6jZOvb0BU9_v2w9of6WPIhQXyxwLXmd2Qh4Ctuzdw3l2_rOcAWLu17x-nttdGYxZFmDX9x0kmP2J5ieCm4vheZInTOigOlWBl1eaeHurjXh6ROOsT0HKT8oqAq00e2dut3-U89bFQYe1jFIqeP5111-aEaAF9futynNaxqP-dEUYLAOwjCjHToDSfj0CJ7rl4XEepY2K2Z6P3tMMziiooxdkAC05aeZaezZibAi2hK-Dq7L_8imPbhhpXIjJfVm3-dUOO42SdkqQc9d9MKjyxDcyeNCeulaEOHOtgBNWHFm5CXFaiv9F1UNxY9pi7cN-IeGj7v0YwuqHkRFAlxZkdLt70O6q2Lcbrg9e6LUneUQkTl75lzYntmV87WDa_MCx9xmKZ9I8Q23TOnCAGOuPRUU_ZsSclpkUCu09vQtXBxj6QTjJgw4YHTBkji27HHvBogiuBzSOM0jUoYlYVkgYMV5TDXghmFoMejdDcKb6bGBohLR5nwQQFAi0GVNNi5gcUJkF9HRA50ftgbnenPlw2Z2Bx20pF9r1zKgX6oa3PkhKtSPLzPSZB1xIt_3yr9DN6jvWIeZxPKsnK0TBlr_XkGNcGIENZyPjo7I9WFJChdZmsjI_tLLiYGDEAQVKTqkWs5XaZIQcrBKWfq2q4SWYkZZZV8NMCkSKmVBLSUXSrqIWL1O6BPXu7jtAuOs2YeqevBcQSfBUZ1EiJHFVFJe-Qg" style="width: 100%;">
                        <p class="caption">샘플 2 캡션 생성 결과</p>
                    </div>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_FrKYQeSB9DhTqCFo4x1Sdv4o4SkN_g1MelFDUqUpU4UWSUhagtgE9xLG3k4RuJsfwoWwv3yUIgvfNJMxWPFfD0-TM7BKF9BILnDZlDacoP4wKS1c_PLp6lbVp5brrPJ225cpSjQG5H5DUNZ1epmj4XTv2FSFrk5MslZTKfVGasTC-NaXksYw6CxftVPb7kxJoO3eXaE2MfEk58bAuW3KrD0DEbPCyUAxtKtgjEpi8X3FpswvA7zEeotve8LGGQeNV_hAq6_SWF9kcnr8WU-mwwzHLebx4UhXt6iNzzj4eWEHVUTtnpzAUEkVOQ6eQsJ81Fx9M4ZUQ8hA9hByQmgXoPBdQBtFytzYMh2slHZnEgEcFFPE2X9GOu1MD0qjuk6qqWNl1g58ujYFPvnYBLMYWw1v7V6cqZwbBfzWjhjrVNvg3_fuzUPuBv4Rgm473oTj_CVHeVsjeF4218pVsY9TqQwqmOu3AP4XAs7sDYb38f5w0-L0qefVjfUMShHokQem_MJIeKp59grGm2dzasWrSLgcY8MiqvcSBPdtNkAmW8X6C7s-5gO3xlfBzcHyWrm8eIy8eB4Q23YZNneZt23nQeJ5KvScTL1JfRvcOvj1LgQqleGPfeF5T5FdTEXz5E69YxxwE332IVXjvaTtVUSFDOjZGn_7thy5EZTbBi12G-RCuJnDCNsmz-B9xkOFoWvOBEIKBepX-lEFPR0J0-a1_Kn4Z1YHOy1SDTilBB3iqOYMHRzv2Y54spCzuM71I_UP_2dtHJQ8aXzjOYlg43MLsasCMsmXb4BZymj9fvwoK_09KdHrxRIntAWMD5iIj4cEy5rf_zEUdH6iTYucp6jIl4NRVwNT-C_myLfgmTZR3Hr9MJ8zqjD9L6SVxShN1Mt5n_WtBNAs62nur69ODACtWyuzYHc0fopRF2JXl4HCcjF_4Sa4pf29wDsJmHXyHiR4--X1-J6G5Mum8mhE6RD38LAiDLihZ4NHgHx3tfbGEaNEdz-3TteMIBKjhj7KtvSh4v96UkJxnU_c9-Nq10Yyy3vuVeiCiSFdK50bFuVAGKpPwCRyrJDQ90TpvVV0Z3PwLr-V3fotWbijAOJ_uv0Ly5xFXihqOXnvhisUdhvtFjey2dqvMUIsMqAg0xDY73JzE7TkYusGZlgVPMX49wWFhcslqr-SxQnkI0kDb39AvxLAKVJnjlmIYrcY-5AdOfqptcDLGcpQ9MlJgn4U1y38ndlVDLtPmEscz5Lsb0v5ZUmGUz3HJrf5Mxx6JDTCBcnxBTtyw7es9wIEHE3-ZPLdU6D6YnlOGuQ9V5l9OOt0hBueie-3Caa_tc-W-6k_vmmL2upotHQjbbajympUhPBi6oP9sVu-nHtkfyA2hLqxtkSXBmuswse7AoPHU9efpe-dnM2miYXAz1Xn_xEvseSxpFKqVTVHkUC0Aretn0H5HX2iy18WLJ6-Lq_j6P1mL4JQTdbsAxVy27EYj6ghHBnPaJ4AEM_j2rk3LWAV4vxVZK7Q8GH4KcVHbmBKhilElxFeRJU5wn5sgG" style="width: 100%;">
                        <p class="caption">샘플 2 attention 결과</p>
                    </div>
                    <p>
                        <br><br><br><b>샘플 3</b>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_G5zLmZ3NmAJuvYlqa31rToH6qrauZdTEvynSKEcU5JmESZq-UZUHu4r2bj6wKEiwSDNTjEG-8c7h5ZF7XcmvOo1vdSkBTI21yv9drFzgaPGCwt93RmtKVGqPbKe-QT0FlxYrjgvP31sAvmxkjTc6voiTSGV2b7Y_q5dhs0f3VJmJT_H4WQH9FTc8DmTimFrUN2ejo-satQkZ9gX5T4SbQAxV5Vr7PAfucDqgv8PUmYVdAkMHhZhkK4DRXjRJXdmvPkmVUupxu_1ZRH9SOpLt1iuZ5fC30uGW2BfCyiyp9J4Y361Vvn4QU8WFTPZkoodqZhbjtrlKoXXs6e1hXg-V-PihJUeRjvVqXBhIush8mP7APembj8u2bfC6YyBQZ1r3v5lPp1FLDb0yIpiR-eUqhrbRwgqdHehVzWyaOlqbhBS5xr809T9vkSKmYdY0VTyZRI0XjEZWOoSmqmbkNLKQlddENp_2Wq1HmrjGPnsdc5M23-6wkezN2yJxCRX-7YoVDisS-zfO4gsw2LYlq4Mp8QKaPJNSl_mkC8JFOhsu_jTqOkJfeLt4Ym3hd7ZYQHmJkxzsmr5g3q4G9ZU1o3DPV33vq4HqA2qG0_J3pQkzay2yR_81HqY431Q7ttINidMomvlVkvC0K5jV9BCh8kNERy9-8SomL56adk19VQPPp-a76NPIqLFr-X7r-WT6qcuFCjrAqdj3IekEW18F4_nDWB0nYgflnOQJUr4v-RCmNcfxbbKE9WWhbT3Lng9G6MAFCCJ0Sx8mVuG0w06TZF31nqiz-n5uVIrDNiEpnG6YEzguwd5EIpmeiNJ4bbB1W6GGuk1U5IdyZdbeRQuJZEJ5U9ClwbgmtGrAdVx7Eufx-OFttyVvt3iM_vtXKU5Pbrb6_BwUvdm5o9BQa1Gg4nybNziLUB5684QTEq77HNvG2yfPvypodjeUykDInG_8vCcVgOKhfZo3jb6GXISH6HYPxVxs4seZmPY01CtIW2y85rem5cFb_AAcxUWBt6zyJpwOegiGA3ikNp4KgqwVWnsqrV8jK8W0HK5nJkZ0UHRjRADd4J2JpOBn3FZxi9y8wdZ4VflrmaTOoSwwg32n8Cun_zeEhRvZJF6vq0A_qEmLpMeKi08T5s3_qAq1ytVw35S-ruu1XAqIcMRSvuL6-KqewOxMs8tjQgtu6mp-uxVygYK0apVW2cmUVccM8z8o3ExV7QaWbMryy1knYP_DfE28r2aq_KlAdFsKiROqHI0sDD-pnGwts0AxrcvNrLG1Djh3uaA7KqqgGLGmUgeOcDTAcyvnID1LNs32flD63s_2gKtvhrtfRUFjuIBqa8R7zukiwOHqNbcaBpRZeA_RJT5HG1REkVAGywu0-oUvNW5Rxe7ET6vTQtC6HpKumwhF-KnshCAKpWwFnP1CjVMkM5fG_Y4Hpl53cUtXGRKRk4ebS7XnV2PNQgmsU9fADRsLUNMEKlDBKu4v-3iLWJIh9u_SeXd6g7uJvDsSKdSr3g5RU9k5E2Te2cgpaJJZpveWVvKNeSCzOfzw" style="width: 100%;">
                        <p class="caption">샘플 3 캡션 생성 결과</p>
                    </div>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_FTqAfAvXY9ld8WDe9y1NNDFNQG6hUSyZVJFGu89T45mOyWNBQPOaIhTbc-pf2mWvF8jkJZXPUy2VMXBC8bwsvffu_JKu--JRmsTvzLiMHM23njf_7BRNI_3ehCYtSFKW8hTIgj8A162nwSESz_yT2FPkdxaBSJrqfIWLQ-HK0_295FNBJZKK7oFcIsxFHxGEsNMPxpWdzTZIvG70trW_5rxo5Jw0XYS1aqzUYPX3zQ3mhSztCzqmLxJsFPL32r2G2v338v8hM_INYc3fibn0muUl6saqDz_NpqNrLfJFuhaZFNzMGD7Z8uFpzt0jlNPAauLXxlLa522ixCgiQv8tVMMVQPR9uw3f558-2niZYfzfNHeMTXItnwxtwKcafx9ad0joH4vaJoyZtaDQbzryXrYr48BHPkykQqPzxkg2glwHfoqLdiAryvb0oNVEPUiQ6G-vgfi64GOgMwwkpDg4cpnOZGOofGoFun2iy8Krx3tKuleadhj2Dn-QCKHMnjuzKm32xVNZJ6oD1ujjGTPZEG4yPsUM8AC4EJMxPfTcpcbduZRTqnGdCOC6TaveGcBZfBD60GKA9JpJzznCUmm5fi9fbp6y0G4tP8-31YSpiUiEyCZf16qH0xWibFqraWwyve_0gh8dGzUUEN46unrz4FLAW3HlSKTvhuyt8khtG48Ct5hWVW31tmZ2u6t4oOFHSqg5d6KdIYVIF2I5Vgdq3yPnTdk8ZgfoKskctWVYoHkZj_junlhNpagznLAsuEs444jvWfLJ3-S4_jpccNA41sjdls_CWJbXTCsGW2hqgk8szWpfW6YlKKZzezdJ3LF5spLoFX1CcqS70hhfqtiKuE-ux51tZvBm2mMSHizgSNLiev5vtQqT43otIlXZo3yNR4oRoeTGeds1Nk_lve-9_welIP8ObtT7TDdeRcHm1xHjAZU_Sur610rg990KYkuP4AiQ4iwxtHwv3m6ZZpm1v1KpAumANV0VqZopMXLYLjSTpHGL5GGnNd7MbTPB8l7FVh1ORcHy8Phzc5t1FhSdc_l8vdycH_XCHRTLkQnFZVwWy4xgJnDnoYTV3Csr53PsmbsUqXavTaxn5BkuIUNKmkcf07AGhutek-NTDzN7y8pMHkA6G1kidC5-2Xsn_DIAqtOOcTJSzN7bCCnS9cCZcKFiZUilm0RVyhR7ne2ofLIuZEQ63vBMCjF8U6oRhHBdRfRtuk8LWYsI6fjLnozpyjtfIpGFbCVtsEMMJKfhT7WrGsX0WSI2jtBMMxcTV3Cotm8PTxdESMDD3H6bmhCYHitUicNjDKjmrgiOETzXufu7-0zvN0qZ_OwMu-u0nPvOisYbROOCSGL2bYLlQe0_f9if4PQyMf8vLAbSYwO4Zc2y5VUW-2QKTb7IKxCaXhfT8M8fWsCBDwmBWJIdhz88L9-kZtaiTlEoBv6lpjir8oZ-9jggc5DDiYVs02ObChVcYmjV08SIo7V0mvBVoP6e8A1qZ85q2od6zP4Xio-WmsBKoaYkvheXrytB6e3gr9mYBNMYAhAQLx" style="width: 100%;">
                        <p class="caption">샘플 3 attention 결과</p>
                    </div>
                    <p>
                        <br>샘플 3 또한 girl, hair, wind 등의 단어를 생성할 때, 이미지의 적절한 위치에 모델이 attention 하는 것을 확인할 수 있습니다.

                        <br><br><br><b>샘플 4</b>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_FziPQoNeIuXJPMJdXEUxPY8WQ4-9ShF41x86xWXFicqAgaT25ssbTjbswtV5CN5p06UObGyUYYbbb_Kajpo4vVHwDi74lb8FpekmaITb3-eMd8y9qvf3BTgRqZmtdt08MJhpkHYrJ-0XfZpZObtz3j80Qv2HniSyI2BUxweo9PaR6gyFWSZwX8qDpT96Zkpc901p_LJ5JqwUUFWt3QqtGQ3VjpGa-bFLEjJ-qAhTL36-h025uiWrqwaxUlTZBCYf-fM88i-qwkiP4Lu9ZDEMyTamG1LYtJ1weMR-vzbWtqidobGAJnP1sMPs4bGHtFut95jF3JglOiSPMaX05ng9KNBzZm1hRiMwQwboFFS1Ft3mvx9_iVgKwQd7Ov9VVbD6Wxuvke6RyDmjiARLmCRSSFSg43rSXjwCO2NyrY6e-uu6G4koa7Ycf909DbgVV5FOU_B2DcuBrSkY-encP_blaAmnMuiQ2fKhQ3_5doSKpvEdNA7DLgH2xBg-8TYaaMRIZzEivByCibBdTADhiaYfEYuWBZBaqJHW7mngoCCynDrGfcMikEctqJh85TdI2EYED0dOUzakIEJs82W3Q2gsCiXOXG-w5pF7Zd35ppv4hAsZoa4eJpIxXWggVd-HOs0CBvBlvK5OkwZCk8se-QINxLze9dEBwyoTWiVFwY_b_fRxs77Dlspl1bAmgGd42HVHIipSJOEdV7wTcyKC6SxRF9uBVj2dSSQwUj3qJnZR7uoTjHLdtrLhfmkIoAhKWDXn7efCLhxPu1M46TpFV7J3LuDMMyrzaO5YOb5Jp8_GPVjVn3veCWCPLkDr6ecZgF3kCDDESv2D818vAZ8RVSxtiIgiB4Eb8poCDJWWJm7A6-Bq8hvj4k3fO3JTUzhPZTyivWW2R_xNkhV3E4Y09uIh9Y-DNXuJrSlPf6mGoz5-Xe3c3Ai7HVmAapiTiA__mMGeCFHlYTwj4ubIX_LrDaRyZvptuTkC5ibhj5Q8xH8s1_Qlg8YQxPiW5D91tU1NQo_8lIiRZb7_8GMMxbOYMrQMehhIvIFqvK_1ohUG-P1D8Yj1Iglr27RQEQzGiub_WgrQ2CQHAiXzFnsLDDQyqHZKPR6zeNjuNm1FJFsEeh0Pn-hSpHLOczhBwS68ztmdMFl1mjhQfPAtWa7fVHrYDVz1zw7965Wegg5nVHAxZOQzGwQn-coCPh63_VuGPAYigfF1UawjwjRUtj0VpHYe1laCKf5Ez1VyKorjOM8M9kkCdOKEutL4lN0GvIkQp69t6B_fhX_EjEfi7zdcta58qx6IYw6GP5NXOdQqRtbtf2yVA9Ld6le-_x6dxKKafy6sWuX1D5bJ8-Qdt71Di7oP09NP9ChpXLU_jfqGZqaqvodgoY8U1GNhl7m0r7pkViDXfqZB-cg0V-hXxzdCC3HrJeOVY-ST5HW9MzjF70NZMCOJY0Es0V9NCIbFPsQLDrsFvDYENzUnQg1NlMoxMCrijl5NxqgqQgHNSSB4fhr2MegfHP1hBgiElHto3EjKgo0aXumvj9V3U4VQ0D" style="width: 100%;">
                        <p class="caption">샘플 4 캡션 생성 결과</p>
                    </div>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_GedgyZX1UDEHRALAO_sMf3YxeKWYGLSxIKbjzM5TM41HG1wblpJ178SpO5J_m-ZjAF7_HXNPy9xOXlXwzQWlNSJrxLM9krAr7S6-mC8HEvoDfAtkTmijyiEVIkYlKJ-w8lJ3rQfZcTM8k-U0k7CIuE-Dj-4X60SWa2o-hpVAdhXm9uDqrrnrX5mUDQH3yaqDH8f5BVvPQGjJDxvzlM9ZllLwq1WYbKgdAnbubCxlsXW4mlv6BoyYsbhNPMSeQILlKQzH7Ad6qAEzZ4hrl8KoFgP9u9BZ1RG9kG6afG9lqJ68jsurRtj-HdKewYhZ47qpxNozqVjvnrELtezm_jKXtDnalLWmPewl0qeoixldM0Is3ER0BwYC16E7x-6hvoWwtpjtOv3TXsHe0PPbmuO_iucM4VYrR41mN6YEdapKdGzF0qu0FYN-yOfMj0kALCmdxdLu0QSg4j-OjVJqNOW2pKDG4iHMu4TUH0kw80gPKvtAsgjCGRSTPz6PcPJHK8C1QdsGNqE7_i11NrXRbAZMuzSA77hXNtwo_z5NnYV0omgKCdJCwV9JAZLRMr_sayDVkpA11lZhFrbHX7sUs2KTgAqyVqIFf-6uOyxbqgH8DTsfUWyno47GpDO_PMKBZubYkNq4DQD-tgkioTO06NTO9DA3c24xCqFyMVYQNVtChkT5c5ygktE7UF0w7RwzhPUUuOwbJsYsx8SVJFUk9wa3iMpUChGEpFkCbR_5VtHWiPPTQiiH6XoEgpkdgzNBLizwP_-NQKw_dfsQyiQkyWytLOBgixkX_ANwhBJkklNtzouEcVPyJuy8BBcPULBnvLOCkHJTS3jdppFnL50ePJf9pBEGDKxOKqWS_c-s7vtdxiLKLDe1mb0LhnCZTVR2PlJPPwQAvMcN6PmYGnRtW__q52JW72wW78aixt9NU0RCYmQJgCbW5cgJOZbJPK8NJkwH_4I3xJaJqg7GIyi7yXGWFxlFV12l1oBs6KM5BBVqZozkG-U1aLrdACxpdZFyaij5CamD2uUA4d6GI9OzjmlsowmBNaNxwh9cXAlg5LwgKOjpZlu8W4_dL2F3OZ3YYin8zevnPGXW3rWt8J5cQD_icWJP3HozIkweUELsFVctm4B5rdqnFG7N-0rasRbY1aD8VL91DROs0p01P8Lw7OKg8BNTz_slvoidGUriFzRKDKzZnEKGF0_GNh3CD6wKlsMD7yU7RT3VA35-udxtbRJuctmVag3R5xo2p0vKTnc9bgU74SyyHij_WPKOwoihcXmr_qnCN120vTf0vfsSWr8hKE2kJzQ1-W_smcigPwrH-TJ_4a6m7uPquXPaA7WRUfjE5Z2RL1JroJ6mpdqeWHyTdhnuV-AkvKm5X4DJRKsaQhmmMxx7FRQMM_ftc6UjqGuGtcig1PzNKpl2khgckvlSoQtlgPNOGRLYBURPmoGBXxVgS75FDy1ktl6F-DiZM3eABga7vBOpsmQRmH5sRcVsnFpISHr4DpWx8_h-gZJ9z-Sgakjmh-MRpbpx6IiQxCDdPRcKWYuCkt" style="width: 100%;">
                        <p class="caption">샘플 4 attention 결과</p>
                    </div>
                    <p>
                        <br><br><br><b>샘플 5</b>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_GDo3S_bYmREhpCRNW0hOBcsqBpQor1sWXMQwIf9ikK7q9mKmdAB8ZikiWFA5lv7AFEmYCTZ1AVIjEMNEX45UXiTnmVNAn_AKyym3MRhNM6E3lP0fpdzb2gEBiF4_SNzmmIofUSdCY9zFxggSI2eaA1vDY_58uY5XXVq0Qy3UVrt3BHqKY-ERepRxXDeDklkCfBlHnna893tPlLSB7hhGvPQz7SPvh1rAUyBC35GlFFMxmdZ1opt0Z2lUT5yV9H9RCPDj9U2OivlCyy66_RqqnTR7aqEAnht-A8k-HBH6gx_P8vJWZ0mCt7QTZoL1nRQz6krvh3s3dx-ojg_biKoLFqf65_pI-4DAKygZZdOcN3BMX2c_d1yeXkXNX7ExXrYkMKbao6AiYuxy6GOw4SQaZdlOX0ZLXlPFxKzh9rtzs1PFDJXsAcRaB6B_X61DP9ZpTfmQZqzDvqz9uzKZs9VK3ngreg4xROuwshNLXJbb0P9nLPCRstpDagzslXHebAnpldq3oDPsiXqPOR2mk7sYoQuCTpiPAj7AA8wO338TKzD_5TxZoErrl1eHWQvQX6PfEgl2FbAZCL8Rr4FM8iluG3fI2Lj21HKY5_yNB9E0Ve4LRUF69g2ouRxaARC2lDOM-zCIuNNbfzh6xVVpVPXkwpVg2gT6z0ahUeoYnSNsUr_ZSHri2qlrflJgn8vF9rbdcmFZhnlAJaSTRLUh6UADvFt_zMTegFsFqpn0HZ93O3CS19IIT5xjLrKi0NQUy8PqhnrOgL3Ns5sxBtLg6k-af8m1I5srOgZIaY4j_F5_DTwKEPaNDsrs7P9VA7TJdffVkFOKm_2ux-WIYyQZeytez31yqx7iU5L9SAGz5fb370amAEyMqNAnMAwd8NJiat37wiD_saSofUb3plmzgxbUQqhGEY5K8nspCrl3v65AOL95HecFJEpE1-1AcD4gKE4pDsgC_mLRLPgtbQSme-RzxS1Tt5YfOH2jBkrGpiyfUthnGhg5TcmHkOrcfqVjhdDcsXr6Tpen-mpv13UAhji-y6FqDYIDmQrWifdXlHxekA0CTSi37uOE7XwypWYdcSOL_J3THSecrWM3aZ8evjy1mXnOwK7WGUzDouzorkbLHGM7JXbfCZhKIkhTwyN9wTTXRnOdXsmNWNwUesIPMTSk-vgUnx3kSd9086yAyZJrTiUw8rnjoye6LxZ6fvzs0JYt3FZtACLNO8HSuyOQRWx6c0rMjO722hlcgvZRhrOoCvXy0tuWSptuLgii99T6jMFuKD4Dk2kA5hqWXKL0ZhzsuYl2LyWaaQY_nz1x1NYhicoJA5XF_WRYcoWTo0gvlQ9u-Cckko9foKv99ABQyh8HM9LWpaMwUyYjHhN5z14N1v9Zvp5m4qqeXUbDxHFfbvPEFRZXLsRCNrDArOoZ4_Hw1Uf6kA4iHv4pBUx6rHYvSubtAHUQOipE2Pg1CYW1fFl5sj5Ppyro2tPYZHuVR5EpQySaA2xtJvyntHtZDoQASrb9t-i6HUTXyXfY9mhSywLxpe8rm7fQa7" style="width: 100%;">
                        <p class="caption">샘플 5 캡션 생성 결과</p>
                    </div>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_EFKOD_onEkHAAxzjXFIg6f7XDIcW17_a9hWMUL5taWdxEsDzsiCkTVuzKDGrSZS5_F7ue6QYKV6nwlLnuyTA2gyQO1R2TyrY7VDo4NjEcJCnbN-PKlxXfwOFnDSW7CVLhyRX44UsKKtM50P6pHxnsgMluoq8Ex8-QdNithzewHMEAipbuy_imk8DgMQsPOqPQMTj9t5X2_n9HWG9usxptSIe1-MgWnZ7hpZl-bi-oABRizGfMa5ebbo7_qIIbG5tcAjO9Oz2ix4uRTD971wvOvwhzv9JOg952yLzyVgL_B-OWmtX2QgAn5Eqb4k2Jk2vHR464rSglEI5K3F5ldXTe04uvla2YovvLPtHg5VaUD9DCahK1KIfChiVJmxfC6V2UvkMFLD9Vr3uSF_H2lwityE6597o5bLHdJ9x6SSPvZM8dGHNZi1tthjhypr_KKpyMWZPI_fAePUX2cz7yLb1Oa0-23Z-JJPUcQLWc2hGTMu6PTHeVsLntLa4vB9teRYZ5JC9BHHWYawellKUlCs3OauD6ntiWjHZ_NKDMnWTB0TD2Cv4MQEqhmWUD6igafc_2KDQg1ZuhywaRB3ZVT2yE4RgUtWYXYUqOUYVrvNIBZdhtCVV95SaBjaiZBkGRdXkoy5tciR-pcE9tXMXKF3hjUBh-UcktDFgA2BUac1VhiurCN8JkeymDr8LUizMg9X82LIEW9PnJDZX6Kc-gFW9doN2P233ey4w9w7GsP9j1ZgPd2Se_IVtkn9MXXHz8Pq1g_OTU5-DrZLKpvo5jC0hroqi90B36dD_pQapAdhLW2oi1R2cH1nffe56q_NX28atWxzE7x6wESIiC6lwgaX6Ob15TmqKzJkuNMVesWOgHq7f8C6yaqfRj5rzIWuIinTwPKoQ23F2EVqfvpvSXjeZ-uPrYHFJBziANJse2j6n3KPTrWUsxl9IpEC0Vp5TkXKzvLMAh6hQRP0D7CaFZ6bjtFl99B47tsPHiDKFYiBZUVfABEVHO-BppOLnxFG3jgE-n-vph3AggBjMT6u32z82YSFKg18ugCmB8d07RD83-rJFCTVU8JUgaaSXiKpijLbotvkgTnkRLWPpnJpW8fY_SZ3yXZe_TMzeNLoD0f3guJLLEqsgPYCR1e-TTTR00XEsI6A1uRvd5YMGWpMczT9Em02h4jmG8HhxTbIID9Gu4DFi1bJMdKz69uv5Q1ibCfiWy_nWp_oxXf8yUyDVlYOOmohjUN4nsz61FpWK66Z8nJSrKsbO1uh8h8wMU46Vvc_POcAw-kKFozSbUY3JQnsoIKCH5tbHU7oMbLtP1rOZL1ngyghPuBJLDnw-V6t9N5SHlOzwWFjUSpw3tL2CCdn_YTqqmVCoNy2AKVAJyMFzPQFnWSG5Z9q_c1nFM5KnaAtMEahRfiXG6pnfycUR-5ilG7zDybgxDXEGAGIkImttPR6x_vXItKOstoU-D93uwebz-YMT66YBiCag95xnNPMaL_Wc1Sp0OEZo_tGebrlYNhGSS_ADCi2_RIKleBQOAxf4tLMixomWFy" style="width: 100%;">
                        <p class="caption">샘플 5 attention 결과</p>
                    </div>
                    <p>
                        <br>위에서 샘플 5개의 결과를 살펴보았습니다. 전반적으로 켑션이 잘 생성되고, 단어를 생성할 때 이미지의 적절한 위치에 attention을 하는 것을 확인할 수 있었습니다.
                    
                        <br><br>지금까지 ResNet과 LSTM을 이용하여 Flickr8k 데이터를 이용하여 image captioning 모델을 제작해보았습니다.
                        학습 과정에 대한 전체 코드는 <a href="https://github.com/ljm565/image-captioning-show-attend-and-tell" target="_blank"><span class="highlight" style="color: rgb(0, 3, 206);">GitHub</span></a>에 있으니 참고하시면 될 것 같습니다.
                    </p>


                </div> 
                <div class="tag">
                    <b>태그</b>&emsp;#ResNet&emsp;#LSTM&emsp;#ImageCaptioning&emsp;#Flickr8k
                </div>
                <div class="pageTurner">
                    <div class="pageTurnerLeft">
                        <span><a style="position: absolute; left: 0;" onclick="pjaxPage('img2txt1.html');" onmouseover="colorOn(this);" onmouseout="colorOff(this);">&lang; 이전글</a>
                        <br>Image Captioning (Show, Attend and Tell)</span>
                    </div>
                    <div class="pageTurnerRight">
                        <span><a style="position: absolute; right: 0;" onclick="alert('Image Captioning 마지막 게시물 입니다.\n\nThis is the last post of Image Captioning.');" onmouseover="colorOn(this);" onmouseout="colorOff(this);">다음글 &rang;</a>
                        <br></span>
                    </div>
                </div>
                <span id="readNum"></span>
                <div id="disqus_thread"></div>

                <script>
                    headHighlightColorChanger();
                    (function() { // DON'T EDIT BELOW THIS LINE
                    var d = document, s = d.createElement('script');
                    s.src = 'https://novicetraveler.disqus.com/embed.js';
                    s.setAttribute('data-timestamp', +new Date());
                    (d.head || d.body).appendChild(s);
                    })(); 
                </script>
                <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </article>
        </div>

        <div id="menuRelated">
            <div class="menuButton">
                <img id="menuImg" src="init/index_img/menu_black.png" onclick="openMenu(this);">
            </div>
            <div class="menu">
                <img id="menuExtension" title="메뉴를 확장합니다." src="init/index_img/extension_black.png" onclick="extendMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
            <div class="bigMenu">
                <img id="menuCompression" title="메뉴를 축소합니다." src="init/index_img/compression_black.png" onclick="compressMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
        </div>

        <script>
            detectScroll();
            pushFunc();
            detectSize();
        </script>
    </body>
</html>