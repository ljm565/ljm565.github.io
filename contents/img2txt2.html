<!DOCTYPE html>
<html>
    <head>
        <title>ResNet, LSTM을 이용한 Flickr8k 이미지 캡션 생성</title>
        <meta name="description" content="ResNet과 LSTM을 바탕으로 이미지 캡션을 생성하고, decoding 단어별로 이미지의 어떤 부분에 attention이 이루어졌는지 가시화합니다.">
        <meta charset="utf-8">
        <link rel="stylesheet" href="init/index.css">
        <link rel="stylesheet" href="init/contents.css">
        <link rel="stylesheet" href="init/index_img/icons/css/fontello.css">

        <link rel="preconnect" href="https://fonts.googleapis.com"> 
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> 
        <link href="https://fonts.googleapis.com/css2?family=Dongle:wght@300&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Gowun+Batang&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic&display=swap" rel="stylesheet">

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        <script src="init/index.js"></script>
        <script src="init/jquery.pjax.js"></script>
        
        <meta name="viewport" content="width=device-width, initial-scale=0.8, max-width=1">

        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-219110982-1"></script>
        <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-219110982-1');
        </script>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7745178886614102"
        crossorigin="anonymous"></script>

        <meta property="og:url" content="https://ljm565.github.io/contents/img2txt2.html" />
        <meta property="og:title" content="ResNet, LSTM을 이용한 Flickr8k 이미지 캡션 생성" />
        <meta property="og:type" content="website">
        <meta property="og:description" content="ResNet과 LSTM을 바탕으로 이미지 캡션을 생성하고, decoding 단어별로 이미지의 어떤 부분에 attention이 이루어졌는지 가시화합니다." />
        <meta property="og:image" content="https://lh3.googleusercontent.com/fife/AMPSemecCFttT_ywQY0GHOwLmpR2L07e7UFkrCVOEX4RoWSC3SgrgzEG5HccKEERmy1LuBn2VMyWdRI-IQK0HamWMuDiCufUyGozI0DPCRlnijxXx7M6VvNlK1Kb86lI_o4IYbwSrpMrUOGvYoCtg8eJB-s0F_C4Y0J2ioESYqQnWUKDqzkI4oxzxYEcQmeCXMiGqE0H9G0uZ5UoO3Xjk6wPXP71VHD0TDPRQJdufPitNp1a9VhDBSvBEO2hzhc_lGod6r5ZVN9I4iC-gMewymLR9e5WWG3Gh1MxmAESbIH7cJT_SGUw8NDyUVkgx5wTs1wlQ1vkla3lsqfuv5TRhDja4oIsxlv_X_mGY1EETdlz5H3DxSgDA4CjDfkHMezQuYDGdutbPbzTjyJH6McVT17axT014ZJx5ot5Db305ZjyCh7rXTieeu9Iwv9FUDdyfj8dHke0odMDzS1UuXx3XZWC__oOugaCT28E3r90_raVu06u-Ka8XotiNWXcZs2A0tQPvIWmqwLc6C6fzsFxOEEUVZVxxYYUtzoZ4YI1X5Zjaad_62ryEREHKanQ8hIVYPDD6Nk__QmsAoxVZbFFACVMTalxu2dYVCy6ScxltC9Qw_P1HxP7BP26knARIhBDGMHU28kD_Liz1gRNJ3mLZT9dDdVRJq02hdO2RWF0xBlI5kN_bNOxvJcqXFJTI3td8Z0xrUNjPCnjTtBmS__dGj5csP1BBl7NNWcYZBDU2umZNCSFI7JE6411q_-NEa8J7O7Le_HN6xmswOaqIbTLdUY4PPUSsL8z9LBEK9mYz9Pu1ZaFdomuAnWxXfervN1GXMg3CZ1QuV2NBQ7Gt9fNDwN0RBxMnXFiMcRp3_7nuD1SEhyhFph9qAXs0N1sIFWoRSdEYo6pNrR_Qzy3rpCC08YWCotqytMNu2mnXgTG8YmBsTYE6lSnPMbbC2XYcd3GALWa13uCHh31rZlCqjp2hVEloI6dkM-ZcG2BIfDW7aeIUIAf_ZowWj6gp-imUyC6H9XxJkZ-E3FuL3sAEOF-fuoiBx8oN4QQR11qKEsNzKZ_-bqltqDvzkukqy_RfSumxJJ38u2Wb1U6sMBMay0Ay_F-sq0XqxO3OfN_A1JkGAAcEQdV34kemeMcfnSP8jr8AY4uVQAvKlKFP3aW5KAOQHOdldu6SB7XPL78IgNyzfNZKex38eAqzg-P9RbGOl2187sNpBc0ovtMrEJtvFS0yr8_erb_x8fzYHXGcyuCKgWkv2sea6PNQZNhhSsib0YSSKGvl7QBXbwmcsigbYAPhtsanaNAL-QECa1U2B5mbYp1CkawWiWsL7ehl083jgeJ7Tpzryb_6oL-CHmNl-s-icgCbFumNKbt_AHYYZj4m5cM5ZWGqqe8M81PjRnYoHtdr8GV4BhUBEGUuqU1uj9Im73QZlZ5d2kspELXfKLMVuZ_dCGjQwfDGzfB7_FUIXcl3mS-ZW8m9cbeACN10BPFBZZWojI" />
    </head>   
    <body>
        <div id="modeButton">
            <button type="button" value="dark" onclick="darkMode(this)" onmouseover="hoveringOn(this)" onmouseout="hoveringOff(this)">
                <div class="modeImg"><img id="modeImg" src="init/index_img/moon_off.png"></div>
                <div id="modeState">다크 모드로 보기</div>
            </button>
        </div>

        <div id="container" onclick="reload();">
            <article>
                <script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
                <script>
                    initMathJax();
                </script>
                <div id="mainHeadWrapper">
                    <div id="mainHead">
                        <h1 class="contentHead">딥러닝 이야기 / Image Captioning / 2. ResNet, LSTM을 이용한 Flickr8k 이미지 캡션 생성</h1>
                    </div>
                </div>
                
                <div class="title" style="background-image:url(https://lh3.googleusercontent.com/fife/AMPSemecCFttT_ywQY0GHOwLmpR2L07e7UFkrCVOEX4RoWSC3SgrgzEG5HccKEERmy1LuBn2VMyWdRI-IQK0HamWMuDiCufUyGozI0DPCRlnijxXx7M6VvNlK1Kb86lI_o4IYbwSrpMrUOGvYoCtg8eJB-s0F_C4Y0J2ioESYqQnWUKDqzkI4oxzxYEcQmeCXMiGqE0H9G0uZ5UoO3Xjk6wPXP71VHD0TDPRQJdufPitNp1a9VhDBSvBEO2hzhc_lGod6r5ZVN9I4iC-gMewymLR9e5WWG3Gh1MxmAESbIH7cJT_SGUw8NDyUVkgx5wTs1wlQ1vkla3lsqfuv5TRhDja4oIsxlv_X_mGY1EETdlz5H3DxSgDA4CjDfkHMezQuYDGdutbPbzTjyJH6McVT17axT014ZJx5ot5Db305ZjyCh7rXTieeu9Iwv9FUDdyfj8dHke0odMDzS1UuXx3XZWC__oOugaCT28E3r90_raVu06u-Ka8XotiNWXcZs2A0tQPvIWmqwLc6C6fzsFxOEEUVZVxxYYUtzoZ4YI1X5Zjaad_62ryEREHKanQ8hIVYPDD6Nk__QmsAoxVZbFFACVMTalxu2dYVCy6ScxltC9Qw_P1HxP7BP26knARIhBDGMHU28kD_Liz1gRNJ3mLZT9dDdVRJq02hdO2RWF0xBlI5kN_bNOxvJcqXFJTI3td8Z0xrUNjPCnjTtBmS__dGj5csP1BBl7NNWcYZBDU2umZNCSFI7JE6411q_-NEa8J7O7Le_HN6xmswOaqIbTLdUY4PPUSsL8z9LBEK9mYz9Pu1ZaFdomuAnWxXfervN1GXMg3CZ1QuV2NBQ7Gt9fNDwN0RBxMnXFiMcRp3_7nuD1SEhyhFph9qAXs0N1sIFWoRSdEYo6pNrR_Qzy3rpCC08YWCotqytMNu2mnXgTG8YmBsTYE6lSnPMbbC2XYcd3GALWa13uCHh31rZlCqjp2hVEloI6dkM-ZcG2BIfDW7aeIUIAf_ZowWj6gp-imUyC6H9XxJkZ-E3FuL3sAEOF-fuoiBx8oN4QQR11qKEsNzKZ_-bqltqDvzkukqy_RfSumxJJ38u2Wb1U6sMBMay0Ay_F-sq0XqxO3OfN_A1JkGAAcEQdV34kemeMcfnSP8jr8AY4uVQAvKlKFP3aW5KAOQHOdldu6SB7XPL78IgNyzfNZKex38eAqzg-P9RbGOl2187sNpBc0ovtMrEJtvFS0yr8_erb_x8fzYHXGcyuCKgWkv2sea6PNQZNhhSsib0YSSKGvl7QBXbwmcsigbYAPhtsanaNAL-QECa1U2B5mbYp1CkawWiWsL7ehl083jgeJ7Tpzryb_6oL-CHmNl-s-icgCbFumNKbt_AHYYZj4m5cM5ZWGqqe8M81PjRnYoHtdr8GV4BhUBEGUuqU1uj9Im73QZlZ5d2kspELXfKLMVuZ_dCGjQwfDGzfB7_FUIXcl3mS-ZW8m9cbeACN10BPFBZZWojI);">
                    <div>
                        <span class="mainTitle">ResNet, LSTM을 이용한 Flickr8k 이미지 캡션 생성</span>
                        <br><br>
                        <div style="display: table-cell; margin: 0;">
                            <img src="init/index_img/profile.png" style="width: 30px; cursor: pointer;" onclick="pjaxPage('/');">
                        </div>
                        <span class="subTitle" style="display: table-cell; text-align: left; vertical-align: middle; padding-left: 20px; line-height: 125%;">작성자: 여행 초짜<br>작성일: 2022.09.18</span>
                    </div>
                </div>

                <div id="content">
                    <p>
                        시작하기 앞서 틀린 부분이 있을 수 있으니, 틀린 부분이 있다면 지적해주시면 감사하겠습니다.
                        
                        <br><br>이전글에서는 image captioning 모델 중 Show, Attend and Tell 논문 모델에 대해 살펴보았습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">이번글에서는 ResNet, LSTM을 이용하여 Flickr8k 데이터를 가지고 image captioning 모델을 제작해보겠습니다.
                        본 코드의 구현은 python의 PyTorch를 이용하였습니다. 그리고 모델을 학습하면서 training set과 validation set의 loss의 변화와 더불어, 각종 지표 (BLEU, NIST, top-k accuracy), attention 영역과 캡션 생성 결과도 살펴보겠습니다.</span>

                        <br><br>그리고 Show, Attend and Tell 논문의 설명은 <a onclick="pjaxPage('img2txt1.html');"><span class="highlight" style="color: rgb(0, 3, 206);">이전글</span></a>을 참고하시기 바랍니다.
                        그리고 학습을 위한 코드는 GitHub에 올려놓았으니 아래 링크를 참고하시기 바랍니다(본 글에서는 모델의 구현에 초점을 맞추고 있기 때문에, 데이터 전처리 및 학습을 위한 전체 코드는 아래 GitHub 링크를 참고하시기 바랍니다).

                        <br><br>그리고 텍스트를 토큰화 하기 위해 사용한 토크나이저는 word tokenizer를 구현하여 사용하였습니다.
                        물론 현재는 unknown 토큰 문제를 해결하기 위해 <a onclick="pjaxPage('word2vec1.html');"><span class="highlight" style="color: rgb(0, 3, 206);">Word2Vec 글</span></a>에서 설명한 byte-pair-encoding (BPE) 같이 subword 기반의 토크나이저가 많이 사용되지만, <span class="highlight" style="color: rgb(0, 3, 206);">본 글에서는 attention 모델이 각 단어를 예측할 때 이미지의 어떤 부분에 attention을 했는지 살펴보기 위해서 단어 기반의 토크나이저를 선택하였습니다.</span>
                        
                        <br><br>여담으로 PyTorch의 유명한 image captioning 튜토리얼이 있습니다. 본 코드의 모델 initialization은 튜토리얼을 참고하였습니다.
                        하지만 튜토리얼의 캡션 길이 기준으로 sorting 후 decoding 하는 과정이 비효율적이라 판단하여, 한 번에 max length를 모두 decoding 하는 방법으로 모델을 훈련하였습니다.
                        마지막으로 원래의 논문에서 소개한 Tanh를 이용하는 Bahdanau attention 기반의 soft attention을 구현하였습니다(시간이 된다면 hard attention과 beam search 코드도 추가할 예정입니다). 
                    </p>
                    <div class="link">
                        <a href="https://github.com/ljm565/image-captioning-show-attend-and-tell" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);">"Show, Attend and Tell" Image Captioning 구현 GitHub 코드</a>
                    </div><br>
                    <div class="link">
                        <a href="https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);">PyTorch Image Captioning 튜토리얼</a>
                    </div>
                    
                    <p>
                        <br><br>오늘의 컨텐츠입니다.
                        <ol>
                            <li>Image Captioning 모델</li>
                            <li>Attention 모듈</li>
                            <li>Image Captioning 모델 학습</li>
                            <li>Image Captioning 모델 학습 결과</li>
                        </ol>
                    </p>
                    
                    <p>
                        <br>본 코드에서 구현한 Show, Attend and Tell 논문 링크는 아래에 달아놓겠습니다.
                    </p>
                    <div class="link">
                        <a href="https://arxiv.org/pdf/1502.03044.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);">Show, Attend and Tell 논문</a>
                    </div>



                    <h1 class="subHead">Attention을 이용한 Image Captioning</h1>
                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center;">&ldquo;</span>
                        <span>Image Captioning 모델</span><br>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        여기서는 image captioning을 위한 encoder, decoder 모델에 대해 살펴보겠습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">코드는 PyTorch로 작성 되었으며, source 이미지를 encoder를 통해 represent 한 후, 이를 바탕으로 decoder의 <span class="var">hidden</span> state로 넣어 target caption으로 decoding 합니다.</span>
                    </p>

<pre>
<div class="codeWrapper">
<div class="lineNo">
<pre id="code1">
</pre>
</div>
<div class="code">
<pre>
<span class="reserved">class</span> <span class="clazz">Encoder</span>(<span class="clazz">nn</span>.<span class="clazz">Module</span>):
    <span class="reserved">def</span> <span class="method">__init__</span>(<span class="var">self</span>, <span class="var">config</span>):
        <span class="clazz">super</span>(<span class="clazz">Encoder</span>, <span class="var">self</span>).<span class="method">__init__</span>()
        <span class="var">self</span>.<span class="var">enc_hidden_size</span> = <span class="var">config</span>.enc_hidden_size
        <span class="var">self</span>.<span class="var">dec_hidden_size</span> = <span class="var">config</span>.dec_hidden_size
        <span class="var">self</span>.<span class="var">dec_num_layers</span> = <span class="var">config</span>.dec_num_layers
        <span class="var">self</span>.<span class="var">pixel_size</span> = <span class="var">self</span>.<span class="var">enc_hidden_size</span> * <span class="var">self</span>.<span class="var">enc_hidden_size</span>

        <span class="var">base_model</span> = <span class="method">resnet101</span>(<span class="var">pretrained</span>=<span class="reserved">True</span>, <span class="var">progress</span>=<span class="reserved">False</span>)
        <span class="var">base_model</span> = <span class="clazz">list</span>(<span class="var">base_model</span>.<span class="method">children</span>())[:<span class="num">-2</span>]
        <span class="var">self</span>.<span class="var">resnet</span> = <span class="clazz">nn</span>.<span class="clazz">Sequential</span>(*<span class="var">base_model</span>)  <span class="annot"># output size: B x 2048 x H/32 x W/32</span>
        <span class="var">self</span>.<span class="var">pooling</span> = <span class="clazz">nn</span>.<span class="clazz">AdaptiveAvgPool2d</span>((<span class="var">self</span>.<span class="var">enc_hidden_size</span>, <span class="var">self</span>.<span class="var">enc_hidden_size</span>))

        <span class="var">self</span>.<span class="var">relu</span> = <span class="clazz">nn</span>.<span class="clazz">ReLU</span>()
        <span class="var">self</span>.<span class="var">hidden_dim_changer</span> = <span class="clazz">nn</span>.<span class="clazz">Sequential</span>(
            <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="var">self</span>.<span class="var">pixel_size</span>, <span class="var">self</span>.<span class="var">dec_num_layers</span>),
            <span class="clazz">nn</span>.<span class="clazz">ReLU</span>()
        )
        <span class="var">self</span>.<span class="var">h_mlp</span> = <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="num"><span class="num">2048</span></span>, <span class="var">self</span>.<span class="var">dec_hidden_size</span>)
        <span class="var">self</span>.<span class="var">c_mlp</span> = <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="num"><span class="num">2048</span></span>, <span class="var">self</span>.<span class="var">dec_hidden_size</span>)

        <span class="var">self</span>.<span class="method">fine_tune</span>(<span class="reserved">True</span>)


    <span class="reserved">def</span> <span class="method">fine_tune</span>(<span class="var">self</span>, <span class="var">fine_tune</span>=<span class="reserved">True</span>):
        <span class="return">for</span> <span class="var">p</span> <span class="return">in</span> <span class="var">self</span>.<span class="var">resnet</span>.<span class="method">parameters</span>():
            <span class="var">p</span>.<span class="var">requires_grad</span> = <span class="reserved">False</span>

        <span class="return">for</span> <span class="var">c</span> <span class="return">in</span> <span class="clazz">list</span>(<span class="var">self</span>.<span class="var">resnet</span>.<span class="method">children</span>())[<span class="num">5</span>:]:
            <span class="return">for</span> <span class="var">p</span> <span class="return">in</span> <span class="var">c</span>.<span class="method">parameters</span>():
                <span class="var">p</span>.<span class="var">requires_grad</span> = <span class="var">fine_tune</span>


    <span class="reserved">def</span> <span class="method">forward</span>(<span class="var">self</span>, <span class="var">x</span>):
        <span class="var">batch_size</span> = <span class="var">x</span>.size(<span class="num">0</span>)

        <span class="var">x</span> = <span class="var">self</span>.<span class="var">resnet</span>(<span class="var">x</span>)
        <span class="var">x</span> = <span class="var">self</span>.<span class="var">pooling</span>(<span class="var">x</span>)
        <span class="var">x</span> = <span class="var">x</span>.view(<span class="var">batch_size</span>, <span class="num">2048</span>, <span class="num">-1</span>)

        <span class="return">if</span> <span class="var">self</span>.<span class="var">dec_num_layers</span> != <span class="num">1</span>:
            <span class="var">tmp</span> = <span class="var">self</span>.<span class="var">hidden_dim_changer</span>(<span class="var">self</span>.<span class="var">relu</span>(<span class="var">x</span>))
        <span class="return">else</span>:
            <span class="var">tmp</span> = <span class="clazz">torch</span>.<span class="method">mean</span>(<span class="var">x</span>, <span class="var">dim</span>=<span class="num">2</span>, <span class="var">keepdim</span>=<span class="reserved">True</span>)
        <span class="var">tmp</span> = <span class="clazz">torch</span>.<span class="method">permute</span>(<span class="var">tmp</span>, (<span class="num">2</span>, <span class="num">0</span>, <span class="num">1</span>))
        <span class="var">h0</span> = <span class="var">self</span>.<span class="var">h_mlp</span>(<span class="var">tmp</span>)
        <span class="var">c0</span> = <span class="var">self</span>.<span class="var">c_mlp</span>(<span class="var">tmp</span>)
        <span class="return">return</span> <span class="var">x</span>, (<span class="var">h0</span>, <span class="var">c0</span>)



<span class="reserved">class</span> <span class="clazz">Decoder</span>(<span class="clazz">nn</span>.<span class="clazz">Module</span>):
    <span class="reserved">def</span> <span class="method">__init__</span>(<span class="var">self</span>, <span class="var">config</span>, <span class="var">tokenizer</span>):
        <span class="clazz">super</span>(<span class="clazz">Decoder</span>, <span class="var">self</span>).<span class="method">__init__</span>()
        <span class="var">self</span>.<span class="var">pixel_size</span> = <span class="var">config</span>.enc_hidden_size * <span class="var">config</span>.enc_hidden_size
        <span class="var">self</span>.<span class="var">dec_hidden_size</span> = <span class="var">config</span>.dec_hidden_size
        <span class="var">self</span>.<span class="var">dec_num_layers</span> = <span class="var">config</span>.dec_num_layers
        <span class="var">self</span>.<span class="var">dropout</span> = <span class="var">config</span>.dropout
        <span class="var">self</span>.<span class="var">is_attn</span> = <span class="var">config</span>.is_attn
        <span class="var">self</span>.<span class="var">pad_token_id</span> = <span class="var">tokenizer</span>.pad_token_id
        <span class="var">self</span>.<span class="var">vocab_size</span> = <span class="var">tokenizer</span>.vocab_size
        <span class="return">if</span> <span class="var">self</span>.<span class="var">is_attn</span>:
            <span class="var">self</span>.<span class="var">attention</span> = <span class="clazz">Attention</span>(<span class="var">self</span>.<span class="var">dec_hidden_size</span>)
        <span class="var">self</span>.<span class="var">input_size</span> = <span class="var">self</span>.<span class="var">dec_hidden_size</span> + <span class="num">2048</span> <span class="return">if</span> <span class="var">self</span>.<span class="var">is_attn</span> <span class="return">else</span> <span class="var">self</span>.<span class="var">dec_hidden_size</span>

        <span class="var">self</span>.<span class="var">embedding</span> = <span class="clazz">nn</span>.<span class="clazz">Embedding</span>(<span class="var">self</span>.<span class="var">vocab_size</span>, <span class="var">self</span>.<span class="var">dec_hidden_size</span>, <span class="var">padding_idx</span>=<span class="var">self</span>.<span class="var">pad_token_id</span>)
        <span class="var">self</span>.<span class="var">lstm</span> = <span class="clazz">nn</span>.<span class="clazz">LSTM</span>(<span class="var">input_size</span>=<span class="var">self</span>.<span class="var">input_size</span>,
                            <span class="var">hidden_size</span>=<span class="var">self</span>.<span class="var">dec_hidden_size</span>,
                            <span class="var">num_layers</span>=<span class="var">self</span>.<span class="var">dec_num_layers</span>,
                            <span class="var">batch_first</span>=<span class="reserved">True</span>)
        <span class="var">self</span>.<span class="var">dropout_layer</span> = <span class="clazz">nn</span>.<span class="clazz">Dropout</span>(<span class="var">self</span>.<span class="var">dropout</span>) 
        <span class="var">self</span>.<span class="var">relu</span> = <span class="clazz">nn</span>.<span class="clazz">ReLU</span>()
        <span class="var">self</span>.<span class="var">beta</span> = <span class="clazz">nn</span>.<span class="clazz">Sequential</span>(
            <span class="clazz">nn</span>.<span class="clazz">ReLU</span>(),
            <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="var">self</span>.<span class="var">dec_hidden_size</span>, <span class="num">2048</span>),
            <span class="clazz">nn</span>.<span class="clazz">Sigmoid</span>()
        )     
        <span class="var">self</span>.<span class="var">fc</span> = <span class="clazz">nn</span>.<span class="clazz">Sequential</span>(
            <span class="clazz">nn</span>.<span class="clazz">ReLU</span>(),
            <span class="clazz">nn</span>.<span class="clazz">Dropout</span>(<span class="var">self</span>.<span class="var">dropout</span>),
            <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="var">self</span>.<span class="var">dec_hidden_size</span>, <span class="var">self</span>.<span class="var">vocab_size</span>)
        )

        <span class="var">self</span>.<span class="var">embedding</span>.<span class="method">apply</span>(<span class="var">self</span>.<span class="method">init_weights</span>)
        <span class="var">self</span>.<span class="var">fc</span>.<span class="method">apply</span>(<span class="var">self</span>.<span class="method">init_weights</span>)

    
    <span class="reserved">def</span> <span class="method">init_weights</span>(<span class="var">self</span>, <span class="var">m</span>):
        <span class="return">if</span> <span class="method">isinstance</span>(<span class="var">m</span>, <span class="clazz">nn</span>.<span class="clazz">Linear</span>):
            <span class="var">m</span>.<span class="var">bias</span>.<span class="var">data</span>.<span class="method">fill_</span>(<span class="num">0</span>)
            <span class="var">m</span>.<span class="var">weight</span>.<span class="var">data</span>.<span class="method">uniform_</span>(<span class="num">-0.1</span>, <span class="num">0.1</span>)
        <span class="return">if</span> <span class="method">isinstance</span>(<span class="var">m</span>, <span class="clazz">nn</span>.<span class="clazz">Embedding</span>):
            <span class="var">m</span>.<span class="var">weight</span>.<span class="var">data</span>.<span class="method">uniform_</span>(<span class="num">-0.1</span>, <span class="num">0.1</span>)


    <span class="reserved">def</span> <span class="method">forward</span>(<span class="var">self</span>, <span class="var">x</span>, <span class="var">hidden</span>, <span class="var">enc_output</span>):
        <span class="var">x</span> = <span class="var">self</span>.<span class="var">embedding</span>(<span class="var">x</span>)
        <span class="var">score</span> = <span class="reserved">None</span>

        <span class="var">gate</span> = <span class="var">self</span>.<span class="var">beta</span>(<span class="var">hidden</span>[<span class="num">0</span>][<span class="num">-1</span>])
        <span class="return">if</span> <span class="var">self</span>.<span class="var">is_attn</span>:
            <span class="var">enc_output</span>, <span class="var">score</span> = <span class="var">self</span>.<span class="var">attention</span>(<span class="var">self</span>.<span class="var">relu</span>(<span class="var">enc_output</span>), <span class="var">self</span>.<span class="var">relu</span>(<span class="var">hidden</span>[<span class="num">0</span>][<span class="num">-1</span>]))
            <span class="var">enc_output</span> = <span class="var">gate</span>*<span class="var">enc_output</span>
            <span class="var">x</span> = <span class="clazz">torch</span>.<span class="method">cat</span>((<span class="var">x</span>, <span class="var">enc_output</span>.unsqueeze(<span class="num">1</span>)), <span class="var">dim</span>=<span class="num">-1</span>)
        <span class="var">x</span>, <span class="var">hidden</span> = <span class="var">self</span>.<span class="var">lstm</span>(<span class="var">x</span>, <span class="var">hidden</span>)
        <span class="var">x</span> = <span class="var">self</span>.<span class="var">fc</span>(<span class="var">x</span>)
        <span class="return">return</span> <span class="var">x</span>, <span class="var">hidden</span>, <span class="var">score</span>
</pre>
</div>
</div>
</pre>
<script>
lineMaking("code1", 107);
</script>
                    <p>
                        위 코드에서 나오는 config 부분은 <a href="https://github.com/ljm565/image-captioning-show-attend-and-tell" target="_blank"><span class="highlight" style="color: rgb(0, 3, 206);">GitHub 코드</span></a>에 보면 <span class="var">config</span>.json이라는 파일에 존재하는 변수 값들을 모델에 적용하여 초기화 하는 것입니다.<br><br>
                        <span style="font-size: 20px;"><b>Encoder</b></span>
                        <ul>
                            <li>4번째 줄: Encoding 된 이미지 feature의 width, height 값 설정.</li>
                            <li>5번째 줄: LSTM decoder 모델의 hidden dimension.</li>
                            <li>6번째 줄: LSTM decoder 모델의 레이어 수.</li>
                            <li>7번째 줄: Encoding 된 이미지 feature의 전체 픽셀 수(가로x세로).</li>
                            <li>9 ~ 11번째 줄: <span class="highlight" style="color: rgb(0, 3, 206);">Encoder backbone model, pretrained 된 모델의 마지막 2개의 pooling, fully-connected 레이어는 제외.</span></li>
                            <li>12번째 줄: 위에서 설정한 encoding feature 가로, 세로 크기를 맞춰주기 위한 pooling layer.</li>
                            <li>19 ~ 20번째 줄: Encoding된 이미지의 feature를 LSTM decoder의 hidden, cell state로 만들어주기 위한 레이어.</li>
                            <li>22번째 줄: Pre-trained 된 모델의 첫 5개 레이어를 제외한 레이어만 학습(high level feature 레이어만 학습).</li>
                            <li>34 ~ 48번째 줄: 이미지가 학습 시 거치는 부분</li>
                            <li>41 ~ 42번째 줄: Decoder layer 수가 1이 아닐 때, hidden, cell state 차원을 맞춰주기 위함.</li>
                        </ul>

                        <br><span style="font-size: 20px;"><b>Decoder</b></span>
                        <ul>
                            <li>55번째 줄: 7번째 줄과 동일한 값.</li>
                            <li>56번째 줄: 5번째 줄과 동일한 값.</li>
                            <li>57번째 줄: 6번째 줄과 동일한 값.</li>
                            <li>59번째 줄: 모델의 attention 여부.</li>
                            <li>60번째 줄: 토크나이저의 pad token id.</li>
                            <li>61번째 줄: 토크나이저의 vocab size.</li>
                            <li>62 ~ 63번째 줄: Attention 사용하는 경우 Attention 모듈 정의.</li>
                            <li>64번째 줄: Attention을 사용할 경우 decoder input 차원은 사용안할 때 비해 2048이 커짐(Attention 결과를 다음 decoder input에 대해 concatenate하여 들어가기 때문).</li>
                            <li>66 ~ 71번째 줄: Embedding 레이어, LSTM 모델, dropout layer 선언.</li>
                            <li>73 ~ 77번째 줄: 논문에서 언급한 beta 레이어.</li>
                            <li>78 ~ 82번째 줄: 다음 단어를 예측해야하므로 vocab size의 크기만큼 내어주는 fully-connected layer 선언.</li>
                            <li>84 ~ 93번째 줄: Decoder weight 초기화.</li>
                            <li>96 ~ 107번째 줄: Target 캡션이 학습 시 거치는 부분.</li>
                            <li>107번째 줄: Attention score도 결과와 같이 반환.</li>
                        </ul>
                    </p>




                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>Attention 모듈</span><br>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        위의 image captioning 모델에서 attention을 사용할건지 여부를 선택할 수 있었습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">만약 attention을 선택하게 된다면 아래의 attention 모듈에 ResNet encoder의 output과 deccoder의 이전 output의 결과가 들어가게 됩니다.</span>
                    </p>

<pre>
<div class="codeWrapper">
<div class="lineNo">
<pre id="code2">
</pre>
</div>
<div class="code">
<pre>
<span class="reserved">class</span> <span class="clazz">Attention</span>(<span class="clazz">nn</span>.<span class="clazz">Module</span>):
    <span class="reserved">def</span> <span class="method">__init__</span>(<span class="var">self</span>, <span class="var">hidden_size</span>):
        <span class="clazz">super</span>(<span class="clazz">Attention</span>, <span class="var">self</span>).<span class="method">__init__</span>()
        <span class="var">self</span>.<span class="var">hidden_size</span> = <span class="var">hidden_size</span>
        <span class="var">self</span>.<span class="var">enc_wts</span> = <span class="clazz">nn</span>.<span class="clazz">Sequential</span>(
            <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="num">2048</span>, <span class="var">self</span>.<span class="var">hidden_size</span>),
            <span class="clazz">nn</span>.<span class="clazz">ReLU</span>(),
            <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="var">self</span>.<span class="var">hidden_size</span>, <span class="var">self</span>.<span class="var">hidden_size</span>)
        )
        <span class="var">self</span>.<span class="var">dec_wts</span> = <span class="clazz">nn</span>.<span class="clazz">Sequential</span>(
            <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="var">self</span>.<span class="var">hidden_size</span>, <span class="var">self</span>.<span class="var">hidden_size</span>),
            <span class="clazz">nn</span>.<span class="clazz">ReLU</span>(),
            <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="var">self</span>.<span class="var">hidden_size</span>, <span class="var">self</span>.<span class="var">hidden_size</span>)
        )
        <span class="var">self</span>.<span class="clazz">score_wts</span> = <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="var">self</span>.<span class="var">hidden_size</span>, <span class="num">1</span>)
        <span class="var">self</span>.<span class="var">tanh</span> = <span class="clazz">nn</span>.<span class="clazz">Tanh</span>()
        <span class="var">self</span>.<span class="var">relu</span> = <span class="clazz">nn</span>.<span class="clazz">ReLU</span>()


    <span class="reserved">def</span> <span class="method">forward</span>(<span class="var">self</span>, <span class="var">enc_output</span>, <span class="var">dec_hidden</span>):
        <span class="var">enc_output</span> = <span class="clazz">torch</span>.<span class="method">permute</span>(<span class="var">enc_output</span>, (<span class="num">0</span>, <span class="num">2</span>, <span class="num">1</span>))
        
        <span class="var">score</span> = <span class="var">self</span>.<span class="var">tanh</span>(<span class="var">self</span>.<span class="var">enc_wts</span>(<span class="var">enc_output</span>) + <span class="var">self</span>.<span class="var">dec_wts</span>(<span class="var">dec_hidden</span>).unsqueeze(<span class="num">1</span>))
        <span class="var">score</span> = <span class="var">self</span>.<span class="clazz">score_wts</span>(<span class="var">score</span>)
        <span class="var">score</span> = <span class="clazz">F</span>.<span class="method">softmax</span>(<span class="var">score</span>, <span class="var">dim</span>=<span class="num">1</span>)

        <span class="var">enc_output</span> = <span class="clazz">torch</span>.<span class="method">permute</span>(<span class="var">enc_output</span>, (<span class="num">0</span>, <span class="num">2</span>, <span class="num">1</span>))
        <span class="var">enc_output</span> = <span class="clazz">torch</span>.<span class="method">bmm</span>(<span class="var">enc_output</span>, <span class="var">score</span>).<span class="method">squeeze</span>(<span class="num">-1</span>)
        <span class="return">return</span> <span class="var">enc_output</span>, <span class="var">score</span>
</pre>
</div>
</div>
</pre>
<script>
lineMaking("code2", 29);
</script>
                    <p>
                        <span style="font-size: 20px;"><b>Attention</b></span>
                        <br>위 코드에서 나오는 config 부분은 <a href="https://github.com/ljm565/image-captioning-show-attend-and-tell" target="_blank"><span class="highlight" style="color: rgb(0, 3, 206);">GitHub 코드</span></a>에 보면 <span class="var">config</span>.json이라는 파일에 존재하는 변수 값들을 모델에 적용하여 초기화 하는 것입니다.
                        <ul>
                            <li>4 ~ 14번째 줄: Encoder의 output과 decoder의 output이 거치게 되는 linear layer 선언.</li>
                            <li>15번째 줄: Encoder의 각 sequence 별 attention score를 내어줘야 하므로 차원을 hidden dim &rarr; 1로 바꿔주는 layer 선언.</li>
                            <li>20 ~ 29번째 줄: Attention 모듈 학습 시 거치는 부분.</li>
                            <li>28번째 줄: Attention score를 encoder output에 곱해주어 weighted sum 하는 부분.</li>
                        </ul>
                    </p>
                



                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>Image Captioning 모델 학습</span><br>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                       이제 기계 번역 모델 학습 코드를 통해 어떻게 학습이 이루어지는지 살펴보겠습니다.
                       아래 코드에 <span style="color:rgb(86, 155, 214);">self</span>. 이라고 나와있는 부분은 GitHub 코드에 보면 알겠지만 학습하는 코드가 class 내부의 변수이기 때문에 있는 것입니다.
                       여기서는 무시해도 좋습니다.
                    </p>
<pre>
<div class="codeWrapper">
<div class="lineNo">
<pre id="code3">
</pre>
</div>
<div class="code">
<pre>
<span class="var">self</span>.<span class="var">encoder</span> = <span class="clazz">Encoder</span>(<span class="var">self</span>.<span class="var">config</span>).<span class="method">to</span>(<span class="var">self</span>.<span class="var">device</span>)
<span class="var">self</span>.<span class="var">decoder</span> = <span class="clazz">Decoder</span>(<span class="var">self</span>.<span class="var">config</span>, <span class="var">self</span>.<span class="var">tokenizer</span>).<span class="method">to</span>(<span class="var">self</span>.<span class="var">device</span>)
<span class="var">self</span>.<span class="var">criterion</span> = <span class="clazz">nn</span>.<span class="clazz">CrossEntropyLoss</span>(<span class="var">ignore_index</span>=<span class="var">self</span>.<span class="var">tokenizer</span>.pad_token_id)
<span class="var">self</span>.<span class="var">enc_optimizer</span> = <span class="clazz">optim</span>.<span class="clazz">Adam</span>(<span class="var">self</span>.<span class="var">encoder</span>.<span class="method">parameters</span>(), <span class="var">lr</span>=<span class="var">self</span>.<span class="var">enc_lr</span>)
<span class="var">self</span>.<span class="var">dec_optimizer</span> = <span class="clazz">optim</span>.<span class="clazz">Adam</span>(<span class="var">self</span>.<span class="var">decoder</span>.<span class="method">parameters</span>(), <span class="var">lr</span>=<span class="var">self</span>.<span class="var">dec_lr</span>)

<span class="return">for</span> <span class="var">epoch</span> <span class="return">in</span> <span class="clazz">range</span>(<span class="var">self</span>.<span class="var">epochs</span>):
    <span class="return">for</span> <span class="var">phase</span> <span class="return">in</span> [<span class="str">'train'</span>, <span class="str">'test'</span>]:
        <span class="return">if</span> <span class="var">phase</span> == <span class="str">'train'</span>:
            <span class="var">self</span>.<span class="var">encoder</span>.<span class="method">train</span>()
            <span class="var">self</span>.<span class="var">decoder</span>.<span class="method">train</span>()
        <span class="return">else</span>:
            <span class="var">self</span>.<span class="var">encoder</span>.<span class="method">eval</span>()
            <span class="var">self</span>.<span class="var">decoder</span>.<span class="method">eval</span>()

        <span class="return">for</span> <span class="var">i</span>, (<span class="var">img</span>, <span class="var">cap</span>, _) <span class="return">in</span> <span class="clazz">enumerate</span>(<span class="var">self</span>.<span class="var">dataloaders</span>[<span class="var">phase</span>]):
            <span class="var">batch_size</span> = <span class="var">img</span>.size(<span class="num">0</span>)
            <span class="var">img</span>, <span class="var">cap</span> = <span class="var">img</span>.<span class="method">to</span>(<span class="var">self</span>.<span class="var">device</span>), <span class="var">cap</span>.<span class="method">to</span>(<span class="var">self</span>.<span class="var">device</span>)
            <span class="var">self</span>.<span class="var">enc_optimizer</span>.<span class="method">zero_grad</span>()
            <span class="var">self</span>.<span class="var">dec_optimizer</span>.<span class="method">zero_grad</span>()

            <span class="return">with</span> <span class="clazz">torch</span>.<span class="clazz">set_grad_enabled</span>(<span class="var">phase</span>==<span class="str">'train'</span>):
                <span class="var">enc_output</span>, <span class="var">hidden</span> = <span class="var">self</span>.<span class="var">encoder</span>(<span class="var">img</span>)
                
                <span class="var">decoder_all_output</span>, <span class="var">decoder_all_score</span> = [], []
                <span class="return">for</span> <span class="var">j</span> <span class="return">in</span> <span class="clazz">range</span>(<span class="var">self</span>.<span class="var">max_len</span>):
                    <span class="var">trg_word</span> = <span class="var">cap</span>[:, <span class="var">j</span>].unsqueeze(<span class="num">1</span>)
                    <span class="var">dec_output</span>, <span class="var">hidden</span>, <span class="var">score</span> = <span class="var">self</span>.<span class="var">decoder</span>(<span class="var">trg_word</span>, <span class="var">hidden</span>, <span class="var">enc_output</span>)
                    <span class="var">decoder_all_output</span>.<span class="method">append</span>(<span class="var">dec_output</span>)
                    <span class="return">if</span> <span class="var">self</span>.<span class="var">config</span>.is_attn:
                        <span class="var">decoder_all_score</span>.<span class="method">append</span>(<span class="var">score</span>)

                <span class="var">decoder_all_output</span> = <span class="clazz">torch</span>.<span class="method">cat</span>(<span class="var">decoder_all_output</span>, <span class="var">dim</span>=<span class="num">1</span>)

                <span class="var">loss</span> = <span class="var">self</span>.<span class="var">criterion</span>(<span class="var">decoder_all_output</span>[:, :<span class="num">-1</span>, :].<span class="method">reshape</span>(<span class="num">-1</span>, <span class="var">decoder_all_output</span>.size(<span class="num">-1</span>)), <span class="var">cap</span>[:, <span class="num">1</span>:].<span class="method">reshape</span>(<span class="num">-1</span>))
                <span class="return">if</span> <span class="var">self</span>.<span class="var">config</span>.is_attn:
                    <span class="var">decoder_all_score</span> = <span class="clazz">torch</span>.<span class="method">cat</span>(<span class="var">decoder_all_score</span>, <span class="var">dim</span>=<span class="num">2</span>)
                    <span class="var">loss</span> += <span class="var">self</span>.<span class="var">config</span>.regularization_lambda * ((<span class="num">1</span>. - <span class="clazz">torch</span>.<span class="method">sum</span>(<span class="var">decoder_all_score</span>, <span class="var">dim</span>=<span class="num">2</span>)) ** <span class="num">2</span>).<span class="method">mean</span>()

                <span class="return">if</span> <span class="var">phase</span> == <span class="str">'train'</span>:
                    <span class="var">loss</span>.backward()
                    <span class="var">self</span>.<span class="var">enc_optimizer</span>.<span class="method">step</span>()
                    <span class="var">self</span>.<span class="var">dec_optimizer</span>.<span class="method">step</span>()
</pre>
</div>
</div>
</pre>
<script>
lineMaking("code3", 43);
</script>

                    <p>
                        <span style="font-size: 20px;"><b>학습에 필요한 것들 선언</b></span>
                        <br>먼저 위에 코드에서 정의한 모델을 불러오고 학습에 필요한 loss function, optimizer 등을 선언하는 부분입니다.
                        <ul>
                            <li>1 ~ 5번째 줄: Loss function, encoder, decoder 모델 선언 및 각각의 optimizer 선언.</li>
                        </ul>

                        <br><span style="font-size: 20px;"><b>Image Captioning 모델 학습</b></span>
                        <br>다음은 기계 번역 모델 학습 부분입니다.
                        코드상에서는 7 ~ 43번째 줄에 해당하는 부분입니다.
                        <ul>
                            <li>26 ~ 31번째 줄: Decoding step별(토큰별)로 attention을 하기 위해서 for문으로 반복하여 돌림.</li>
                            <li>36 ~ 38번째 줄: 논문에서 언급한 regularization loss term.</li>
                            <li>35 ~ 43번째 줄: Loss를 계산하고 모델을 업데이트 하는 부분.</li>
                        </ul>
                    </p>




                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>Image Captioning 모델 학습 결과</span><br>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        <span style="font-size: 20px;"><b>Loss History</b></span>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemdPvKRZkhvQkMNK0P61Jdlb8oq0H6U0xQYbXytH5ujs0HDujIS2yf9ptI-pYzsNQBgOLPp5CvUli_rSmLLEQGViuc8N6G9dTfyYAleWSpCKSWBHCwgNfy_fBOIrtSMqYe6V-5GO-BZd-coRq9yh2PLIYXeT-AaqvbETX57OZlwgC5ck17JZ-BVm2QtUCBhKbQstReJTKdOh3xPvB1HfrVbzt4aavbWJP3oKyUx2U32xM8EXfvFp7APsA-P2mzNoeSMcvOLVoayt20B8Kh82hQ3Fl4J2V5r1lMLNS9OmkYG1tUxq1HxfO5_Zv5na44TQCEZtalgoGhq_0eiwbLddin9JaEiLjpddnBYlTiMQtrhSHlAEL3hacQMVI2f3AQKhy1CsxShwsaa1X5Cib2aEdg6L7PbHmcatAGKuZ-MmURi26RgC32bW0X8LQbVthl__SxtWZK_tgTkP1uZU08XoRMXAv4MKLMmIRpKyK9hZlL-lfCOr4MnxNsZQo7c-lClIXWevfD7bVoTJDFOPRYmx7nLtikOZaDn5KyZa312d7UP9jPiIuGU2CnlbbMit4DZpQWJTf519EiMLWLaiNqjQnc9nRhgzT-JS4UbwMYTHnE97XVm2ixeDbp5KHAsg9efmK8zW_9uwYmdIEcfq2GlKrnOM2rmds7hSyeYnlvCtT1Rz97BhG61lnqLZGdpYD7eLUzC1QWL_akEcxpOypXBd52q7W-9gOJ0-BBBudkKVvLoRNb6aSRUk9Fm9eOr3nlMeLtrdMwlh8ip7YE_r1JoFt2PGMrWNKlLlI2W2k5247lyrmj7pXBFzYj7h-36pmq93dXaAfymN78-8ep4S6Mmqp8T9YTK6-AUscd1eSmVxxo8oyJH18TmkBt5yOalGNvoK4FvDED41DJoaBBnUPOBfQuO2yMNznC2ppkBWFu_r4En12sW0ENGHVuZVDVVBvV4wMtMCORaVPB8NPivuJYbWQ96LQj6yu7aSJeG4aPmqNkISnrqQykOzMztF6t83WbCE42JyUZyE5ZAUm784-IG7e-jLf1jHpPO4wEuVHts5pihTDc1FjhJXBBJhq54TUCmwcIJBBN-gPLaT8lMAPNgowYUF01Knmh_cVqzwtS4hIH6eZFFgUqkwOSipwUYvw0n0OwOXcbCY_VX_-ln7Fe3HauZXw8V_1IyOqm0dps-zm5E2z38JuL6heqjf5Q8oZA11vPAlX5V5HYevG2WOnu-WfF_zOIvCovRKlzRiYQ0jTlX1TJLt0BIkrWPjwDhV5FxU8QEctHa0ez6qWlJKD4R-9Vpklzkj3GS6Q6o32g66WyIPPhPh7dRC4vxwuUZyE1l4dO0ACNjMaQuGYjeg-b4wH_eQUtNn1H_nk-_tcdDwEXvMXVsVVDno_LU7F0z-V52Hh95owFfIDzAthcs4K7zr6nim2vZuu0yVARK8cg6A8nhJKdkvvb_jRqU5NJ08V9jjA_HZGlFdsFb6y4jDu2aBKAg" style="width: 100%;">
                        <p class="caption">Loss History</p>
                    </div>
                    <p>
                        <br><span style="font-size: 20px;"><b>Validation Set BLEU Score History</b></span>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemfvdsUdvd9A0PY2Ff59FpydK6n4K04RtJidv4d_u5gQXFVBHRXzLJ1xk80OCcTwn2yO79zOuHtVsGeRzw1WdyI9FmszkYUw6rxcNgT15gtvCuEPakb7O0j7hKHKXwkDSnTODlIexRw6DG8MbKejjZnkFU3IMSmzXkOgnZSqmMfRqTQxJ1Sv6fVX7FCsGg3yppgYGtK5Vezm2dU2tpLzz5xf4uo5i99B8JHhLNmIRZnCN2dNUL5kridWLi7pM-Y1E1x6YdW8PWEChNOjwMU0hmsbI4YEgQiIfFTREacLq_hYL0Zm5m402rO-5gGaTZUA_oCT5scCPbxIjNpBHdJiw_AbnSVKtqPIyhGPXaP8ZzGVsueWeJ0X1cUZ8bWpaHxgKK748rQGmqqzDxVAaZoivDcZ6mcvSZuTIEQsAZuyeju85aOYrWrKdTI08fWOdNKMX2rKPt-1FSXcEMcO31Yp26_pV-_aZIwtBsDN7RBcjWY8fqQFo9c3Kw2G1K9c2EyEek8uGtRVO-31ASvoXc8AvL41Y1K5LWyFEY-222dM0WsKDk9--C6Lf8rykhTraRGxpFJRPIugGId_Aksa5ZYa_wtOt-qlRc51NfOrlRb72NEI_1JZtQgA_gw0rfSLMHw3dgawN-ayihzGAguG8A6TAv41-pKUOjqfqeJjcUp1w9VFe6xItJO4Ug8CX7DS-gwsm7TKsNW5O1KdR3QfxueWXTlGAGnSAiUyRP_ZBtr1KrWLUrPJAiQP45tB97FcK7tP21ZW-hQD8DfGfIdXlVLbkmOs_6hor5lgV7r3yj0TgpnPxMPrAT2MGP8D_mmZF4X9GV6Tx5aE-q1wpqO6R9ufG6sblKJOOcnuH05Ap1MR7Al59pdPIZwE-DYaFy37bt__Sh0fvXyW3F_BdQghQ_tBDk0nCVe_dKHrue_QhdxELe8EPPvf9qdAYeJBF_K3YMFi0-e5mOaTMtNHnzGyc9bNp52OLXHCvV5zs1SsMq9FHrueE0S4wbPwv7oog25EM_4rL06O2CDpbUHCa7AoNtA41uKW6SCx0tXza4ymJI4Y9YXH2wOEbc7Y_GhRZXd2yKIiIRMtgsExMLR6RnZkXq7oAFFXS6LiX2yXfWM7vSBfExQe69jKyFuO_aElrsK9Pc4DMlhhuLigfA2UUFNLFXYZVYEvqp5id3BY0F4ltolrv_B0BDavVbAH7ZhVAfZHfJK3wg6wi8xpj0kBD_xUr2kBp1d1j0csmqfEfk9sEQgGt6x3P8uebZb2LIfjTB7DC6rTXvF4WFV_NOJYjghpxtbRbm1be1bakNS8Lpn2lOzzhg9xqefOg2JlFjaChoGX7AXkZgFWLeby__ZKOMvumV1SmJH848LNGkpeasRWRjgH--KvB47AC0pp4GQpw1S33tHPS7mspi_MfR1M953_HHeSZ6g-p9vi6EYIw0lHaK-XcAZ99KhuT27LFLhbR9heCj3UASTQUPJcytCckOPmIfxLMUk" style="width: 100%;">
                        <p class="caption">Validation Set BLEU Score</p>
                    </div>
                    <p>
                        <br>
                        <ul>
                            <li>Best BLEU-2: 0.3053 (22 epoch)</li>
                            <li>Best BLEU-4: 0.1402 (23 epoch), BLEU-4 기준으로 best model 저장.</li>
                        </ul>

                        <br><br><span style="font-size: 20px;"><b>Validation Set NIST Score History</b></span>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemf8pJeH3LrWcJ_JXm9Olj19aN6F2shqIyNbDZvE9XPNZvbaQI6qj1xYdJ-lG4XMnzzEl2VOYyrFtUCRqLL-FPjcAgbMdrQ3w7IjTWPIy_GuqiQuoMibBviczzlgXxhrUg15MR9LKmobPbZRU4J1Nydfzgi9tObjALH9deOy9Hywdf3njP1RbUo5M6FfN5ND_BurPJcs3FM7edJ2up6Etk28TscIdH6btqMlKiiOxUfC1N3INucJUGrLS1k14lj_fDhsrS8zYDNYKBsQfb5pea6l5DGXVU_ulkC7uaDTHnvxWXYE5SUnJQ_S7hZuHjZgsDqe6uPItn766XHFIBcZMVlhCnxUIPhOp54xZJ0QUoAmtM5MSwJaYjx0SJCvfUJa8m2PBrnOPFjMjQzXHslTv86YkgLPSDF_cc84I_QsJL7QFNu6lu10JonugMM4c6Kya3RsVpyF__uTpvosEHUkaxQOSPgUdrMb6mMaRIj3_b3LIkGyRulmLR9rYY_5IEmDTtT5JqyjiBJfzp2EUw4obk8Qr3Zh_lz2nWJvawHkugV0UdZigZ3FAkCWCCWXfExlGJJTXR55G8if_PIDYrUgWk3KXJ7oSHDbMmnG2Eq_LF57SogbOnF9foxv5huDYbyTt43rSqbOUKa7jYncjbxFBZ8VdfTzhQBn6udcou6Bn99QcxMVFWNprJQuqVfw_DASJX8WJ_aDHC4mP_gHEhdFOTqKa3sFlpaeDiJVK445ucJ5bE622IQvMJzYZh0CVELAxky_D_Fr8eLkEyWH-PAD7pWtc89FWKliNWOpZnQ72n3MRSXjUCQYC77DQasu3P63CDPaLPpppW-SuW4ObABGmZuL1onhTeI8fXB-FZiFzlLmum_7g0IpPPtct85poB4xYEVPa06Nbb4D3LL77YHTbffQJZB2wnimqM2qJUtA3CTfJpfhTRaDeuASOsvNajijcVqU0F-B3vao_wqEbniBAacXyEUaUM3PGaVDEozfvMsOKL-gPv5H5MCMmEHtm3ke6ogtWPJ-beOC1aBOOUqtIWwZoEsmE-GVHRndo1ik4S1ZmOY2Hch1P5OZzHvE6predGao0ox7M4xL5g58XgNZ-RJrL2CARL9hWMWN3MEFJdwpub4Tg97nv-6RBafw0WOkaK-eYdp4lbdA5gRrNDOexBoClWEHZVfPNHgTmLGDi7t3bLak43pdjpOFIvwuHVGHRHfsmjIqxuHYVN7TcKhY96PK6ByFU-70rSULt0xymyh3mq8iqv6eRnXQw50Z9nVTCOisu0Cf8rBCf20p8aBEK9XBn7L0_Px1MYhM2Wxdd6UnRh9UzAixfnvveWXF9GU22xQrf5jwS4W2wg2AxQSM8vMxpFfx_NkQr8hlGxxc_8qo8qWpFaTuIYmUGjh_mRYgsCnVFcRdT06SsLQvSU3xL0wnh74c9s8GLuIjkzhf0HNJEUYRuhcYhE0v7dUSOZA8xJQ2hq1JUxAOlht9cFdOkFU" style="width: 100%;">
                        <p class="caption">Validation Set NIST Score</p>
                    </div>
                    <p>
                        <br>
                        <ul>
                            <li>Best NIST-2: 3.9032 (22 epoch)</li>
                            <li>Best NIST-4: 4.1633 (22 epoch)</li>
                        </ul>

                        <br><br><span style="font-size: 20px;"><b>Validation Set Top-5 Accuracy History</b></span>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemfBV6ulIx-TJBnXm4-Tl1fXP-B8e_cxMz5MY3bhvARjuzAjOv4oknMsCzZKNlICoUAA2lBg11JaCU9QcvolzrBcCCIIMbz6x51OKj_cBKonRCxhfavz2uOK8VfGh56wbZW5cbZMBNDhbMHjwMUfxvCjZHRpPtDkMOH1jfhknSj0zceS2qvTcxQb_VbSPj_92FL-0eAA0l0o22I6KyzRvN7n21MXOQ3gagAeVM-a4d-QGGVefzyZ_Acihh-i1I7GPNO2eK77cPiTbWXF9QzZGjorHxUf2mh4PIR-b2PNcNri_6HuZC8Ooft-HPGvF5_Fe585NXkVupWXT2u3Pf-dIMyWxyHjJ3BV_pJ9i0xmBK8VUtKFDaMWM-10trjEDFXbeY5cT190IybmFoPLkIuM3DB-a8WAkLYgcFh49RVJ1kd81qR9eBvEkYoApJ6cRmRKEj4pJqBYKgY3WWqsbTz2JigF_2fA1NslaqXBGQhPXHPy1VaYRBu1UDjIV1vL57nWUpqRDB6xX_Hn1NLpNVhY_4chziUHx49KH0Gs0_Rj70E16CBTNNTDN9ch9oMKN7vEBWqZ6raRvNb5iyRWaWpSRZMY-OmJVOG-MOmWnjkA7quqkvhN7rZDWTDcIeeni6btx0piHuXcKnw72jmtGZ9FpzzfMdLqQtb7l7GHnYAx7KdJRHT6EawbLCa_5BIe9su_vmmlZFV6rX-U0zltzwZfuyV2VcZhMTSkB89I5f9S08u0ECT0SBruEZKTgH9DgCrgYU_RyOdUB2Xi0c3s9dsHSdr4Q27MXOqg6hriJFm5AHZagxoSt69QPIHUX19gkDUU9uXrxkNOADIbcoTTB6tuGf8X40ttkfWHNdOpxIEX7JiGwYxeIiiQhvhG6yJ9_PNjXRHivAOzmWF4JVf1zo2nZXpZcBPDgx9woQJ9kiF8pJQ97dwE01HfRNHZgos1jHSrpd5QP7VBE8MUKKTwFZGk-hu_LsFi6-G2pMS3FMWIwFf0J3-aRYwybFdQJoptEz-5Yv77-dDs_WrwL0V1a1mVAmhZj41VWUgl4AiwnBQwWRiM5Oo_UkkWdd18z3zi7w3vGBNwKhfWZ6Wx-jSQFOCT9Y3FIjxfCOquhRSV5wYe4YWoF4XwzDVqaZlmNQDgUGVeLAc_MU-YhNMsMjBJ5kbpEEJhbFlFn3Ol84zWrzPh7d19CKI0PuFq6dZPFf4gANVjknXyZ1RJpXlax5H9oU5XUwnhiDeZS7nisjbaXUPkAvqCIGf4Cy9rQ5OIT8n8LY0hWQlmhrkdhGurtRg4re3OTidfYBWgBbrEIO62TWgd2Q4HJJkVlJymgxbCOvElGQsW02i-HC1oM0baZg-zTRgEh9PdZEGckS4eyx2i8q9TV1mjuWjqZTAezO_DY0IehrCwYDHU54JGPL3KyptJ8SNltzrca93qxdWwG4xM4NMKvMxpqVKj97Q2bAOejUcmkjQvgUNiYqLdNjztlZPjYfGec0o" style="width: 100%;">
                        <p class="caption">Validation Set Top-5 Accuracy</p>
                    </div>
                    <p>
                        <br>
                        <ul>
                            <li>Best top-5 accuracy: 73.3850 (16 epoch)</li>
                        </ul>

                        <br><br><span style="font-size: 20px;"><b>생성된 캡션 샘플</b></span>
                        <br><b>샘플 1</b>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemeQeEt5AFaalM9RkOj8_zPEw9XIsMhXe6E4QsDb9HAj9eo6f4DmoF2potyPFw5_XHDuUksAAtVrsi4gYA1VGfyg8vHBHgq27DcrONNs5T_F8ShFBQp0wwvgrO_X9uYkqOET2c9NM758dIZ-0RZQvHjkkeDjC6i2fF02zzxjsnCzW0FHYot4oKeO1KCazecPlbQerxprGk2AQ3CWQ1idlSy50AV9ibK7V2pm_NnhJE7ccTo9uO0Gx6eyc4Ap4cjnv5j_m9hSMoxxjwnsR_nkzM6zObjQmJtiRuzs-dEsbAb72y3JuwesMvISm2-ukNbX_E4CH7KM3icIgaQwLGF5OEmTk0-bGQSSLJTYeMixt3tvihq9V-2jaKTuR-qfAWeTwzrbNT_6nEUgrlxlFVMfzQU9UVadKUspGG2U_KADpn2Npma3WxlPxQwgsAr9Eue2P3HAck83PHrp-TG2-W5wi4kBDekPSWcWkjGihD9nyCrl40tllFhusKGVIBoj-Xe7WlPWvW3fuh8Umk2QvOXeYhi_t4JaQr99DzrxPwRpx6JnW-Bl3Quoon1YnNOZ8rG9pYlcorSNZ05xPpLWkcIY48MkKhju2ZwRcEwcpTgjfnPwU0LHg-lb5Pcn83OLEUgeX0ZJgGVyBWU2Ybwd8azhR0WzhBa44qL0GBZOgQ4svL0OXtrw2Kee611CW3CZpVs191bsXeI25TWoZiDzNe22pkvpbuQ_n0yKi_RNllqufQhNqtHh2U_LYnFlNRArpW9yNJ5qYBHL04G2AK-oJ5Et9erQzewy1zDgHVlgH4P1mY9h7xJN8tu6vKVd_mAboCTg9ZCZJjbbGZt6A9yJItmjip78n1pAddTKY5_HKZ7TFS9R1tZZdxWqmG8YzyCXbt_o-BM9WlhCahWLOkJFrDD75m6fPYtnKiJN-nQat74TeJznXUm15Wq6x_un2IC0TJ_WfrsggQNTsFPxuc3GIuVcutY9yGk_VhCNPqlcVuoM14D7LxjSdZgbAsF1ahwu2VvLXdHko9OGs6_VmYeBtJMmjZC3oO7rbMm7G7W4EqvRptJncCjKW9_uRag8snTNbFEIh5_KBD5xFxIbD7cVltdDjs9Bqc5UWCrxknMMsvNO2s9n9OpiFtXhuhXCSD8EGirwIRoBkvjTMRimHHJgcDvAWKm9TbMS6r24zbFa-QivDka-g9406wsybY1VDhePWYDgkVk6LMZSStXmSrN50CBgTXNB8wSDupeOF2LvTN_qUJ6FVBJrqQb_IgJ1BdAh8i0pX6r-2lWJaChPfuFW2lRuARzWlz-X8TJegonEz1_TZAQlXBuollavA0aLbN3qssFmEmBGneOoscGn5Wazr36SkQNNjHq5y6aENq9g17AYUpWzTQge53rAa25lTz0xeq5F2uXobnyV2SQrNV47VAPB6urrHlSnSEgO6gJWRGmd9rTYgSPgd-J19IATjRNawEpmUM1lRFEShKnIzTx7crMFQCk" style="width: 100%;">
                        <p class="caption">샘플 1 캡션 생성 결과</p>
                    </div>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemc3AjVXrQSWicAzThO9T5zNvSEMwVf19p1s0FYBgQbmcidDi2ZJSGBU__fR9WsQLKfumWkJFPim723WjF8kIv8QxWZriD6qgNJfLMaE6J66biYxtyRZQV79m7whbb04F98eUTq9072kcqhbIweEaRjHnTU8kFXz7PnHbzKM3vFlH4CRkZm9yBhhzIRE5ElRLSA-jax3fsaZYw-RZW2_WXGct7peiDRVLBH4RtKJ090IECjRUUNnjj9VNqdO4I8qt8Rr01VupEk_bEx1x73WlqocvBA2rhhEy2qegI8sgwiRE1dvMllf4ThNT8uQOUTQWVTcOU-BW1GDRCSgsPsIrwYqD_uaeSNWRc-TcKBVPkZqVh3jgloVGfEsAcCZJpYyIi9HLf5jKNyDuybnLBdxypvavANlkVo8rrzvgAdEJWrUsYxm5aeS4ZsORwktv3NPTdMI1CkPn2szzvlCpeyz05SX5gvONG-Gj17FS2rhzyAYWjfmKuzTTCUaCJaPrKCBEEVv13ykMnNacN1NPyU9LjmtzbIsbV9s-DZYoYnrKfFj9LdZ_ysmXlg0Z8iD6NYFwQ0uWapLgppEp1XBGd35XrKJzL3rtbmt420Ps6k5-2x11Lay8OxFUaGhPbGXXFXwc6ECpAjLCRyfOfo4q9e0VeWQJmZ6SaJyiD6zWvZIdrBl5jVDk1WwDCgYTVnVVQ_nRH_tIjegwTJCcl01CXakOxPx-QXJ9h4PalJcbXeNDENnOTWDArBxNbEZBxCdg5e8j8-dktsQhqYS64L9FMlZ77Ro4rX3zscVCyRH9zpcbtMKrhCJSp0k4yjyfktLTQl3FE_nIxaoM3J9sHDRdPyo70DS4emaA9UMr03XKfU0KbzvaUBFOKuYBVsL8ISFdZQL11fiawSzkhLMLULuvEgWwDxXCgBeQB21AtN1LVb-nGLaAHIlv06eCD8-OfsBZx-0ow16h6i_ybMQDnJpBYSiPPZ6EirkwF2z_g1FmtqGTenxyJyg-_vDDpSyj4TNTKisEQBO279WSxULj9MtKaGfphMsItgkVyfgHU8dIkeEEZjN9OurQj4LjMVWFKHsrbqfLD0UL0B8FEyuT0PU6NQOdIXkIPNkMj5i0IywTLbBGwA85PpmIjGiBu1SlHwuaBVljIBFU6eQ5jGwZ_Z8XqBiK2kbX4RNB7XsifwAHMgK8-Tw0MiD_6lhGi5GkK11-d9W6LosXoNL6M5grmVikDvXocoNmJ305-CqsFbt3zHvgmqDYaNVdMbdprMOB8NdwlUr-c4t_DEE6IXbOi1Huv88gWRipu4Obhf-DFd0wZMRPCWjVnXQ1t0j2jrWUKZqZx6z3npE7cW7ty2xhhXw-xVRMnyKSzALlfRxqcexneic3T9Fu1BFD0s2xUPB18EKLOmrpE9S0bidCLpG0dlO38NK8Bz7gLidbiIHiuycGBMjJYI0JlSG7xaqsBjqDa5oP812YRkiMcXKQ2Gf76Sr223QBfk" style="width: 100%;">
                        <p class="caption">샘플 1 attention 결과</p>
                    </div>
                    <p>
                        <br>캡션이 잘 생성 된 것을 확인할 수 있습니다.
                        그리고 boy, rock이란 단어를 생성할 때, 이미지의 적절한 위치에 모델이 attention 하는 것을 확인할 수 있습니다.

                        <br><br><br><b>샘플 2</b>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemcwKmxH4l4EyUD22K2KKAtLJODgxuF0FzNwIAaEkzw9PTpNTDCqb1GXqlgtilv8jkg5j6ALXcYiRAhx8sHSZUNeUop5YfIsMPnAffGiEbliE6qwJtTm4gON2SZtyPmxvg1W643xjnaAqASe0iN1EvSS9dfehHp0Aj_qt5pTAJRG9QWUtuh-7hcMC7iqtgsDRm05Uvmz63Hwm3F66fUP6Uw4pqLLrITZDuheTF-75uA06OwaHG1rGTpk8ZqSRImd_X_3NT8GTKGE1o5K-19PdrCyLBXuHXjFVvHVsYmo9CmKYGVZXzbstFTH1zFtWRzq-QEVrUZ4tpeVFVFPCq3y6patj-mUwa0sY1ym3MiHPBL7DNAd27U0BBby-AMf-8cxpezhQ1_4IZQXEEr3TeQ9ZRXy6O5SqGCIsH0WxfUur7p35CWj8Jn81ot90Wq7pEThhdtMRXUw9rvid_fiIGCE9CcnoQ--XspZtyiDU1brqN-_drLsR4zXc51xUMYOLCrJbcYToifvaSyY0iGGzhXOY_kN5_iTW6UmFdR4ziZCVoaXV47sXHG1js6ol52bMCI5jCL2nBrdHwtf8Fs6H8jzzxtlVZrRQaPWLPP_QnzbJU3RSNWRNlJ_8MW_1RETEqJg2ZD9l37TItRAufdwuYnf7fsu1cPmZGgPqH-cLftGz1Y3M6pe6maMyIYJCV3leBXPoqD14-7d5IZ6WrOaxXx8A72OrgGv4GmyLN7F2nZFJa3XOfE0fFzA1AcMLaF9bDWf4_l1BRbQ7Ek7n41ymtk38NEm1pwsNNNjiQZvA1oH3d0d837h35L1JBO0jc8nfUBMM_enHYMwM50k-Nhn6tlqiiOUfCMqeZmIJK2wK-kXS7MP2Hj_5f_zkeNPJelzr6J0i0uRhPhI4MO3PyKlinv5fbbKp4q9c0-21mvf44SQNy6WTgsLspX1s8ybaJhhMQ8MPXnKK4u2rYBkMB72b32fPTTn9c2TYenFZJEulcZybc2Atev8y5uuuPBVYIQYtu8p0dltbozJFADSQvajaQEXhwqmOL_NfnjZqPgVbPgQRxIV-ClKFusyRS6u8BCcVk3sSP2CIkJdY31A0GgW8VnTE6TCIbFZyxVF5R-iwOAi9dmv2dzogXArRv50WFCi3KPT01ElMA8m4ycKWoeZuwQdO7Gmco-4MzeoHsn4eH37yJGhZIRr2nm2oKgd7cnTh0ZFExHhPTDOajXkBdHHLVcruQvrlI2p8fxQIvCnavLYkGg_NBuX-hluPKo_aD93Zxr-uEYuN0fXvhR9xITungJa7e_TldjW1P2vkvF6roiLSr6ichbm9lCsuqb7jCqmze13SJLELsN_7h4VPLTHKfZHNR4Nx_7cG_zcG7X-T73McfNqU64DKCLvgeOnSbqsHsY7ItZTt0z1JqWu1-XODpHAAVcv3bPChUklkp8szG_vERA41MbPPwOCcIvWKcMOr1-EayO95cjK1GGDFRl7fYV35x0" style="width: 100%;">
                        <p class="caption">샘플 2 캡션 생성 결과</p>
                    </div>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemey0ctJRkiV4mzWgxQjC_hM0piLBd92HgmO4dKwGOGN-PWNJlknke6eylSEzTk5RKhFoticzCIRuAie51WYMFwNX9f4DoRK_ZjnfFzVOjz806qCo9_irEn5_JIM2JnNd3z_k216OQ9bU9B0p8XLnMzTqMes7bAp4w0DPij7OkkEvEljFP0XIXcg1GMgPWYJJVvgDjX19N_rqHB2AJdGdgsQ1DPiVbMj1roPXlgUwyAIpxLTqGAmQ6G1eukeqNB2lpDk6-wiGxG5-G38dkGHYX2G2Igxg7Y9XVE_LXjDe1Slc-vC7xo-c1eyDA39Gh4FgBRrvQDa2NXWaCSknPfu5cUOoMPiibJDdTnkpKOePpfdp4-nFaYeffCwY4pQVILhBqxi_4bMh-tGoOCfKJf5U-RoO-Ag-zer2AS7zvPqhpc4PBtcRVYiTdE-lH9iUSWzSKT-T71sOI0NMK3AICZ79_gTeIO4M6haGggF9rJUNSCZ1pXk3m1Jy4E0Qv-t6yZnpJcA_6dEjBlI5cfSu0Y9F-ezjDJvm_bC5Ax7Z9divktc4k1hyndA2S5BaOrQKC_iBQdZlGgOOEivCyjibflzTBE93DF6xgP6Gr0TvyhDGiGwwvdtA_g2wWH4Kiz6mRzXFfLhiNXGdxb47E3wPo6Gd60uhCCtVsFokjJJoTMS-8KrfEIWbiBwiOcfzaqh7xCDHeUnhQCY9jz9eUvMduVYOK9_NePs8rcqO1-2j7fZ2bAy-ajxJE_kQr8TeDpOpUW43fYZFTKOy16Jfr_p9qP8N7YKAFk8zJ8_NBoi3KjS04DgVChrMFrUyibOc23XuTvg74cVXBtpIn7nJceCwuWi8_WCIpRvRnZutL-nM1cS83x85Fhujk8S7dbBCWcNLh0HXFxL6EzZoMAQD5EeIdoQwOJCx5SOvdYrrX8sn_nVahCdSIsHDhUQuj_pU9kxypR5byHIfs6BnebtoEi9zbZoZYO9HMDXDky0YAhei-4YVxAXqe6LZV-NsXUlOs_LIeACFgwJp82kpeeaM78VJvqyWBcTMhTB6av4gXSVP04k3bDcN6sJ_OdKqwKrQbDTNk8tkM1SLxI_yHjfKHu2uUHXx9or0f4STavIanZJYZq_3Tga0l4Dl5psC7IRQj76BSfVqsYKL6jP6Eu04dDaD3ysg1JuGOKn2aZR4pUOUqgc-GfcsgOsC_Lv5pVY_584QuA_XlLlvmAafbwDwINjDnpWnEO4f2czIitPmYBCjVHXfhVK2SVULXaMkc1R5GNwWAYXwWHR5MLstFnF2DtwLGSvYxxi91XsjjJqS-4vkGswC-ldxWBrgFZm5aOlcSXUePLllc4UiXbiTHZ-UfEJqwDdjwmcb525UDIjSLf5MtFFt4OXiPz9Aprt6VIzkV7feT2r9aR7U7y3zZ6idxdJdA4HfrAXuwfl7rjtrnbtEJh0oEgtFCAI60XKro7MdlYh2WOijRy3BbX4TSSmwmnkSEC3zqE" style="width: 100%;">
                        <p class="caption">샘플 2 attention 결과</p>
                    </div>
                    <p>
                        <br><br><br><b>샘플 3</b>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemeuJFtHWtDbxwht_sdNPtCrd7F-4CXDxo3KShH5qJtgw_wrzE08A7psBKc-yzxXB8v7VcPQtV6R85qVLz8JtkdEl9Bn1zFON23XFxgo3D5TlI23Ojll05YbfxTO1_HgwbV9QgM-GsrNlZns5yOXVMZ0Dw_bS7e_XG167W6ylHSignaf96NkY_lpHwcOYB6ZFYtruuVGWtmz-OQXm_XW3UT22tfkhiSAB5gYKxa1CgWHd2a045K2DeIWDAKWao7Q2zbLjZOIcjpOlGBtE-F1GezMWrjNtilhBC3nQ3g-_2uWWY-Gvn_b-nExoMms-oXRZktpJU8syax9qpZAFPzCjvMDce4Zen6Yt72a9t2Aec0vqVPX5J92nRyEW7_ER0SAkfUOou-y7_R-0PzGUb8_lPk4-VsealtAYrLpNyz4Us6pTfJFoHebITSGOyB36JO8mq9N_8TkPLuLSE5V-6YH37Dn6TKNJcyeuMU1w6u_qG17t7AwID6O7coAHRwliAEZlWptPncGaoxwY4HaNGubugQDoVnWa6UUamDFBPmoZSjo63gIZSSGJp9FS_glH0R4f9udeXEvoRklXG2JWrj2vMl8l6Dz_yU8LutY9b8wwTSc41HRcs_LVYy-OCaTc0VukvQNres66nZkGsfssSavOcpHRcxfm1UX-t6w1Fr5TEcXxOWLa3jEKPw0DaFPyEy20nBuJBqEIbyova_6WU2ECfytV1KfA56RZZ9JMI6TUlHkk1IYpcnjUn7_JS49uscZN4n0gu9NLE39ZIAzv5JRGEA5--FQjl5l3KuABRl1or_EDSzC-ZI1K2lH_wi3SVZkgDmXxRrp9tIEBhtJnHid2zuwkZASAZz8pEaey8_KEbyOqNnSB5lRhSdfWu8ThFdcPAW-x5hjCR5AvnB3d1idXKlnjYvARMSbqzwtqHOktXAEgGEBJ-3Vm-FPT6ZRUvMQCpY_6Bo0DuGXUjJ8E7lFY6jzIICcuYJknRrGZ_YoZSQ4UAsk-p80x4qaFboRW3z7vKhz2ddgUD2qCFADUR8v64cTjsf8euzRn4e8T9i74pV6-zAX56z-hN5kVctYe5G4Ms3aVdaOgI2zhFw9l8Oc1Pf7YUA69gsiRSp8R8S1IFmTdQ3ZTY3wZrtXx4YJyDWB5gpKCdEzTL4W5BoJQ5JuOzhstV7LA3N1PZV8ZG0WD6vmXBEoit14vY6PJzuSpOp3Yywuk7MjiG-bIC0GyaqnOvGAM4F0vS7-Cgjd0gmqaBn_8KRlNol1dMeOdMqYldPV6PT-i1QSeqVYRI1KiBlTgfaoqdf0WKu-JZRBki14kBZux6Qr_gp1__5CBUl9Tx2N1zxvlNsjLrt5sfmbLmmcYM1c7fWiOONHp-MRPvQHerUTrQFhvH1dbyLJLdlWY54HTGn-2mXQBheILOLFK9S2IjCiHr6yQ-10r4spcVAv8zQu3WW94UT68bzFsfSyocgF2lodnt3vqnDY0uO-3eMD4sQ" style="width: 100%;">
                        <p class="caption">샘플 3 캡션 생성 결과</p>
                    </div>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemfkLu7b5FKD9CKgzAh61-Ailk0AenW2d3Ii9iZe2eZzQyRK8is5owORY2GmdbIVQUpubTgy2f__AMHncSq0jgh2xAicKVoUVP0xCmrrkOJBE9qNJcvUlhqv5M8W_ErPcAMzphFjB3UCmy4cGm9HJ0p-VziEt_ADJKnTMTKEfefn12saRm_ho_-89KEo_ataB3vdO7yyPjEi5avOnUw5FIsk4NB-IXLzs3sAeWuMKfGEEiAUnBedKiPqZ4k6wyLYAWRpovZryZ8olpwKxWJWRxGir2_8f84I-3_aFhY9JFgIoAlofrtZs7JmFv8Yjts-GCaCIxpgDRKTA5i-GerQCiue-HtHezSY3Y8YUeWbwNAgfmlUgjDDI71-DlzUQH3L6V3AXret3zzLUhfDt6rqFhAFEGQiwewGZa1doibmCFz29iPjKMSTNdoJfJKFTptwUHz7CERWf71nmNh8kFzEJVosBdtZqaxy-ti0dFKNAr8jErf2Sgumeywjp3U1i4FmQ53ijrGbKc37bZXrIT8c_mV-GSqnXeVrv7IpisF-3FFjglM38JC0J7aMHC1rhbSszmZiQeGN9Gph_VTvOuoFJwyBz6kgBEi9FZNRNXkccQNVaIGK2cQ9PlPxaKzFIjUF5VJrx_vvXMc6pNPu_jNga9usu7n6nbNWphYbptZz6YIwSpU9cdPPwIIUjx04Ufv-9u6AU1vAe2FghekFxbBpjV3_zgDogyWXZsebraZF-jLbsCj3Aufpf_xjqgWnHaIZeyzzCWe2e8q9GLQNnMZoB3sBLS7S-ff2rAMBPt8v1r26Ra1e7b6oYFtfwWbZOr59Ol6ePRkDKhQ7Y5Z9mSVmJ2AOK-6fT8GZSirIUB_ESfWcH2Evv1wmJXfaCtLn0d_eNAnfACZriEt7QMRuau0_0SVsbZa_hvtq4YOgPNzpszpL7V5QJadZsaDs6GeYcPI-igSrotxLuF6pmR2guzQTINfoNhY_ixMPcLYqMFUqKxDoROy9JNr48m6jJTL1ZJ4qtuQWDF2X4zZ4wX0T5NFi7QObNO4nHht2qIwRny1w4xpas8VEdNZ3Wh-0IbCDMGj9zvTA39xHzHg0SjkMJpJCl8Owa-UV4G8u-geRgfj_QCVgQrM45i2Q1YfJ4Sf_daQdH3P0JdyC-vjqNIlDm_J_5YQuhyP9TaDZGr_3-dMpjmSU3zBYEDTaSwhxHE8LXEhTV3bopm52B3aHa09ZipGJ7wC9tO25_QQLe7SrGY9G-EaKK8I_JllHFpm2X2M-ywIv551fYSLL9lRmsev7uSfCLdb5A5U4hE3dcQd3wHneGoLV88RbhRexhm3HslcnuO9Gph-Qn1s1cn6nHrJT6f_cGylSmwuMpkHy60cC-zTB6FC5XUr08b7kYENlGTg6v8sqNONUXnXiIJJdwwPF7UNTXqhXAGzzf4HCPngk4-EDOQNepVoVq4ssiXF9s-QobVBWCqLNHrrh_RKD9H1aRSTt364" style="width: 100%;">
                        <p class="caption">샘플 3 attention 결과</p>
                    </div>
                    <p>
                        <br>샘플 3 또한 girl, hair, wind 등의 단어를 생성할 때, 이미지의 적절한 위치에 모델이 attention 하는 것을 확인할 수 있습니다.

                        <br><br><br><b>샘플 4</b>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSeme626hQ3vwaItnb76pEln2SNK2muk4SgKixLqBdz9rwNp9AeDLTHvyHjUzWmT9zQTF15_aQo0LMtYeQHaRksn-OBlQ7IAtS0du95E6zI9RnbG-qo8aIsspb2FGuOHAxN5ZOkMLooxG8y7zGrzvwGEAswo4JH9Onp-R3s7cWE2XqjEuQXeQYwJ7urBEHVRddEe8abq2JSc4kQzGzGMIMVqRUU5GqxbvqmR9sTnqmKY-1mw2FR0DAL5wkkO877gNpC_UwD3-kzejug3V246fg2diLjZXVd4UgKli4mTEJumSgLmY3NbRvkWtv4R7AfbOEgaQziUTrjvBDKMeXyWe7QChYprYPX3J33hR9MSdg-bASMJt6Z37TXUAm9lT1c0qPpbTNMgm5yv7QidLmH_aPCeEk8VBrUQ81kmqE8uFXernC9gX8KXJfRHp_smihWDvmq0qdq4GwgU125x5yGlNcJmoV46D-jjQLB42v9NJtli1L_u1D6LV_X29TelkmupmJQx3_udgI9IyGcfwSyqdnOxAyy8MlQ5guiiMynFkX9rnzARq77Fy5TeIZoCg4wit0jNLWsPgQ1sI7xGaKsxb-1FItOdojj8tdlOG5gltscQdRUUF0KDGUTCsfYquc1I-jhX-GNHUDsrighm1Oiqj3uyWlzN_LIktGtwVZh2hgX-zV1EvO2LUw9JjFfyliFqdCJh2HPsoSZQTU4Luo_6yPckJCLhYFpyAhsohWkjr1z4TK8rao6XICh5lwMXVLGRi9ncn5VaM2BV7scDkHhyFKfGeIK6IhKlBh3-L4uJ9FGaHR8zk2E2k_XR7_HjBx1aKJPsUL6jDQVTFOSfdgvwuGFKaMUxYx6k1SpUc4LHaTimUb7kmVGVHtg9qaZGlzJMqdlN5QpQ-WNziMnI5INgLKC9ClEAqdUQE3Ap8kQxAUI2Hb2F4a2Y2yzYG68meqi7a96rVVz8x1BGcttYI6grTnOnvPsE4W3JaZQ_4v8sxtXfnu7NonnyWZiwb_rx-jc6HBBToemt-VEtZyO4uFSSADdtF-gpJwbQVr8iDncog-jxk6PcDjjwifPgk_T6LAemoGmiLAncaEk5P_fLhZl_43YhwKxgjwCvoXB5FXu2_smnIt3kkiQNEh52od_k6NSuFU9-5Ec9vEncw61eM8J7ELWnjNGy0P6sYRjGxJrRwMhQw4GT6vuP4bNmUnxoVCvk9VNhOeC2RaYAnSNZJLTfr7X2mhALc0PvEdx2xxSVn1rJiFGHCwkCOm9UwIWp9R-L8jbOsuOioPWiDsitQsgdMYZCvIHpRJlbo6v44aoYCJ7U7IvrnTUslc_vN7HplO5jG1-zIog6bRXCtrgOvgXbaqdZdtmj7Mal5i217j5B1FF3lrXMz0hrWp-VwOn4joAFfhLkhba-nByS94_Vh2IQYPRoMG4r_zmrqL2HhN1-mpjmfEC2iO900iLQqd0uV78rVt2FEdTZT2DFavQU0V4rQG4Aw" style="width: 100%;">
                        <p class="caption">샘플 4 캡션 생성 결과</p>
                    </div>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemdmipiFDImlGPlXy-2z8OUD-5aQYqCDB2bHV1TbRoyhKsbq9VdU6-Ggjpind3kAEV3AZHpm-F8W1gCfZjJohIJMuXo72hyPyo3xh8_MxjFlFqTGns1GMVR85J-l08rc6FOSgle_jGhWKTvMceJxZFQaEt2Z1p7gmffcv1rkdX_jjfqGrlelw4q2o58kVn6PZsQ4u0OZGrZqKdHa8hf-0NGYkneJEZLf4Zg5AG3TwK2ZfbISQy0tLtnODcKZO9GVZAnt8nVOybNOqXfjwt2dWeU995_7M0pty-_UmRkrcGoKwDDaTQhjK5VG9ZAxWvjKWWF3vJ8hgHO5TK6EjVb5JyPUy0qEQzkKqPEQSxP2REmxDhVpS-zzLPD31-MZR4NXaBiaYcNX-JtvrwMkgzd_dXxwIHYZvSPDNSf8rF3FWkI7vivh1W6y_jSTr5f5mRDbpBheim3v_ofNAqGlLcKwKJPb3aWpxo5m4HcRr7-9s63Gbhycueel-MUmgyY4p4UVtbdXm47lWtfnuLmzX04ayV8OA9_e_qkAGE0Y6aCrLN72q8kyXxEknyAIQ6436WkU2f5IfJ3CW5fczA80gnxLUxw3BsSA_A3kj42FpGVd9bzfAr8nm6bj4v38rcXv9FnSBtIarQgzgDvQzZYJViZAahzKtyc3LXI0vPbXRb5tGoSvzbFwfY1jHr1aZFwP1nKHF2SCesRDoH3q9jX8lvDnT92bYKUNwt6QcleSbza8s_nAk7JhCzqGRFw6ZYQZnlodQh9me9geff_0znwOtvrLEFaZAQAfvQzh-5UvqMSo0zuLFI0r5uA0v3PZqATOGmPg3S9YgC0sG3J2g4lRef1ggvQHfku48FNS9eHjFd83jLAIEh9vhYxaMQL7oa_VFCg4CpDk-uePw9UGKLQ03ZZZcC1mHyU1Az9PLmykwIBaaBw_t8uebpcT59zrPtmXQLHFxijCGWCsXvF5gYNa1Gi7sNRDP0ol6nKpJIzZE1BxSWgbuHXc8OgrelpOUveGSzFcpWMDsOdMPYboB6G9soqu9CHST5TXEDMC8HXQb8fI_3YIBhvWSNmheEbgRAu1AF65-CZ1YCGcdYQEo_LYE6wKV3QDmaGo1LEv2LXTUB7iqDcTU5cBt5Up48D5j4Uu0tPfpzVJpv4bTvx89p_jEa9Vj69l2rKi8IuneqXT4FA-F-Vqot4DxehQoDcFNqtVWYb3UaEic6BaOx4UZr-QjScF3mJrkN96rsTVtGspEOpn4BMPASZ_4eEQxTDe9YuyNrhWVX-LbfdNPvkv7wVzRg1MSVjVxBNu6u_3rcLLWrHmea_lbCwHq9pyTl2d_8_ntO3CG1qOzzvI-fGkYEfJDZnl2ShB0e3pOLA-gNvx5WU3nzoaRTk3eTaypj0ARRElmvI1mfbEwuhVdv9PRIiE02IoFO8Csq_yT-Pk_oR_5VrbBhUoDSOWjLd4kmdSU5M-IPGKEmGrGin8OxyQXfXQF5KGaHk" style="width: 100%;">
                        <p class="caption">샘플 4 attention 결과</p>
                    </div>
                    <p>
                        <br><br><br><b>샘플 5</b>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemdnnM_fzftSfsyOVGIQbLrEg2BPFiCzZoZ3nZk1X6oxaKVZtOIdOrJOuv_-zty3P_XJ4BTGsolcAwyppCCfHKb6O_E8AEB_oBAESKOSoMEMU1mZCSEgjvyZF2kOxmSYD5l2TUkRIqHshTpWZxIb6YSxin5ylm_tHolkGOFjdJyiiCDyJMhKjSy6qq3UhyTnBdmOPWsKNk9Kyv1Dv4sX5zSYAsp-6qNvAHT7tgyPByYDbyidLR7oJ7FyilJMJiwKkoLTY5jArXVPfVEpUKBKeHthwPsHtbwUjKu6Ccuqp2nIF-1cM11gdFWRevV5fwxAAaL3-dHOGgGVxTTtEc8018DvJOTe3Y2x_hdZbqdsTCmRnapq6yYf_IRkYbx5B1GX5RsHY4N31x3J54iZj0DI5YbgL92AxPKqbkbzOakQk86t10hG-yFqEIxHxY271CQXKFBPOSHFADn3fSFXZpf0HSwB4B0XDOdwbnfDo1cTSvQXa6gmrn0ObOjqqGDl5qhUepwEJX7rFCQsYpXO2VHVUrOUy4uOm1sE_yEG5El7-PXqHwQPtFnnardEgh3LH6fJb7g_yWlXaF57oCz9_l0hM7w1BssdppS0Jhr5h_E32rxOqeyUm2sGPLzBt5-0mq9YulM38-JJIJM8vAovWBGofB2sk3LONJkaZWuQ1WSqfEnvmL_pTMIFPPwV6NUE9XKjrAlx9374U6TY4SGI82h5Kg6pPHZhCfJTp5eCO8sErzklDeRcoTsUNUUs-MlYBYkdnXj7d2gkLUBBpusAzGsrU70L8emxnak5pF5iqi1E2BFiQiTjb2NGIg-NcZQutQZP5_qbt1uLaC5mN7H7Z8ZxCkb4102LHafUAtLd1CnzaL2s6WE3I1jEV_337CAnHvPLOOBxGNHIKn7i0-S-TXtcPUMp2Aky5AGzBbLNZvxuV4zmUx_ipblt7_3wKElabmhrhUkDEgbKb5v-PNC8He1rM9zSSZ3gwRRR1LjDCIA65fQDhQOBKcp277aVFB2cTfbq4stIMYPsMAiDI38yfVcr2CEciQZjxW8Pcg84P_DDx2cdY_7ND5tA9xVjDuX1kPaDgaj9XpObYbL_Y-nbLblHVNJuHWs3Cn0Y8tzfYiYmtza9bbcm68trsC1zcUZOEFENgZyV2R7IshCTq5B4AX4A53-uteHoFE2paN3uY6bJGERBTN8Hl38_1tB3UZPpDFitWzk8lm-RA5KkhsKPtpdhCA3s0NV7aaOj2DhQSh9pfSKRxGyUxgCwd-VlkaMMN7IbX0KKzh9n87eSBkviufpgIlT8vs2KEkEzdYW-HCulHmLYwkOgS0hxaOp63r0fjG5Z06JR14SpUh07cOKDYzC8C3FPgC02X1WqTvlW4YGA55J2i5YHuawYnRXfwdUQZb7EY77_6sYxtfzitWAndctVUFUwXfMbhspHcgiYGGO2OSFyrr4O26-sXR4a_C7MhJv7_cz99gWiP46hqXnEk4QSMNk" style="width: 100%;">
                        <p class="caption">샘플 5 캡션 생성 결과</p>
                    </div>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/AMPSemecCFttT_ywQY0GHOwLmpR2L07e7UFkrCVOEX4RoWSC3SgrgzEG5HccKEERmy1LuBn2VMyWdRI-IQK0HamWMuDiCufUyGozI0DPCRlnijxXx7M6VvNlK1Kb86lI_o4IYbwSrpMrUOGvYoCtg8eJB-s0F_C4Y0J2ioESYqQnWUKDqzkI4oxzxYEcQmeCXMiGqE0H9G0uZ5UoO3Xjk6wPXP71VHD0TDPRQJdufPitNp1a9VhDBSvBEO2hzhc_lGod6r5ZVN9I4iC-gMewymLR9e5WWG3Gh1MxmAESbIH7cJT_SGUw8NDyUVkgx5wTs1wlQ1vkla3lsqfuv5TRhDja4oIsxlv_X_mGY1EETdlz5H3DxSgDA4CjDfkHMezQuYDGdutbPbzTjyJH6McVT17axT014ZJx5ot5Db305ZjyCh7rXTieeu9Iwv9FUDdyfj8dHke0odMDzS1UuXx3XZWC__oOugaCT28E3r90_raVu06u-Ka8XotiNWXcZs2A0tQPvIWmqwLc6C6fzsFxOEEUVZVxxYYUtzoZ4YI1X5Zjaad_62ryEREHKanQ8hIVYPDD6Nk__QmsAoxVZbFFACVMTalxu2dYVCy6ScxltC9Qw_P1HxP7BP26knARIhBDGMHU28kD_Liz1gRNJ3mLZT9dDdVRJq02hdO2RWF0xBlI5kN_bNOxvJcqXFJTI3td8Z0xrUNjPCnjTtBmS__dGj5csP1BBl7NNWcYZBDU2umZNCSFI7JE6411q_-NEa8J7O7Le_HN6xmswOaqIbTLdUY4PPUSsL8z9LBEK9mYz9Pu1ZaFdomuAnWxXfervN1GXMg3CZ1QuV2NBQ7Gt9fNDwN0RBxMnXFiMcRp3_7nuD1SEhyhFph9qAXs0N1sIFWoRSdEYo6pNrR_Qzy3rpCC08YWCotqytMNu2mnXgTG8YmBsTYE6lSnPMbbC2XYcd3GALWa13uCHh31rZlCqjp2hVEloI6dkM-ZcG2BIfDW7aeIUIAf_ZowWj6gp-imUyC6H9XxJkZ-E3FuL3sAEOF-fuoiBx8oN4QQR11qKEsNzKZ_-bqltqDvzkukqy_RfSumxJJ38u2Wb1U6sMBMay0Ay_F-sq0XqxO3OfN_A1JkGAAcEQdV34kemeMcfnSP8jr8AY4uVQAvKlKFP3aW5KAOQHOdldu6SB7XPL78IgNyzfNZKex38eAqzg-P9RbGOl2187sNpBc0ovtMrEJtvFS0yr8_erb_x8fzYHXGcyuCKgWkv2sea6PNQZNhhSsib0YSSKGvl7QBXbwmcsigbYAPhtsanaNAL-QECa1U2B5mbYp1CkawWiWsL7ehl083jgeJ7Tpzryb_6oL-CHmNl-s-icgCbFumNKbt_AHYYZj4m5cM5ZWGqqe8M81PjRnYoHtdr8GV4BhUBEGUuqU1uj9Im73QZlZ5d2kspELXfKLMVuZ_dCGjQwfDGzfB7_FUIXcl3mS-ZW8m9cbeACN10BPFBZZWojI" style="width: 100%;">
                        <p class="caption">샘플 5 attention 결과</p>
                    </div>
                    <p>
                        <br>위에서 샘플 5개의 결과를 살펴보았습니다. 전반적으로 켑션이 잘 생성되고, 단어를 생성할 때 이미지의 적절한 위치에 attention을 하는 것을 확인할 수 있었습니다.
                    
                        <br><br>지금까지 ResNet과 LSTM을 이용하여 Flickr8k 데이터를 이용하여 image captioning 모델을 제작해보았습니다.
                        학습 과정에 대한 전체 코드는 <a href="https://github.com/ljm565/image-captioning-show-attend-and-tell" target="_blank"><span class="highlight" style="color: rgb(0, 3, 206);">GitHub</span></a>에 있으니 참고하시면 될 것 같습니다.
                    </p>


                </div> 
                <div class="tag">
                    <b>태그</b>&emsp;#ResNet&emsp;#LSTM&emsp;#ImageCaptioning&emsp;#Flickr8k
                </div>
                <div class="pageTurner">
                    <div class="pageTurnerLeft">
                        <span><a style="position: absolute; left: 0;" onclick="pjaxPage('img2txt1.html');" onmouseover="colorOn(this);" onmouseout="colorOff(this);">&lang; 이전글</a>
                        <br>Image Captioning (Show, Attend and Tell)</span>
                    </div>
                    <div class="pageTurnerRight">
                        <span><a style="position: absolute; right: 0;" onclick="alert('Image Captioning 마지막 게시물 입니다.\n\nThis is the last post of Image Captioning.');" onmouseover="colorOn(this);" onmouseout="colorOff(this);">다음글 &rang;</a>
                        <br></span>
                    </div>
                </div>
                <span id="readNum"></span>
                <div id="disqus_thread"></div>

                <script>
                    headHighlightColorChanger();
                    (function() { // DON'T EDIT BELOW THIS LINE
                    var d = document, s = d.createElement('script');
                    s.src = 'https://novicetraveler.disqus.com/embed.js';
                    s.setAttribute('data-timestamp', +new Date());
                    (d.head || d.body).appendChild(s);
                    })(); 
                </script>
                <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </article>
        </div>

        <div id="menuRelated">
            <div class="menuButton">
                <img id="menuImg" src="init/index_img/menu_black.png" onclick="openMenu(this);">
            </div>
            <div class="menu">
                <img id="menuExtension" title="메뉴를 확장합니다." src="init/index_img/extension_black.png" onclick="extendMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
            <div class="bigMenu">
                <img id="menuCompression" title="메뉴를 축소합니다." src="init/index_img/compression_black.png" onclick="compressMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
        </div>

        <script>
            detectScroll();
            pushFunc();
            detectSize();
        </script>
    </body>
</html>