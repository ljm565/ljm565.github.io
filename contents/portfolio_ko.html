<!DOCTYPE html>
<html>
    <head>
        <title>Portfolio</title>
        <meta name="description" content="포트폴리오">
        <meta charset="utf-8">
        <link rel="stylesheet" href="init/index.css">
        <link rel="stylesheet" href="init/contents.css">
        <link rel="stylesheet" href="init/index_img/icons/css/fontello.css">

        <link rel="preconnect" href="https://fonts.googleapis.com"> 
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> 
        <link href="https://fonts.googleapis.com/css2?family=Dongle:wght@300&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Gowun+Batang&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic&display=swap" rel="stylesheet">

        <link rel="stylesheet"
            href="init/highlight/styles/github-dark.min.css">
        <script src="init/highlight/highlight.min.js"></script>
        <script>hljs.highlightAll();</script>
        <script src="init/highlight/highlights_line.js"></script>
        <script>initNumber(window, document);</script>
        <script>hljs.initLineNumbersOnLoad();</script>

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        <script src="init/index.js"></script>
        <script src="init/jquery.pjax.js"></script>

        <meta name="viewport" content="width=device-width, initial-scale=0.8, max-width=1">

        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-219110982-1"></script>
        <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-219110982-1');
        </script>
        <!-- <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7745178886614102"
        crossorigin="anonymous"></script> -->

        <meta property="og:url" content="https://ljm565.github.io/contents/portfolio_ko.html" />
        <meta property="og:title" content="포트폴리오" />
        <meta property="og:type" content="website">
        <meta property="og:description" content="포트폴리오" />
        <meta property="og:image" content="" />
    </head>   
    <body>
        <div id="modeButton">
            <button type="button" value="dark" onclick="darkMode(this)" onmouseover="hoveringOn(this)" onmouseout="hoveringOff(this)">
                <div class="modeImg"><img id="modeImg" src="init/index_img/moon_off.png"></div>
                <div id="modeState">다크 모드로 보기</div>
            </button>
        </div>

        <div id="container" onclick="reload();">
            <article>
                <script src="init/highlight/highlight.min.js"></script>
                <script>hljs.highlightAll();</script>
                <script src="init/highlight/highlights_line.js"></script>
                <script>initNumber(window, document);</script>
                <script>hljs.initLineNumbersOnLoad();</script>        
                <div id="mainHeadWrapper">
                </div>
                
                <div id="content">
                    <div class="portfolio_name">
                        <span><b>Jun-Min Lee</b></span>
                    </div>
                    <br><br>
                    <div class="portfolio_intro">
                        <img src="init/index_img/profile3.png" style="width:25%; float: right; margin-left: 60px; padding-top: 40px; padding-bottom: 30px;">
                        <p style="padding-top: 40px;">
                            저는 인공지능을 통해 세상을 더 나은 곳으로 만들고 싶은 인공지능 개발자입니다.
                            인공지능은 생명을 구하고, 업무 효율을 높이는 등 다양한 방면에서 큰 역할을 할 수 있다고 믿습니다.
                            처음 인공지능을 공부하기 시작했을 때만 해도 이런 미래를 상상하지 못했지만, 이제는 LLM과 MLLM 같은 기술의 발전으로 인간만이 할 수 있었던 많은 일들을 인공지능이 척척 해내고 있습니다.
                            제가 꿈꾸던 인공지능의 이상향에 한 걸음 더 다가간 것 같아 매우 기쁩니다.
                            이러한 이유로 자연스럽게 LLM에 관심을 갖게 되었고, 현재 LLM을 다루고 공부하는 중입니다.
                            세상을 더 이롭게 하는 인공지능 연구원 및 엔지니어가 되기 위해 다양한 경험을 쌓으며 꾸준히 노력하고 있습니다.
                        </p>
                    </div>
                    
                    <div class="portfolio_about">
                        <p style="border-bottom: solid rgb(199, 199, 199) 1.5px;">
                            <span style="font-size: 20px;"><b>Skills</b></span>
                        </p>
                        <ul>
                            <li><b>Programming Language</b>: Python, Java (Spring)</li>
                            <li><b>Tools</b>: FastAPI, PyTorch, PyTorch Lightning, LLM Training &amp; Serving (Triton-client, TensorRT-LLM, TensorRT-LLM Backend, vLLM, ollama), PEFT, RAG, Docker, Git, Elasticsearch, GCP</li>
                            <li><b>Environment Preferences</b>: Linux, Mac</li>
                            <li><b>Others</b>: PostgreSQL, HTML, CSS, JavaScript</li>
                        </ul>
                    </div>
                    <div class="portfolio_contact">
                        <p style="border-bottom: solid rgb(199, 199, 199) 1.5px;">
                            <span style="font-size: 20px;"><b>Contact</b></span>
                        </p>
                        <ul>
                            <li><b>Mail</b>: ljm56897@gmail.com</li>
                            <li><b>GitHub</b>: <a href="https://github.com/ljm565" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);">https://github.com/ljm565</a></li>
                            <li><b>Blog</b>: <a href="https://ljm565.github.io" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);">https://ljm565.github.io</a></li>
                            <li><b>CV</b>: <a href="init/cv.pdf" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);">[PDF file]</a></li>
                        </ul>
                    </div>
                    <div class="portfolio_researchArea">
                        <p style="border-bottom: solid rgb(199, 199, 199) 1.5px;">
                            <span style="font-size: 20px;"><b>Research Area</b></span>
                        </p>
                        <ul>
                            <li>Healthcare</li>
                            <li>Natural language processing</li>
                            <li>Document Understanding</li>
                            <li>LLM, MLLM tuning and serving, PEFT</li>
                        </ul>
                    </div>
                    <div class="portfolio_education">
                        <p style="border-bottom: solid rgb(199, 199, 199) 1.5px;">
                            <span style="font-size: 20px;"><b>Education</b></span>
                        </p>
                        <ul>
                            <li>Ph.D. in KAIST Graduate School of AI, 2021 ~ present</li>
                            <li>M.S. in KAIST Aerospace Engineering, 2019 ~ 2021</li>
                            <li>B.S. in Aerospace Engineering in KAIST, 2015 ~ 2019</li>
                        </ul>
                    </div>
                    <div class="portfolio_work">
                        <p style="border-bottom: solid rgb(199, 199, 199) 1.5px;">
                            <span style="font-size: 20px;"><b>Work</b></span>
                        </p>
                        <ul>
                            <li>Kakao Healthcare, 2024.10. - 2025.04. (DS/IX, 대학원생 인턴)</li>
                            <ul>
                                <li>의료 NER(개체명 인식)에 특화된 LLM을 PEFT와 전체 학습 방식 모두로 학습시켰으며, vLLM을 사용해 여러 의료 전문 기관에 모델을 배포함.</li>
                                <li>RAG(Retrieval-Augmented Generation)을 통합하여 정확하고 문맥을 반영한 건강 상담을 제공하는 GCP 기반 헬스케어 상담 챗봇을 구축함.</li>
                            </ul>
                            <li>Lomin, 2023.04. - 2024.09. (ML team, 전문연구요원 병역특례)</li>
                            <ul>
                                <li>문서 이해 과제를 위한 문서 특화 LLM을 학습하고, TensorRT-LLM 및 TensorRT-LLM Backend를 활용해 엔터프라이즈 온프레미스 환경에 최적화된 추론 형태로 배포함.</li>
                                <li>텍스트 검출, 인식, 분류 등을 포함한 다양한 딥러닝 모델을 BentoML과 Triton client를 활용해 여러 기업의 온프레미스 환경에 배포함.</li>
                                <li>문서 이미지에 특화된 텍스트 검출 모델의 성능, 속도, 견고성을 향상시키기 위해 YOLOv8을 커스터마이징함.</li>
                                <li>특정 태스크에 대한 파인튜닝 없이도 미지의 문서 유형에 일반화할 수 있는 문서 임베딩 모델을 개발하여 zero-shot 문서 분류 시스템을 구축함.</li>
                                <li>기존의 2단계 OCR 방식에서 벗어나 텍스트 검출과 인식을 통합한 엔드투엔드 파이프라인을 설계 및 구현하여 운영 효율성을 높임.</li>
                                <li>브라우저 내에서 실시간 처방전 인식이 가능한 경량 Autoscan 모델을 개발하고, 서버 측 연산 없이 다양한 약국에서 사용할 수 있도록 TensorFlow.js로 배포함.</li>
                            </ul>
                            <li>IBRICKS, 2021.09. - 2023.04. (AI Tech, 전문연구요원 병역특례)</li>
                            <ul>
                                <li>Java로 개발된 문서 분석 제품을 유지 보수하고 신규 기능을 추가하여 안정성과 기능성을 지속적으로 개선함.</li>
                                <li>GPT-2, DialoGPT, BART 등의 모델을 활용하여 LLM 등장 이전에 오픈 도메인 챗봇 시스템을 설계하고 구현함.</li>
                                <li>긴 문서에서 핵심 문장을 식별하고 추출하여 간결하고 적절한 요약을 생성하는 BERT 기반 추출 요약 모델을 구축함.</li>
                                <li>전통적인 sequence-to-sequence 구조를 shared encoder-decoder 모델로 대체하여 모델 크기와 복잡도를 줄이고 성능을 유지하면서 효율성을 향상시킴.</li>
                                <li>LLM 등장 이전에 설계된 텍스트 데이터 증강을 위한 임베딩 공간 기반 비지도 GAN 모델인 TESGAN(Text Embedding Space GAN)을 개발함.</li>
                                <li>온라인 홈쇼핑 광고 이미지에서 텍스트를 추출하는 데 특화된 OCR 모델을 개발함.</li>
                            </ul>
                        </ul>
                    </div>
                    <div class="portfolio_researchContrib">
                        <p style="border-bottom: solid rgb(199, 199, 199) 1.5px;">
                            <span style="font-size: 20px;"><b>Research Contribution</b></span>
                        </p>
                        <ul>
                            <li>2025 PC Member, Association for the Advancement of Artificial Intelligence (AAAI)</li>
                            <li>2023, 2024 PC Member, Association for the Advancement of Artificial Intelligence (AAAI)</li>
                            <li>2023 Industry Track Committee, Empirical Methods in Natural Language Processing (EMNLP)</li>
                            <li>2023 PC Member, Empirical Methods in Natural Language Processing (EMNLP)</li>
                            <li>2023 PC Member, Association for Computational Linguistics (ACL)</li>
                        </ul>
                    </div>
                    <div class="portfolio_publication">
                        <p style="border-bottom: solid rgb(199, 199, 199) 1.5px;">
                            <span style="font-size: 20px;"><b>Publication</b></span>
                        </p>
                        <ul>
                            <li>[P8] Geun Hyeong Lee*, <b>Jun-Min Lee</b>*, Kihoon Sung, Ji Young Min, Jae Won Jang, Eun Jin Ahn, Yun Ah Baek, Hyun Jung Kim, Ji Yeon Park, Min Young An, Yu Ri Cho, Hye Yeong Kim, Dosang Cho, Choongki Kim, Hong Seok Park, Kyung-Jae Lee, Joo Heung Yoon, Hyo Jung Kim, and Soo-Yong Shin (2025), Large Language Model-based Named Entity Recognition for Unstructured Clinical Test Reports: Multi-centre Implementation and Validation, <i>Preprint</i> (*: equal contribution). (under review)</li>
                            <li>[P7] <b>Jun-Min Lee</b>, Meong Hi Son, and Edward Choi (2026), H-AdminSim: A Multi-Agent Simulator for Realistic Hospital Administrative Workflows with FHIR Integration, <i>Preprint</i>. <a href="https://arxiv.org/abs/2602.05407" target="_blank">[pdf]</a></li>
                            <li>[C2] Jiyoung Lee*, Seungho Kim*, Jieun Han, <b>Jun-Min Lee</b>, Kitaek Kim, Alice Oh, and Edward Choi (2025), Trans-EnV: A Framework for Evaluating the Linguistic Robustness of LLMs Against English Varieties, <i>Conference on Neural Information Processing System (NeurIPS)</i> (*: equal contribution). <a href="https://arxiv.org/abs/2505.20875" target="_blank">[pdf]</a></li>
                            <li>[P6] <b>Jun-Min Lee</b> and Tae-Bin Ha (2023), Unsupervised Text Embedding Space Generation Using Generative Adversarial Networks for Text Synthesis, <i>Northern European Journal of Language Technology (NEJLT), 9(1)</i>. <a href="https://arxiv.org/abs/2306.17181" target="_blank">[pdf]</a></li>
                            <li>[P5] <b>Jun-Min Lee</b>*, Hyun-Soo Kim*, Tae-Bin Ha, Hojin Park, and Youngmin Ahn (2021), Open-Domain Dialogue Generation using Pre-trained Language Models in Korean, <i>Conference of Korea Computer Congress (KCC)</i> (*: equal contribution). <a href="https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11113420" target="_blank">[pdf]</a></li>
                            <li>[P4] <b>Jun-Min Lee</b>, Yunshil Choi, and Jung-Ryul Lee (2022), Laser structural training, artificial intelligence-based acoustic emission localization and structural noise signal distinguishment in a thick FCEV fuel tank, <i>International Journal of Hydrogen Energy (IJHE), 47(6), 4236-4254</i>. <a href="https://www.sciencedirect.com/science/article/abs/pii/S036031992104372X" target="_blank">[pdf]</a></li>
                            <li>[P3] <b>Jun-Min Lee</b>, and Jung-Ryul Lee (2021). Acoustic emission localization on composite hydrogen storage tank and feature analysis of acoustic emission and noise signals. <i>Conference of The Korean Society for Aeronautical and Space Sciences (KSAS)</i>. <a href="https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE10613500" target="_blank">[pdf]</a></li>
                            <li>[C1] Yunshil Choi, <b>Jun-Min Lee</b> and Jung-Ryul Lee (2020), Nondestructive Testing and Structural Health Monitoring for Pressure Vessels of FCEV using Guided-Wave Ultrasonic Propagation Imager, <i>Conference of The Korean Society for Composite Materials (KSCM)</i>.</li>
                            <li>[P2] <b>Jun-Min Lee</b>, Yunshil Choi, and Jung-Ryul Lee (2020), Structural Health Monitoring of Hydrogen Pressure Vessel using Artificial Intelligence, <i>Conference of The Korean Society for Nondestructive Testing (KSNT)</i> (<b>Award</b>).</li>
                            <li>[P1] <b>Jun-Min Lee</b>, Yunshil Choi, and Jung-Ryul Lee (2019), Acoustic Emission Simulation using Pulse Laser-induced Wave with Considering Arrival Time for Quantification, <i>The 1st Korea-China-Japan Joint Symposium on Composite Materials</i>.</li>
                        </ul>
                    </div>
                    <div class="portfolio_project">
                        <p style="border-bottom: solid rgb(199, 199, 199) 1.5px;">
                            <span style="font-size: 20px;"><b>Work Projects</b></span>
                        </p>
                        <ul>
                            <li><span style="font-size: 18px;"><b>LLM Training &amp; Serving (2023.12 ~ 2024.09)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: 채팅과 문서 이해를 위해 LLM을 훈련합니다. 이 과정에서 다양한 학습 방법론과 LoRA, DoRA, MoRa와 같은 최신 PEFT 기법을 포함한 최신 LLM 모델을 사용합니다. 또한 이러한 모델들에 대해 성능 실험을 수행합니다. 훈련된 모델을 온프라미스 환경에서 서빙하기 위해 TensorRT-LLM, TensorRTLLM-Backend, vLLM, Ollama 등의 도구를 사용합니다.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 100%</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, PyTorch, TensorRT-LLM, TensorRTLLM-Backend, vLLM, ollama, Deepspeed</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>AMP, deepspeed 등을 이용한 LLM의 Full-parameter tuning.</li>
                                    <li>최신의 PEFT 적용 및 테스트.</li>
                                    <li>TensorRT-LLM, TensorRTLLM-Backend, vLLM, ollam를 이용한 LLM 모델 변환 및 서빙.</li>
                                </ul>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>BentoML &amp; Triton Serving (2023.08 ~ 2024.09)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: On-premises 사업에 제품을 서빙하기 위해 BentoML과 Triton inference server를 사용합니다. 그리고 지속적으로 모델의 성능 개선과 고객의 요구를 들어주기 위해서 유지보수를 수행합니다.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 5개의 사업을 맡았으며, 3개는 현재까지도 진행 중입니다.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>:Python, BentoML, Triton Client, Trition Inference Server</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>BentoML 서빙.</li>
                                    <li>Trition inference server 서빙.</li>
                                </ul>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>Document Detection Model Enhancement (2023.11 ~ 2024.09)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: 본 프로젝트는 문서 탐지 모델의 성능 개선을 위해 시작되었습니다. 문서 탐지 모델을 경량화하여 속도를 개선하고 성능을 높이기 위해 커스텀 모델을 제작했습니다. 뿐만 아니라 다양한 class로 분류하여 예측할 수 있도록 모델을 개선하여 도입하였습니다.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 100%</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, PyTorch</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>기존 모델 대비 속도 개선.</li>
                                    <li>기존 모델 대비 성능 개선.</li>
                                    <li>ONNX, TensorRT 등 다양한 모델 타입으로 변환 가능하도록 지원.</li>
                                </ul>
                            </ul><br>
                            <!-- <li><span style="font-size: 18px;"><b>Lina (2024.01 ~ present)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>MRAS (2024.03 ~ present)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>보건연구원 (2023.11 ~ present)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>Jeekim (2023.09 ~ present)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                            </ul><br> -->
                            <li><span style="font-size: 18px;"><b>Zero-shot Document Classifier (2023.06 ~ 2023.12)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: 이 프로젝트는 매 사업마다 문서분류를 수행하는데 그 때 마다 각각의 문서에 대해 학습해야하는 수고로움을 줄이기 위해 시작되었으며, 이 프로젝트를 리드했습니다.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 70% (Two individuals involved)</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, PyTorch</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>모델 학습.</li>
                                    <li>개발한 모델의 정량 평가(Contribution: 40%).</li>
                                </ul>
                            </ul><br>
                            <!-- <li><span style="font-size: 18px;"><b>Hanwha Aerospace (2023.08 ~ 2023.09)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: It was a project to extract table data from English documents. We developed an end-to-end model that takes document images and outputs table data.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 30% (Two individuals involved)</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, PyTorch</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>Trained model (20%).</li>
                                    <li>Post-processing of model results (Contribution: 80%)</li>
                                </ul>
                            </ul><br> -->
                            <li><span style="font-size: 18px;"><b>End-to-end Document OCR Model Development (2023.06 ~ 2023.11)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: 문서 OCR을 위한 모델은 detection, recognition의 2단계로 나누어집니다. 이는 서로의 모델이 dependent하여 유지보수가 어렵고 학습의 불안정을 야기합니다. 이를 극복하기 위해 end-to-end로 문서의 텍스트와 그 텍스트의 bounding box까지 예측할 수 있는 모델을 개발하였습니다. 그리고 detection, recognition의 대표적인 모델들과 개발한 모델의 각각의 단계에서의 정량적인 성능을 비교하였습니다.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 65% (Three individuals involved) </li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, PyTorch</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>End-to-end 문서 OCR 모델 개발(Contribution: 50%)</li>
                                    <li>유명한 baseline 모델들과 개발한 모델과의 정량 평가(Contribution: 60%).</li>
                                    <li>Technical report 작성.</li>
                                </ul>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>Autoscan Model Serving (2023.04 ~ 2023.05)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: 오토스캔은 문서가 카메라 스캐너에 들어오면 자동으로 사진을 촬영하는 기술입니다. 이를 위해 문서 삽입 여부를 판단하는 모델이 필요하며, 이 모델은 프론트엔드에서 가벼운 성능으로 동작해야 합니다. 저는 ResNet을 수정하여 경량 모델을 학습하고, 이 PyTorch 모델을 TensorFlow.js로 변환하여 JavaScript에서 WebGL을 이용해 서빙할 수 있도록 했습니다.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 100%</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, JavaScript, PyTorch, Tensorflow.js, WebGL</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>5,000건 이상의 문서 이미지 수집 및 실제 스캔 환경과 유사하도록 만드는 augmentation logic 개발.</li>
                                    <li>PyTorch custom 모델 제작, 학습 및 Tensorflow.js로 변환.</li>
                                    <li>False Negative 보다 False Positive가 나타나지 않도록 하는 것이 더 중요했기에, JavaScript에 스캔 여부 판단하는 smoothing logic 개발.</li>
                                </ul>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>KEIT Text Analytic, Classifier, Clustering (2022.03 ~ 2023.04)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: Java로 구축된 문서 분석 제품을 유지보수하고, 문서 임베딩 모델의 성능을 개선했습니다.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 35 ~ 45% (이 프로젝트는 회사 제품을 유지보수하는 상시 업무였습니다. 이 업무는 3 ~ 4명에서 유지보수를 수행했으며, 아래는 그중 제가 참여했던 개발 목록입니다).</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Java (Spring), Postman, Apache JMeter, FastText</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>문서 임베딩 모델의 성능을 개선, 이를 텍스트 클라우드 프로젝트를 통해 평가 검증.</li>
                                    <li>FastText를 통한 문서 분류 handler를 구현(Contribution: 80%).</li>
                                    <li>Java Spring을 이용하여 API 통신 구현 작업 및  Postman으로 테스트 수행(Contribution: 20%).</li>
                                    <li>여러 요청에 대해 node별 로 분산처리가 가능한 서버 개발(Contribution: 45%).</li>
                                    <li>Apache JMeter를 이용한 서버 부하 테스트(Contribution: 30%).</li>
                                    <li>K-medoid 모델 학습을 통한 카테고리별 텍스트 클라우드 구성(Contribution: 50%).</li>
                                </ul>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>Open-domain Chat System Modeling (2022.03 ~ 2023.04)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: 이 프로젝트는 비식별화된 한국어 데이터를 사용하여 일상 대화 챗봇 모델을 구축하는 것이었습니다. 생성형 모델로는 DialoGPT, GPT-2, BART를 베이스라인으로 사용했으며, 저는 DialoGPT와 KoGPT 모델의 학습을 담당했습니다. 또한, CLIP 모델에서 영감을 받아 순차적인 텍스트 임베딩을 활용한 Text-CLIP 모델을 개발하였으며, 이 모델은 이전 문장을 기반으로 데이터베이스에서 적절한 응답을 검색합니다.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 75% (Two individuals involved).</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, PyTorch, Hugging Face, Uvicorn, Websocket, FastAPI</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>DialoGPT와 KoGPT 기반의 생성형 챗봇 구축.</li>
                                    <li>개발한 생성형 챗봇 모델을 공공기관에 시연, 공공기관에서 제공한 챗 로그 데이터를 추가로 수집하여 프로젝트를 진행(Contribution: 50%).</li>
                                    <li>Text-clip 모델을 개발하여 데이터베이스에서 적절한 응답을 제공하는 챗봇 구축.</li>
                                    <li>Uvicorn과 Websocket을 이용하여 FastAPI를 비동기 방식으로 구성하여 여러 챗봇 모델이 동시에 실시간으로 문장을 생성할 수 있도록 토큰 스트리밍을 구현.</li>
                                    <li>데이터를 '해요체'로 변환하기 위해 형태소 분석을 수행, 이를 챗봇 학습에 사용(Contribution: 50%).</li>
                                </ul>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>Document Extractive Summarization (2022.06 ~ 2022.08)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: 공기관의 요청으로 수행한 프로젝트입니다. 문서 추출 요약을 위해 모델을 학습하였으며, 실험을 위해 KoBERT, Sentence BERT (SBERT)를 baseline으로 삼았습니다. 이중 KoBERT를 통해 추출 요약 하는 모델을 제작하였습니다. 하나의 문서는 문장의 양이 매우 많기 때문에 sentence n-grams 기법을 도입하여 해결하였습니다.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 50% (Two individuals involved)</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, PyTorch, Hugging Face</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>KoBERT 기반 추출 요약 모델 개발.</li>
                                    <li>내용이 많은 문서 요약을 위한 n-grams 기반의 추출 알고리즘 개발.</li>
                                </ul>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>Language Model Lightweighting (2022.06 ~ 2022.12)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: Open-domain chat 모델 개발을 수행하면서 학습 자원 효율성 증대와 다양한 auxiliary task 확장성 증대를 위해 언어 모델 경량화를 수행하였습니다. 기존 범용적으로 쓰이던 seq2seq 기반의 모델을 encoder와 decoder가 weight를 공유하도록 하여 모델을 경량화 하였습니다. 또한 모델의 마스크만을 변경하여 다양한 task를 수행할 수 있도록 제작하였습니다. 이렇게 나온 모델은 text-text, image-text 등 multi-modal에 대응이 용이했으며 기존 모델 대비 semantic task에서 월등한 성능을 보였습니다.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 98% (Two individuals involved)</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, PyTorch</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>커스텀 모델 구현 및 학습.</li>
                                    <li>학습한 모델의 정량 및 정성 평가.</li>
                                </ul>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>Text Augmentation using GAN (2022.01 ~ 2022.12)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: LLM이 등장하지 않았을 당시 text data 증강을 위해 모델을 개발했습니다. 당시 텍스트 증강 기법은 supervised learning에 의거한 autoregressive로 문장을 생성하는 방식이었습니다. 이 방법은 훈련 데이터를 생성하는 data memorization이 발생했습니다. 따라서 이러한 문제점을 해결하고자 비지도 방식의 GAN 기법을 도입하여 text embedding space를 비지도 방식으로 학습하여 문장으로 변환하는 모델을 개발하였습니다.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 95% (Two individuals involved)</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, PyTorch</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Paper</span>: <a href="https://arxiv.org/abs/2306.17181" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);">https://arxiv.org/abs/2306.17181</a></li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>아이디어 증명을 위한 모델 개발 및 학습.</li>
                                    <li>논문 작성.</li>
                                </ul>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>Online Commercial Advertisement OCR (2021.09 ~ 2021.12)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: AI Hub와 같은 공개된 한국어 text-in-wild 및 공공문서 OCR 데이터를 바탕으로 학습한 모델의 온라인 광고 OCR 성능을 평가하고, 학습된 모델의 결과를 Tesseract, ABBYY 등 대표적인 OCR 서비스와 성능을 비교했던 프로젝트입니다.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 100%</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Python, OpenCV, PyTorch, Tesseract</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Performance</span></li>
                                <ul>
                                    <li>OpenCV를 이용하여 text-in-wild &amp; 문서 OCR 데이터 가공.</li>
                                    <li>CRAFT와 transformer 기반의 OCR 모델 훈련 및 평가.</li>
                                    <li>상업 OCR 플랫폼 성능 평가.</li>
                                </ul>
                            </ul><br>
                            <li><span style="font-size: 18px;"><b>Document Inverted Indexing (2021.09 ~ 2021.09)</b></span></li>
                            <ul>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Description</span>: 문서의 단어 빈도수, 사전 순서를 고려하여 역색인 프로그램을 만들었습니다. 30만건 문서 기준 3초 이내로 역색인 생성이 가능하도록 StringBuffer를 이용하여 구현하였습니다.</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Contribution</span>: 100%</li>
                                <li><span class="highlight" style="color: rgb(0, 3, 206);">Tech Stacks</span>: Java</li>
                            </ul>
                        </ul>
                    </div>
                    <div class="portfolio_individual_project">
                        <p style="border-bottom: solid rgb(199, 199, 199) 1.5px;">
                            <span style="font-size: 20px;"><b>Individual Projects</b></span>
                        </p>
                        <span>* 더 자세한 내용은 <a href="https://github.com/ljm565" target="_blank"><span class="highlight" style="color: rgb(0, 3, 206);">GitHub</span></a>을 참고해주세요.</span>
                        <ul>
                            <li><b>UnivLT</b> <a href="https://github.com/ljm565/UnivLT" target="_blank">[GitHub]</a></li>
                            <ul>
                                <li>오픈소스 LLM을 손쉽게 파인튜닝할 수 있는 모듈형 학습 프레임워크. Instruction tuning, 전체 파인튜닝, LoRA, QLoRA를 지원하며, DDP, FSDP, gradient checkpointing 등의 학습 전략을 제공함. 간단한 모델 래퍼 통합만으로 자가회귀(pretraining) 방식의 사전학습 및 SFT 기반 instruction tuning이 가능함.</li>
                                <li>Tools Used: Python, PyTorch</li>
                            </ul>
                            <li><b>PatientSim-pkg</b> <a href="https://pypi.org/project/patientsim/" target="_blank">[PyPI]</a> <a href="https://github.com/ljm565/patientsim-pkg" target="_blank">[GitHub]</a></li>
                            <ul>
                                <li>환자 페르소나를 설정하고, 구축된 환자 에이전트를 기반으로 응급실 및 외래 진료 시나리오에서 시뮬레이션을 실행할 수 있도록 해주는 패키지 프로젝트.</li>
                                <li>Tools Used: Python, Poetry</li>
                            </ul>
                            <li><b>H-AdminSim</b> <a href="https://pypi.org/project/h-adminsim/" target="_blank">[PyPI]</a> <a href="https://github.com/ljm565/H-AdminSim" target="_blank">[GitHub]</a></li>
                            <ul>
                                <li>H-AdminSim은 다중 병원 환경과 FHIR 연동 환경에서 환자 접수 및 진료 예약 업무를 대상으로 LLM 기반 병원 행정 에이전트를 평가하기 위한 시뮬레이션 프레임워크.</li>
                                <li>Tools Used: Python, Poetry</li>
                            </ul>
                        </ul>
                    </div>
                </div>

                <script>
                    headHighlightColorChanger();
                </script> 
            </article>
        </div>

        <div id="menuRelated">
            <div class="menuButton">
                <img id="menuImg" src="init/index_img/menu_black.png" onclick="openMenu(this);">
            </div>
            <div class="menu">
                <img id="menuExtension" title="메뉴를 확장합니다." src="init/index_img/extension_black.png" onclick="extendMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
            <div class="bigMenu">
                <img id="menuCompression" title="메뉴를 축소합니다." src="init/index_img/compression_black.png" onclick="compressMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
        </div>

        <script>
            detectScroll();
            pushFunc();
            detectSize();
        </script>
    </body>
</html>