<!DOCTYPE html>
<html>
    <head>
        <title>LSTM을 이용한 IMDb 영화 리뷰 감성 분류</title>
        <meta name="description" content="LSTM과 attention 메커니즘을 바탕으로 감성 분류 모델을 제작합니다.">
        <meta charset="utf-8">
        <link rel="stylesheet" href="init/index.css">
        <link rel="stylesheet" href="init/contents.css">
        <link rel="stylesheet" href="init/index_img/icons/css/fontello.css">

        <link rel="preconnect" href="https://fonts.googleapis.com"> 
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> 
        <link href="https://fonts.googleapis.com/css2?family=Dongle:wght@300&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Gowun+Batang&display=swap" rel="stylesheet">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic&display=swap" rel="stylesheet">

        <link rel="stylesheet"
            href="init/highlight/styles/github-dark.min.css">
        <script src="init/highlight/highlight.min.js"></script>
        <script>hljs.highlightAll();</script>
        <script src="init/highlight/highlights_line.js"></script>
        <script>initNumber(window, document);</script>
        <script>hljs.initLineNumbersOnLoad();</script>

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        <script src="init/index.js"></script>
        <script src="init/jquery.pjax.js"></script>
        
        <meta name="viewport" content="width=device-width, initial-scale=0.8, max-width=1">

        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-219110982-1"></script>
        <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-219110982-1');
        </script>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7745178886614102"
        crossorigin="anonymous"></script>

        <meta property="og:url" content="https://ljm565.github.io/contents/RNN3.html" />
        <meta property="og:title" content="LSTM을 이용한 IMDb 영화 리뷰 감성 분류" />
        <meta property="og:type" content="website">
        <meta property="og:description" content="LSTM과 attention 메커니즘을 바탕으로 감성 분류 모델을 제작합니다." />
        <meta property="og:image" content="https://lh3.googleusercontent.com/fife/ALs6j_FYLru0Hh0-ucPQKqBvcSxPJHpa4W70SPDy1OfCMIahhcnemkcV_27h-faRZ9ZNarvwEMuSqDdFmYTVIdpSAOK7F5SstsGuSQycBZuyh9cPLP586G4fORl00-rP0jWkHuHSk0N-tIjwnYzgoz89eQ1hswj0iWxph6A9S3HKqrGKROOIhNSD_QIxaoZDhVrJpx9Q8xuJ0JyFvEVZEHcYjUbt1zHDO-9R7N5_dH5nP2MOrunCFrZtPEERwj0cEoLR44P7f1fvGvit-CUEvSgFgzUWReZdcQj43dldyHAkNOohu-2gOG1J-BTRnP0Wn9Q8LHNZJT_c8gFd3yHrLjMU3eSz3bnMaoUzIZUlPygrb8tA1l_r7tAVSwJ5OeWseVX-BUy6j5DrxdOVgthb-2KzeCsRM6M6zGEJRKeQvQImliwtvTnenEUqjFkwq25_Cn-kEncmvkBymvpgQa40aWDAZ-xqvYL0X8jWQ6N_MsMtRqYBpR9IQZ7g9dtMylY8EtDIR4ITQkMjk21ZNcz2c6R5-8_vb9TcW3SDExR4KlLwfr9woUwIEkzL1xwEc30B6tcPPmu9Ls8PY6DwLwWb9WErlx-Qs5HOYG-HrLlc0adpiub09gED_lHhZOae5ETJ92KDupBCPStV0Gt4iJ3C795oOOwzcT4tGzarPUX_-MIWACi7bPuLtFKzhTIOrUUrdDwOpW5anUr0ssAT6_YzT6Iag4YB7_q8abUIyoco31M8JFny0HB6iOL2ugUkmnZGJrNUokIhrnjpv_jcAgMfeNUPlwVkANwJcKacFXhHznNdpWfps0fx7bZ92lbXi6Lzbe4sJVhpna3fNgmNRSK8kwfDzG91crehjM6uv7RmQ0vDZg_yAxXkR0HaUHPc34c45tBvvJkuYI4ZCNaqHnYYEs4KiZ9K5AHrT9PnOcUJ3XgmMcPbMGoU_tLh8UbWbhDvfgB8K6OX4Mjp3FYEkSId5RUt--L1tT7eLRnEAbV9gnz0Ryez1IGr9T4VUn43NFbDsJQ94iBv_IrQg7S41z4UXIr1rarvanJZUC3VqseKhaN-clL_22yP6A_6Yo3bSufiSE5O4-MnYQMiFLAkeask-Tt07rHWkDwZ0ZmpyJftFWyKRXieVE6ke1o1XQoLX7gV_NTMBDFs6KFIwb3R8qGoLdaWvgYBTn0NKDnBJeLmscAInlGJfHHp4732bpSC7OcGP8laop7WqbRhDJ9qAA9fOd14v9gicGVbrajmTLMNmNbciJxNESm915mqbTrKwF2RAShkFeW8um26F7gMQVPIyqhhEB1dvrQ88dHhxf7MaHra78BuaEyAJ3zHKr2VasvDNxC0ygaYwy17rtK8La7ndPbz1AHPHP15t98YKOZK6EB_lRBTlRbYZ-ZQ3IyvFwuguQbekjO4g1gBcBLEdh5kkzgA5WaESkwWhfTKBvHOwpC1kZV7ZgTyFW8XQY5DUAn6H3Gl_g-sjwaT1N_J2gzyWAiecTTrTt5-l3cM4Nz4WHI3d1Y08dqVKhWEFtnDD5qLqdS_LyKZaJJZ6idH" />
    </head>   
    <body>
        <div id="modeButton">
            <button type="button" value="dark" onclick="darkMode(this)" onmouseover="hoveringOn(this)" onmouseout="hoveringOff(this)">
                <div class="modeImg"><img id="modeImg" src="init/index_img/moon_off.png"></div>
                <div id="modeState">다크 모드로 보기</div>
            </button>
        </div>

        <div id="container" onclick="reload();">
            <article>
                <script src="init/highlight/highlight.min.js"></script>
                <script>hljs.highlightAll();</script>
                <script src="init/highlight/highlights_line.js"></script>
                <script>initNumber(window, document);</script>
                <script>hljs.initLineNumbersOnLoad();</script>
                <script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
                <script>
                    initMathJax();
                </script>
                <div id="mainHeadWrapper">
                    <div id="mainHead">
                        <h1 class="contentHead">딥러닝 이야기 / Recurrent Neural Network (RNN) / 3. LSTM을 이용한 IMDb 영화 리뷰 감성 분류</h1>
                    </div>
                </div>
                
                <div class="title" style="background-image:url(https://lh3.googleusercontent.com/fife/ALs6j_FYLru0Hh0-ucPQKqBvcSxPJHpa4W70SPDy1OfCMIahhcnemkcV_27h-faRZ9ZNarvwEMuSqDdFmYTVIdpSAOK7F5SstsGuSQycBZuyh9cPLP586G4fORl00-rP0jWkHuHSk0N-tIjwnYzgoz89eQ1hswj0iWxph6A9S3HKqrGKROOIhNSD_QIxaoZDhVrJpx9Q8xuJ0JyFvEVZEHcYjUbt1zHDO-9R7N5_dH5nP2MOrunCFrZtPEERwj0cEoLR44P7f1fvGvit-CUEvSgFgzUWReZdcQj43dldyHAkNOohu-2gOG1J-BTRnP0Wn9Q8LHNZJT_c8gFd3yHrLjMU3eSz3bnMaoUzIZUlPygrb8tA1l_r7tAVSwJ5OeWseVX-BUy6j5DrxdOVgthb-2KzeCsRM6M6zGEJRKeQvQImliwtvTnenEUqjFkwq25_Cn-kEncmvkBymvpgQa40aWDAZ-xqvYL0X8jWQ6N_MsMtRqYBpR9IQZ7g9dtMylY8EtDIR4ITQkMjk21ZNcz2c6R5-8_vb9TcW3SDExR4KlLwfr9woUwIEkzL1xwEc30B6tcPPmu9Ls8PY6DwLwWb9WErlx-Qs5HOYG-HrLlc0adpiub09gED_lHhZOae5ETJ92KDupBCPStV0Gt4iJ3C795oOOwzcT4tGzarPUX_-MIWACi7bPuLtFKzhTIOrUUrdDwOpW5anUr0ssAT6_YzT6Iag4YB7_q8abUIyoco31M8JFny0HB6iOL2ugUkmnZGJrNUokIhrnjpv_jcAgMfeNUPlwVkANwJcKacFXhHznNdpWfps0fx7bZ92lbXi6Lzbe4sJVhpna3fNgmNRSK8kwfDzG91crehjM6uv7RmQ0vDZg_yAxXkR0HaUHPc34c45tBvvJkuYI4ZCNaqHnYYEs4KiZ9K5AHrT9PnOcUJ3XgmMcPbMGoU_tLh8UbWbhDvfgB8K6OX4Mjp3FYEkSId5RUt--L1tT7eLRnEAbV9gnz0Ryez1IGr9T4VUn43NFbDsJQ94iBv_IrQg7S41z4UXIr1rarvanJZUC3VqseKhaN-clL_22yP6A_6Yo3bSufiSE5O4-MnYQMiFLAkeask-Tt07rHWkDwZ0ZmpyJftFWyKRXieVE6ke1o1XQoLX7gV_NTMBDFs6KFIwb3R8qGoLdaWvgYBTn0NKDnBJeLmscAInlGJfHHp4732bpSC7OcGP8laop7WqbRhDJ9qAA9fOd14v9gicGVbrajmTLMNmNbciJxNESm915mqbTrKwF2RAShkFeW8um26F7gMQVPIyqhhEB1dvrQ88dHhxf7MaHra78BuaEyAJ3zHKr2VasvDNxC0ygaYwy17rtK8La7ndPbz1AHPHP15t98YKOZK6EB_lRBTlRbYZ-ZQ3IyvFwuguQbekjO4g1gBcBLEdh5kkzgA5WaESkwWhfTKBvHOwpC1kZV7ZgTyFW8XQY5DUAn6H3Gl_g-sjwaT1N_J2gzyWAiecTTrTt5-l3cM4Nz4WHI3d1Y08dqVKhWEFtnDD5qLqdS_LyKZaJJZ6idH);">
                    <div>
                        <span class="mainTitle">LSTM을 이용한 IMDb 영화 리뷰 감성 분류</span>
                        <br><br>
                        <div style="display: table-cell; margin: 0;">
                            <img src="init/index_img/profile.png" style="width: 30px; cursor: pointer;" onclick="pjaxPage('/');">
                        </div>
                        <span class="subTitle" style="display: table-cell; text-align: left; vertical-align: middle; padding-left: 20px; line-height: 125%;">작성자: 여행 초짜<br>작성일: 2022.09.02</span>
                    </div>
                </div>

                <div id="content">
                    <p>
                        시작하기 앞서 틀린 부분이 있을 수 있으니, 틀린 부분이 있다면 지적해주시면 감사하겠습니다.
                        
                        <br><br>이전글에서는 sequence-to-sequence (seq2seq) 모델과 attention 메커니즘 예시를 몇 가지 살펴보았습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">이번글에서는 LSTM 모델을 이용하여 영화리뷰 데이터인 IMDb를 가지고 긍부정을 분류해주는 감성 분류 모델을 학습하고, attention mechanism을 적용 해보겠습니다.
                        구현은 python의 PyTorch를 이용하였습니다. 그리고 모델을 학습하면서 training set과 validation set의 loss와 accuracy 변화 뿐 아니라 attention score, 실제 긍부정 결과 샘플도 살펴보겠습니다.</span>

                        <br><br>그리고 seq2seq 모델과 attention에 대한 설명은 <a onclick="pjaxPage('RNN2.html');"><span class="highlight" style="color: rgb(0, 3, 206);">이전글</span></a>을 참고하시기 바랍니다.
                        그리고 학습을 위한 코드는 GitHub에 올려놓았으니 아래 링크를 참고하시기 바랍니다(본 글에서는 모델의 구현에 초점을 맞추고 있기 때문에, 데이터 전처리 및 학습을 위한 전체 코드는 아래 GitHub 링크를 참고하시기 바랍니다).

                        <br><br>그리고 텍스트를 토큰화 하기 위해 사용한 토크나이저는 word tokenizer를 구현하여 사용하였습니다.
                        물론 현재는 unknown 토큰 문제를 해결하기 위해 <a onclick="pjaxPage('word2vec1.html');"><span class="highlight" style="color: rgb(0, 3, 206);">Word2Vec 글</span></a>에서 설명한 byte-pair-encoding (BPE) 같이 subword 기반의 토크나이저가 많이 사용되지만, <span class="highlight" style="color: rgb(0, 3, 206);">본 글에서는 attention 모델이 결과를 예측하기 위해 어떠한 단어에 집중을 했는지 그 score를 보기 위해서 단어 기반의 토크나이저를 선택하였습니다.</span>
                        
                        <br><br>오늘의 컨텐츠입니다.
                        <ol>
                            <li>LSTM 감성 분류 모델</li>
                            <li>Attention 모듈</li>
                            <li>감성 분류 모델 학습</li>
                            <li>감성 분류 모델 학습 결과</li>
                        </ol>
                    </p>
                    <div class="link">
                        <a href="https://github.com/ljm565/sentiment-classification-LSTM" target="_blank" onmouseover="colorOn(this);" onmouseout="colorOff(this);">Attention을 이용한 LSTM 감성 분류 모델 GitHub 코드</a>
                    </div>


                    <h1 class="subHead">Attention을 이용한 LSTM 감성 분류 모델</h1>
                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center;">&ldquo;</span>
                        <span>LSTM 감성 분류 모델</span><br>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        여기서는 감성 분류를 위한 LSTM 코드를 살펴보겠습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">코드는 PyTorch로 작성 되었으며, 문장 데이터를 input을 받아서 0, 1 사이의 값으로 내어주는 모델을 구성합니다.</span>
                    </p>

<pre><code class="python"><span class="reserved">class</span> <span class="clazz">SentimentLSTM</span>(<span class="clazz">nn</span>.<span class="clazz">Module</span>):
    <span class="reserved">def</span> <span class="method">__init__</span>(<span class="var">self</span>, <span class="var">config</span>, <span class="var">pad_token_id</span>, <span class="var">device</span>):
        <span class="clazz">super</span>(<span class="clazz">SentimentLSTM</span>, self).<span class="method">__init__</span>()
        <span class="var">self</span>.<span class="var">pad_token_id</span> = <span class="var">pad_token_id</span>
        <span class="var">self</span>.<span class="var">device</span> = <span class="var">device</span>
        <span class="var">self</span>.<span class="var">is_attn</span> = <span class="var">config</span>.is_attn
        <span class="var">self</span>.<span class="var">hidden_size</span> = <span class="var">config</span>.hidden_size
        <span class="var">self</span>.<span class="var">vocab_size</span> = <span class="var">config</span>.vocab_size
        <span class="var">self</span>.<span class="var">num_layers</span> = <span class="var">config</span>.num_layers
        <span class="var">self</span>.<span class="var">dropout</span> = <span class="var">config</span>.dropout

        <span class="var">self</span>.<span class="var">embedding</span> = <span class="clazz">nn</span>.<span class="clazz">Embedding</span>(<span class="var">self</span>.<span class="var">vocab_size</span>, <span class="var">self</span>.<span class="var">hidden_size</span>, <span class="var">padding_idx</span>=<span class="var">self</span>.<span class="var">pad_token_id</span>)
        <span class="var">self</span>.<span class="var">lstm</span> = <span class="clazz">nn</span>.<span class="clazz">LSTM</span>(<span class="var">input_size</span>=<span class="var">self</span>.<span class="var">hidden_size</span>,
                            <span class="var">hidden_size</span>=<span class="var">self</span>.<span class="var">hidden_size</span>,
                            <span class="var">num_layers</span>=<span class="var">self</span>.<span class="var">num_layers</span>,
                            <span class="var">batch_first</span>=<span class="reserved">True</span>,
                            <span class="var">dropout</span>=<span class="var">self</span>.<span class="var">dropout</span>,
                            <span class="var">bidirectional</span>=<span class="reserved">True</span>)
        <span class="return">if</span> <span class="var">self</span>.<span class="var">is_attn</span>:
            <span class="var">self</span>.<span class="var">attention</span> = <span class="clazz">Attention</span>(<span class="var">self</span>.<span class="var">hidden_size</span>*<span class="num">2</span>)
        <span class="var">self</span>.<span class="var">fc</span> = <span class="clazz">nn</span>.<span class="clazz">Sequential</span>(
            <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="var">self</span>.<span class="var">hidden_size</span>*<span class="num">2</span>, <span class="num">1</span>),
            <span class="clazz">nn</span>.<span class="clazz">Sigmoid</span>()
        )
        <span class="var">self</span>.<span class="var">relu</span> = <span class="clazz">nn</span>.<span class="clazz">ReLU</span>()



    <span class="reserved">def</span> <span class="method">init_hidden</span>(<span class="var">self</span>):
        <span class="var">h0</span> = <span class="clazz">torch</span>.<span class="method">zeros</span>(<span class="var">self</span>.<span class="var">num_layers</span>*<span class="num">2</span>, <span class="var">self</span>.<span class="var">batch_size</span>, <span class="var">self</span>.<span class="var">hidden_size</span>).<span class="method">to</span>(<span class="var">self</span>.<span class="var">device</span>)
        <span class="var">c0</span> = <span class="clazz">torch</span>.<span class="method">zeros</span>(<span class="var">self</span>.<span class="var">num_layers</span>*<span class="num">2</span>, <span class="var">self</span>.<span class="var">batch_size</span>, <span class="var">self</span>.<span class="var">hidden_size</span>).<span class="method">to</span>(<span class="var">self</span>.<span class="var">device</span>)
        <span class="return">return</span> <span class="var">h0</span>, <span class="var">c0</span>


    <span class="reserved">def</span> <span class="method">forward</span>(<span class="var">self</span>, <span class="var">x</span>):
        <span class="var">self</span>.<span class="var">batch_size</span> = <span class="var">x</span>.size(<span class="num">0</span>)
        <span class="var">attn_output</span> = <span class="reserved">None</span>
        <span class="var">h0</span>, <span class="var">c0</span> = <span class="var">self</span>.<span class="method">init_hidden</span>()

        <span class="var">x</span> = <span class="var">self</span>.<span class="var">embedding</span>(<span class="var">x</span>)
        <span class="var">x</span>, <span class="var">_</span> = <span class="var">self</span>.<span class="var">lstm</span>(<span class="var">x</span>, (<span class="var">h0</span>, <span class="var">c0</span>))
        <span class="return">if</span> <span class="var">self</span>.<span class="var">is_attn</span>:
            <span class="var">attn_output</span> = <span class="var">self</span>.<span class="var">attention</span>(<span class="var">self</span>.<span class="var">relu</span>(<span class="var">x</span>))
            <span class="var">x</span> = <span class="var">x</span> * <span class="var">attn_output</span>.unsqueeze(<span class="num">-1</span>)
        <span class="var">x</span> = <span class="clazz">torch</span>.<span class="method">sum</span>(<span class="var">x</span>, <span class="var">dim</span>=<span class="num">1</span>)
        <span class="var">x</span> = <span class="var">self</span>.<span class="var">fc</span>(<span class="var">x</span>)

        <span class="return">return</span> <span class="var">x</span>.squeeze(<span class="num">1</span>), <span class="var">attn_output</span>
</code></pre>
                    <p>
                        <span style="font-size: 20px;"><b>LSTM</b></span>
                        <br>위 코드에서 나오는 config 부분은 <a href="https://github.com/ljm565/sentiment-classification-LSTM" target="_blank"><span class="highlight" style="color: rgb(0, 3, 206);">GitHub 코드</span></a>에 보면 <span class="var">config</span>.json이라는 파일에 존재하는 변수 값들을 모델에 적용하여 초기화 하는 것입니다.
                        <ul>
                            <li>4번째 줄: Vocab 중 pad token id 값.</li>
                            <li>6번째 줄: Attention 사용 여부.</li>
                            <li>7번째 줄: LSTM 모델 hidden dimension.</li>
                            <li>8번째 줄: 토큰화 한 Vocab size.</li>
                            <li>9번째 줄: LSTM 모델 레이어 수.</li>
                            <li>10번째 줄: LSTM 모델 dropout 비율.</li>
                            <li>12 ~ 18번째 줄: Embedding 레이어와 LSTM 모델 선언.</li>
                            <li>19 ~ 20번째 줄: Attention 모듈 선언(Attention 부분은 아래 코드에서 설명).</li>
                            <li>21 ~ 24번째 줄: 이진 분류를 위한 fully-connected 레이어 선언.</li>
                            <li>29 ~ 32번째 줄: LSTM hidden state 초기와 함수.</li>
                            <li>35 ~ 48번째 줄: 학습에 사용되는 input이 거치는 함수(x의 크기: batch size * max length).</li>
                        </ul>
                    </p>




                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>Attention 모듈</span><br>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        위의 LSTM 모델에서 attention을 사용할건지 여부를 선택할 수 있었습니다.
                        만약 attention을 선택하게 된다면 아래의 attention 모듈에 LSTM의 output이 들어가게 됩니다.
                    </p>

<pre><code class="python"><span class="reserved">class</span> <span class="clazz">Attention</span>(<span class="clazz">nn</span>.<span class="clazz">Module</span>):
    <span class="reserved">def</span> <span class="method">__init__</span>(<span class="var">self</span>, <span class="var">hidden_size</span>):
        <span class="clazz">super</span>(<span class="clazz">Attention</span>, <span class="var">self</span>).<span class="method">__init__</span>()
        <span class="var">self</span>.<span class="var">hidden_size</span> = <span class="var">hidden_size</span>

        <span class="var">self</span>.<span class="var">attention</span>  = <span class="clazz">nn</span>.<span class="clazz">Sequential</span>(
            <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="var">self</span>.<span class="var">hidden_size</span>, <span class="clazz">int</span>(<span class="var">self</span>.<span class="var">hidden_size</span>/<span class="num">2</span>)),
            <span class="clazz">nn</span>.<span class="clazz">ReLU</span>(),
            <span class="clazz">nn</span>.<span class="clazz">Linear</span>(<span class="clazz">int</span>(<span class="var">self</span>.<span class="var">hidden_size</span>/<span class="num">2</span>), <span class="num">1</span>)
        )


    <span class="reserved">def</span> <span class="method">forward</span>(<span class="var">self</span>, <span class="var">x</span>):
        <span class="var">x</span> = <span class="var">self</span>.<span class="var">attention</span>(<span class="var">x</span>)
        <span class="var">x</span> = <span class="var">x</span>.squeeze(<span class="num">2</span>)
        <span class="var">x</span> = <span class="clazz">F</span>.<span class="method">softmax</span>(<span class="var">x</span>, <span class="var">dim</span>=<span class="num">1</span>)
        <span class="return">return</span> <span class="var">x</span>
</code></pre>
                    <p>
                        <span style="font-size: 20px;"><b>Attention</b></span>
                        <br>위 코드에서 나오는 config 부분은 <a href="https://github.com/ljm565/sentiment-classification-LSTM" target="_blank"><span class="highlight" style="color: rgb(0, 3, 206);">GitHub 코드</span></a>에 보면 <span class="var">config</span>.json이라는 파일에 존재하는 변수 값들을 모델에 적용하여 초기화 하는 것입니다.
                        <ul>
                            <li>4번째 줄: LSTM 모델에서 설정해준 hidden dimension.</li>
                            <li>6 ~ 10번째 줄: Attention 레이어.</li>
                            <li>13 ~ 17번째 줄: LSTM의 output이 들어가는 곳(x의 크기: batch size * max length * hidden dimension).</li>
                        </ul>
                    </p>
                



                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>감성 분류 모델 학습</span><br>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                       이제 감성 분류 학습 코드를 통해 어떻게 학습이 이루어지는지 살펴보겠습니다.
                       아래 코드에 <span style="color:rgb(86, 155, 214);">self</span>. 이라고 나와있는 부분은 GitHub 코드에 보면 알겠지만 학습하는 코드가 class 내부의 변수이기 때문에 있는 것입니다.
                       여기서는 무시해도 좋습니다.
                    </p>
<pre><code class="python"><span class="var">self</span>.<span class="var">model</span> = <span class="clazz">SentimentLSTM</span>(<span class="var">self</span>.<span class="var">config</span>, <span class="var">self</span>.<span class="var">color_channel</span>).<span class="method">to</span>(<span class="var">self</span>.<span class="var">device</span>)
<span class="var">self</span>.<span class="var">criterion</span> = <span class="clazz">nn</span>.<span class="clazz">BCELoss</span>()
<span class="var">self</span>.<span class="var">optimizer</span> = <span class="clazz">optim</span>.<span class="clazz">Adam</span>(<span class="var">self</span>.<span class="var">model</span>.<span class="method">parameters</span>(), <span class="var">lr</span>=<span class="var">self</span>.<span class="var">lr</span>)

<span class="return">for</span> <span class="var">epoch</span> <span class="return">in</span> <span class="clazz">range</span>(<span class="var">self</span>.<span class="var">epochs</span>):
    <span class="method">print</span>(<span class="var">epoch</span>+<span class="num">1</span>, <span class="str">'/'</span>, <span class="var">self</span>.<span class="var">epochs</span>)
    <span class="method">print</span>(<span class="str">'-'</span>*<span class="num">10</span>)

    <span class="return">for</span> <span class="var">phase</span> <span class="return">in</span> [<span class="str">'train'</span>, <span class="str">'val'</span>]:
        <span class="return">if</span> <span class="var">phase</span> == <span class="str">'train'</span>:
            <span class="var">self</span>.<span class="var">model</span>.<span class="method">train</span>()
        <span class="return">else</span>:
            <span class="var">self</span>.<span class="var">model</span>.<span class="method">eval</span>()

        <span class="return">for</span> <span class="var">i</span>, (<span class="var">x</span>, <span class="var">y</span>) <span class="return">in</span> <span class="clazz">enumerate</span>(<span class="var">self</span>.<span class="var">dataloaders</span>[<span class="var">phase</span>]):
            <span class="var">batch</span> = <span class="var">x</span>.size(<span class="num">0</span>)
            <span class="var">x</span>, <span class="var">y</span> = <span class="var">x</span>.<span class="method">to</span>(<span class="var">self</span>.<span class="var">device</span>), <span class="var">y</span>.<span class="method">to</span>(<span class="var">self</span>.<span class="var">device</span>)
            <span class="var">self</span>.<span class="var">optimizer</span>.<span class="var">zero_grad</span>()

            <span class="return">with</span> <span class="clazz">torch</span>.<span class="clazz">set_grad_enabled</span>(<span class="var">phase</span>==<span class="str">'train'</span>):
                <span class="var">output</span> = <span class="var">self</span>.<span class="var">model</span>(<span class="var">x</span>)
                <span class="var">loss</span> = <span class="var">self</span>.<span class="var">criterion</span>(<span class="var">output</span>, <span class="var">y</span>)

                <span class="return">if</span> <span class="var">phase</span> == <span class="str">'train'</span>:
                    <span class="var">loss</span>.backward()
                    <span class="var">self</span>.<span class="var">optimizer</span>.<span class="method">step</span>()
</code></pre>

                    <p>
                        <span style="font-size: 20px;"><b>학습에 필요한 것들 선언</b></span>
                        <br>먼저 위에 코드에서 정의한 모델을 불러오고 학습에 필요한 loss function, <span class="var">optimizer</span> 등을 선언하는 부분입니다.
                        <ul>
                            <li>1 ~ 3번째 줄: Loss function, generator, discriminator 모델 선언 및 각각의 <span class="var">optimizer</span> 선언.</li>
                        </ul>

                        <br><span style="font-size: 20px;"><b>감성 분류 모델 학습</b></span>
                        <br>다음은 감성 분류 모델 학습 부분입니다.
                        코드상에서는 5 ~ 26번째 줄에 해당하는 부분입니다.
                        <ul>
                            <li>17번째 줄: x는 IMDb 토큰화 된 데이터이며, y는 각 리뷰의 긍부정(0 or 1)의 label.</li>
                            <li>20 ~ 26번째 줄: loss를 계산하고, loss를 바탕으로 모델을 업데이트 하는 부분.</li>
                        </ul>
                    </p>




                    <div class="doubleSubHead">
                        <span style="display: block; text-align: center; margin-top: 150px;">&ldquo;</span>
                        <span>감성 분류 모델 학습 결과</span><br>
                        <span style="display: block; text-align: center; margin-top: 13px;">&rdquo;</span>
                    </div>
                    <p>
                        <span style="font-size: 20px;"><b>Attention 사용 하지 않은 감성 분류 모델 결과</b></span>
                        <br>먼저 attention을 사용하지 않은 모델의 학습 loss와 accuracy history입니다.
                        최대 accuracy는 <span class="highlight" style="color: rgb(0, 3, 206);">0.883560</span>입니다.
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_G42JtvqG1PmaHsdWU54diR5izEhuWG5qcVDYkWS7i8dN87pW_AJJ2XSfbCjPSVC1qQdrohc1ov1OGx3dK-wPIvuBjUO8XAKVfWJi3HJcVjBEkqMvsuCdN68SsxCzlHDtCddiWTCvHVZ_etR1OnoyY_WwUXqctoohWpDLsewdzuhpMD_MDsszTs2tWK8EKjZH0ChiboTTiQy0nmocHX_Axxg_pYttH4YVnqE9yYO9dX4tJQ2Dd0QcGEZTd_Ch6Wkh-a4RpxgfF3cnpwgrUvQZmwSYtGFAXPKk2IecDFZzY7cz6bVsdlJatzZj4k84TRNHkcIIeDoBjRZb-MpsfFXPAdKCd4waK2ijpvhpEpKxZ5qrHc5p1UV-gaDPC8C4p7LpUKpT_T4sKdLJGcJ74-a30y5ulXMFUu7bu5o5FMEfM0HehppvHBd7up6DPypfk81bUS1C6x04vo1FPiB7k01XR8ZYPyZ07w6_f_mm5RY77bcX2LI93hFhmCR7yY-DaljnpSrXtN1UXcN70PIoSWHRqDMPOJgJAxrdi93S_lrik4Os_3jRPlip2SUeL7_GF7sm5mJLwToTTjiy8uTx5GQALSGtIMz-khRlNeHAdqNpiCzcsvsy7mm5rqbRwJwwVmcoMq9i36aTrlxE0ywW2KoU3CTiRKfgJAKeCQT2b27Fkgk7fAY3cfvHQjgKh8clWyzCdfOKuAuF4dT5_STS6cULUl_7YVrF8vhZurucH0_cJWvRTC2cQeX6hMVYffHx5lQscbiumFR_ibFBO4NyEVDyPdDmzQr7pd0AHNfCoz6xHUQjC5mR3sIQPivC2jXOFw-2vAh4t63aszG_CFndDMLmmI1onaFcJ1zg3rfZDpbhTyjOsmWhcHhCYPxyIMjrKIZWjBhSSu6Y5UjMs22KxTVvhFO9NjrkSJADEJ4OdkOsPFFJOVS4lw6sgebEXrp6bNQYdTFv4jcUC0184_Dh-vvXMJsV2zq5tw3uk6pLbRrmvgl9j5qmv457yyPL4FXzUcdH4axnCw3kFTLXPRlQz6_SW6qmjQdCS3c1SX6uCAbdSuLGXw3eg4jzxqKxztNqcoEOrLqwyL9L1OygFylZio2PVmzxkl5v93rFz1f7xnozMYaFUAvCZX2IKu0pN4W6P5hrauOwBBdFpBeZNycKsI9UDkPJdl-TX87d_Wos7rILWvRNyCc-BNEdDXgSZvKNmzuIbzrZhK9gfqjW4GXPTXBzI_kLvJKnmYocI7eTazH4_KUV2FTF0_8VIQ8NVL6M2XTzleysUx4t8_ni97kGmsYfQ1UQTlitIAQGRVpKhKf9YZFV0EagZtNK4y_jgsQTz92-KVOrvnbAhiJ5Dsa7TKSMxvqkWjN06QRyvdC389olhd7qAdoE7FlpQmhvgHTc5h82JwgB2enIiFQbdYhtKaqoPh7oYdz00IJAzYM-MG_c703-nZCM8KLDD_8mPdecD7IgRqXAsraXSS8dLRn5Lvm-yrcqEm8xnz-0sEvSZGeNAdhg_0Xn2tVmh6iTySS0Pm-tr6JIRs3A" style="width: 100%;">
                        <p class="caption">학습 loss history</p>
                    </div>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_HveF9_2ieCNh_1iQ6QMpNSPS4t-CY6DlNDF4Hr3GiAkgqFdCfgi_VlAN__t9mbqy-iTQWg0U7Wuc-cgltp9vVzR_H4YJfT80VYKz4Onfnvwq_Mhl-2ZZFbWb2fBnYZrrDTAzBuYgyLE-mkoou3k7QTwsBbCyGbDbPP1I_6NrXAz0oM9IWx4XiBFUqG7QyWG8eG5REajWLlddfAxGZuvh9wBbWa_es2LhbhrJyEbJIYJYjyu_bkYm5xCqI4fjHMMKv0n4YVFKnWzP1kKGJtr-GVWE0DSuZa-bX5CcYvw7gG4MKZzBxUPNFajq0IeU7LymZD7RcS0s7UJ-CPlUM-3nbZymzlJC__IrtIdgh__a60_LXfVTNJX_OzD2OdYmyK2z08s8566T7z7pZx89ncYDxL1KQxx0TZeTiutFZ0Zoast6f7MukISZLHkNpkEqwBuEjMtwBbdGmrlYquy1F7BoCNoVivdQZ4xyl4zBulNbBKz6J1aiAFIC6hYsXEFNZs9ue_wJ8KQtGwmCFLfPKNhJv79gXpv7llnjDmRkvOYCU9AYyoFDfFi_aIDSYRRe9n3Rrq55f4PFwwueldvCIAx5A7G9664eXThdK-oKAjGmh7lPqMR9DAjcnfZAW18ROKQhbU6msQY1YYR1CwR1sMJCjXzVVeiasIcMs36J91dYUNzaUWbgYTuFBsgWOd6hMWJvcZ8yLKPCbxggM7eN7m0fiZJuVuQpberLEqHgB6g1gjgqHZCiC7XB6rtyI7CsDyKtQPcUXZ3p01oZYM5VBWS42yNdty1PW4i9gFw3q65H1EbnY0--m3CJjELSzGRySEFPBnysxuFY0d7XH8q8LoWwoSSA32sansFL8RKRceta0wm-mqy5uQXWVYaFJ8fnTzxDTkvlOySYhJB8GnP3I2y4vy9dxNAlhDYt3NfjHkTccfsDM-ZVZ2CeztWkufy25Az5pGNPzhjFPv75zMPInzBw5mDCtdMr5N28glyzzVHiuMONPlttm1DXMTK6Rx0av-fuwoVSA4NKPygmng16FZWbBJ95MoYzevnZKQjdbG7cvVoX3ccv1YTKpK_kMNQ14WVUd5IhnCCRGB3_jDJ6jAMqt1mute6ydIeIZX8UwRBkMFwGg6Ow4-G74frVW6WPTEn42W4Low9VVhPymbOp1k2LWpuD6ZCjX-ErQ9ptGE8C0xqI04pt8SCKRYoYT-Idg66_o_OexzFn8hkPPCJ06hUNKfu4dM7llfMAWhYFA8mjCmOuM0zP9hU8nM_wwpfQ5kJ-RPPErP6O5dBVaemgrrVIkONA5pCCN55u5WdX0rECIHINsObtzr8ePyMXuf6A-KGjyFHx-MkXMdhYXovTkL341jBWmvJ8magH6l9QGrc_i6XLMgTl6XB5px-ugSeYopO2llfcdrVPjxRSaG18wFDdl6Y-lSp_n-qd1Cu-u5UsdFS4m_fCGtwmVzDsvA2DRgZagzOQOw9IYpAfvcm9GglfU-MOvE0QmnuVjd_iwM6g4X-yiVFHVVfoDyLKJBc7TlA0n19VxORwoo" style="width: 100%;">
                        <p class="caption">학습 accuracy history</p>
                    </div>
                    <p>
                        <br>그리고 아래는 예측한 몇 개의 샘플입니다.
                        <br><br>this movie was awful plain and simple the animation scenes had absolutely terrible graphics it was very clear to see that this film had about the budget of my [UNK] bill the acting was just as bad i've seen better acting in pornographic films i would seriously like the hour and twenty minutes of my life back in fact i [UNK] on imdb just so that other people don't get sucked into watching this like i did don't get me wrong though i love scifi films this one seemed more like the intro to a video game i'm glad i only spent a dollar to see this one the story line reminded me of the movie pitch black a prisoner on a ship in outer space escapes oh my goodness what are we gonna do i would not even let this play in the background of my house while i was cleaning bottom line here you can do better
                        <br>******************************************
                        <br>It is negative with a probability of 0.999
                        <br>ground truth: 0.0
                        <br>******************************************


                        <br><br>the beloved rogue is a wonderful period piece it portrays [UNK] century paris in grand hollywood fashion yet offering a [UNK] side to existence there as it would be experienced by the poor and the snow it's constantly [UNK] about adding to the [UNK] of the setting brilliant the setting is enhanced by the odd cast of characters including [UNK] [UNK] and [UNK] a brilliant performance is turned in by john barrymore [UNK] only by the magnificent conrad [UNK] who portrays a [UNK] [UNK] louis [UNK] to perfection and yes [UNK] picks his nose on purpose pushing his portrayal to wonderfully [UNK] limits
                        <br>******************************************
                        <br>It is positive with a probability of 0.816
                        <br>ground truth: 1.0
                        <br>******************************************


                        <br><br><br><br><br><span style="font-size: 20px;"><b>Attention을 사용한 감성 분류 모델 결과</b></span>
                        <br>이제 attention을 사용한 모델의 학습 loss와 accuracy history입니다.
                        최대 accuracy는 <span class="highlight" style="color: rgb(0, 3, 206);">0.884720</span>이며 attention을 사용하지 않은 결과보다 살짝 높습니다.
                    </p>

                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_EEQpr9pzabxtFK7CuT9fJSWwICuuEOPTzMYro4v9SDmU2TqpGjOmjjfxMPkDdS2nnj8G1wqqNvqBfLyOcyJ-JYEf4QEwS-4kIncr1_AF4rcsPX2hQbbMo-zoN4ME5xJ1Py_fbtKbHNFpghz9uatL8MPutp-klbMhX0fKK8VQ92YlIVKQNfquMyFypIbqREaPWdgLYxx-eKZ7kQ99FcXq3GGUbtuiC3XgiZCNUUM0Eg7dmvlSuHq9IPgxjPQYslCIiIOa6CaPvAtR5K6SrZ-QtziV6mbFgDrn5b_S26m2Sb0jksm4hfzRsVUSQ9GXOOsuNlR8N_AsbWq5wAIndqvdtn0ImHsJ8XWFIsb4Mek8F-hVnTm0_jOy5Vo0jTZkE-_bqMTgVrOZgm9rn8r0zKY1DzGXBCdc6g4EpEY7l6P86jx6d8I0x3Qk9Tz-Fw4_8DmlsUMJWj-uwj8LYZqTPRHCpfoNNo4rYtU_OLAqPcMDytj-LMFsQBfsu2RlLXtrfRazPNwElkJltXjBYGDRtCkq86XSXOjJ_tz8Y2FEkXqtJnjqpXLArCkdwHgtUTqxYn4cQx0QotkkjQ4mRSxgQOBJXzQrK-rqOdSKoyG6d8c--337-728P7EjJwtG6SVCrfTdi9JHKDxJ2jGl2KPG4CLcvCE9wmSNGsfC9vi_VCHSi1eX_ZxiejwMfdbB-UdWnrFSQSkafTXRB22-ken8IDRK9c5MLoQMOeT1vJZWFdo8IDnjjhojgNWqEzW0BjfFOmRHn9A02QkJm_cesAD1s1JXw00nAZtphBw7e0wu1jt9TCgcbfascEj1_g4a2a04WqrCmv30jvWaRtvlD5wZySoS1I7u1MsZeNsM5RbQ6F-slD-GcseoD6bB3gWaCGkfQ3FBOQYeZcYKu7Ze09tG6juYTfNzsv67dGPEbkS5FFzxBPaDylXH9wywNNukLuEq-3CfdScr3RjIZVZzqmpOme7f_Ad2eYrNCnDysDbqzf99n3kKHm2Go7gdtqTIwMC4CSeZsbvPWLJwFlIZgNGsaeNeJ1KxeWbPFbuXER91J0iz0oGKC0KOxO2qMePaw9lf6lLWPneWnPDizKhhDg6gFGs1490n-FQHZE-KY9w0QCw_Lyik5HHPrgWQkRaLFHeu3U7KBy7cwkUzDJoKjpm-6RL1jCADKXJF7tPT-CSV3ZBIlPOWpz5gborim-_MQwBp3w3hmvvdU7ZrM557ioejl074mL1O3HJW4sb0yS5MLLeLQJNgt-VVAAIotjbySie_FPKjhwhyLi8Sn-bZW8NkBOE28UFo1HyoDc-4akps3_tEgxxndYYSjCSOEzCZCcLAtsCPFnrt52DYqO6qFCaAiERNdu97-QCcaslzYS5aFR0MuZE9XjM5p9t838F0hzccmEsB0MSA34LbgWBm44KRh7vqdZmQuNqIeEadGLkgzFda9UNGaKQT8w08KuyPqExMogyMMeXwRjrZ6yKe9ZaKXtLqnXGZIWpbxSwNr7fcZ-w8y6-SNSrz7x3VwxOah1hUt872NnplZz3w" style="width: 100%;">
                        <p class="caption">학습 loss history</p>
                    </div>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_EUm_3BXg-q5hGvFOzXi30XB-7Tk87MDeGBHQbhMV3O-58qmOnRhcM-ErhYZAw6RXURgIbIpec7yRsCw21-aZjm4ywh0DJxYlU6V3JW_ClY5wcsXCCKBZnYSarQb0hN2Rdhc2RRQpzaoZYSr_Tx2Qh58W6Yjc_Fz_tSsTGUW9_8WVHTlIc0a9KjpoE-ReHfhlQ3Lk22rHk5CoVs_rD04wWeIFZRap4bdTgNtS3lbv_u8bzi6PlhMqV1Q8Yxl6uGzLrAUYZBC8NX2kf79w3xF7FLmaAI2GeT5aV5FhXUEVyD-xDVxTDAcmYOVSq9HKrJqNnUQ3Yl9G5XF6_PVfAuDCWsr1ZAGa-ML1zUGKe8QzlK1NkNk6oY_cE2Jpka0nY8Me03gk46S8xtZFtlD2e3QSFoerHunmt2oPv1IOvNpg_JfzkvMgPd-cU8emtF7x6N1u1Upm4lmVtJMJJx6GZdCU_IEGQmzoi72DITipsZhSRpi0Rq6A__9O6KDdGN1q_OicP7sZeY964ahXnxj9_7HixpNLSymud6INVQQ2_kQR-oal7RObUKlh0kJOYc7YSuWMqgiMHH-Vpc9Mx2iQc8s1vIqOnX9wVFUYgo_lxEukskDbay5UurTikeuB0hecDbyVokghoKEkjOXkOVavGYSM7y5FdmYNRNgGP1YqRd2kmQa3yjf7ke4SzWAMYUxYv3jZkAcPUgOypKkjqk4MaEyl6lHVCsidN3mYZm2O1_gq9LsvXw0KlpsWLhIRRO9TNcUg2-QVV0zJCOynCJyswbT4NNYKOxClv4dEP4tOi9Xx-lcP1S9kUv5jAkmGxmG7BQsAB6Txm6KLK_sHMCXOjREzmkePNUJ5zmg7IBXzmJd8mTOkuy0gFPHI011hWHmeE8Lxfjl3kZpq-dXpyHm0v2TeeCBiPiHhTVT5jWK5M2skKkV8L8oHDqtAwMHjwydzJFGBju6EBpOZSJ2Zcsaf0am_7LoMqCA6DNWPQ0s7_i0aGyzOJpqf4S5aksc2oc_ieaI__nDkSBfyB8x8ejshPT1olGW15pPN99gYvQU9axLM1JtsUbwyoYxA052nz7_8QXb0gv9aGByjIUP-X_vYFlC5JaH_KPhYkVk-uTaVk0sj2syJS7jKgoySGKxlqk0nOnJ2UVQFiCBG5HbqT-cBWl4iYpHbCQ-eaNTxUqh2i9oEqtSSU4qCx64rjwsdLxdDx_95sY34VGr3-SKwf5pfQy9U-uaZ5_PwjpUYb2BP5-u_-EnVMyJGV1v4EWbSNdBBD8ZNmFLTPoSX7a6VR79xiHFt5ZuUrYlzU5PTOqB6t5FZ5qKreDzFpQviGzgpOVWZleJ2hfDxhZvuzXUfGqCL-QzE7tkf75KiLM_H6tGaKtrdfIKLuuIDUpuKx9-KX4XngpvNUJR4mtil6VMJqmeN7VDkS5oHiTkxoOaIiGOc-AH5Qa4U_juBdR33T1Yuh8d0FHwZPHmqEYcQ3rLaTYaDeurG2Ao9Y8A0JmACEX2xF6Enb58roX1XpI6bzwpt0KZHU36l3LFXkWvg3w" style="width: 100%;">
                        <p class="caption">학습 accuracy history</p>
                    </div>
                    <p>
                        <br>그리고 아래는 예측한 몇 개의 샘플입니다.
                        <br><br>i saw [UNK] on broadway and liked it a great deal i don't know what happened with the film version because it was dreadful perhaps some dialogue that works on stage just sounds incoherent on screen anyway i couldn't wait for this film to be over the acting is universally over the top only kevin spacey has it together and he seems like he knows he's in a bad movie and can't wait to get out
                        <br>******************************************
                        <br>It is negative with a probability of 0.784
                        <br>ground truth: 0.0
                        <br>******************************************


                        <br><br>how do these guys keep going they're about 50 years old each and act as if they're only 30 they play 3 hours of music at every concert and barely break a sweat this dvd is their first concert in [UNK] brazil although the people don't speak english they try to [UNK] the words to the most famous rush songs and try to sing a foreign language at the concert with their best friends from tom [UNK] to the spirit of radio this concert dvd will keep you in the chair not wanting to pause or move away from the classics that you've listened to when you were young this is their [UNK] reunion tour started in 1974 i went to their [UNK] [UNK] concert and this was just as good although in [UNK] they didn't play [UNK] so i was upset they have [UNK] they have the trees they have [UNK] the pass driven [UNK] red [UNK] a [UNK] roll the bones [UNK] and much more 10 out of 10 because nothing else [UNK] if you never go to a rush concert then at least buy this dvd
                        <br>******************************************
                        <br>It is positive with a probability of 0.961
                        <br>ground truth: 1.0
                        <br>******************************************

                        <br><br><br>그리고 attention을 사용하였기에 attention score도 어떻게 작용했는지 살펴보겠습니다.
                        위의 결과에서 보여준 리뷰는 너무 길어서 짧은 리뷰에 대해 나온 결과를 살펴보겠습니다.
                        <span class="highlight" style="color: rgb(0, 3, 206);">먼저 긍정 리뷰에 대해서 모델은 great, spcial이란 단어에 좀 더 집중을 한 것을 볼 수 있습니다.</span>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_FYLru0Hh0-ucPQKqBvcSxPJHpa4W70SPDy1OfCMIahhcnemkcV_27h-faRZ9ZNarvwEMuSqDdFmYTVIdpSAOK7F5SstsGuSQycBZuyh9cPLP586G4fORl00-rP0jWkHuHSk0N-tIjwnYzgoz89eQ1hswj0iWxph6A9S3HKqrGKROOIhNSD_QIxaoZDhVrJpx9Q8xuJ0JyFvEVZEHcYjUbt1zHDO-9R7N5_dH5nP2MOrunCFrZtPEERwj0cEoLR44P7f1fvGvit-CUEvSgFgzUWReZdcQj43dldyHAkNOohu-2gOG1J-BTRnP0Wn9Q8LHNZJT_c8gFd3yHrLjMU3eSz3bnMaoUzIZUlPygrb8tA1l_r7tAVSwJ5OeWseVX-BUy6j5DrxdOVgthb-2KzeCsRM6M6zGEJRKeQvQImliwtvTnenEUqjFkwq25_Cn-kEncmvkBymvpgQa40aWDAZ-xqvYL0X8jWQ6N_MsMtRqYBpR9IQZ7g9dtMylY8EtDIR4ITQkMjk21ZNcz2c6R5-8_vb9TcW3SDExR4KlLwfr9woUwIEkzL1xwEc30B6tcPPmu9Ls8PY6DwLwWb9WErlx-Qs5HOYG-HrLlc0adpiub09gED_lHhZOae5ETJ92KDupBCPStV0Gt4iJ3C795oOOwzcT4tGzarPUX_-MIWACi7bPuLtFKzhTIOrUUrdDwOpW5anUr0ssAT6_YzT6Iag4YB7_q8abUIyoco31M8JFny0HB6iOL2ugUkmnZGJrNUokIhrnjpv_jcAgMfeNUPlwVkANwJcKacFXhHznNdpWfps0fx7bZ92lbXi6Lzbe4sJVhpna3fNgmNRSK8kwfDzG91crehjM6uv7RmQ0vDZg_yAxXkR0HaUHPc34c45tBvvJkuYI4ZCNaqHnYYEs4KiZ9K5AHrT9PnOcUJ3XgmMcPbMGoU_tLh8UbWbhDvfgB8K6OX4Mjp3FYEkSId5RUt--L1tT7eLRnEAbV9gnz0Ryez1IGr9T4VUn43NFbDsJQ94iBv_IrQg7S41z4UXIr1rarvanJZUC3VqseKhaN-clL_22yP6A_6Yo3bSufiSE5O4-MnYQMiFLAkeask-Tt07rHWkDwZ0ZmpyJftFWyKRXieVE6ke1o1XQoLX7gV_NTMBDFs6KFIwb3R8qGoLdaWvgYBTn0NKDnBJeLmscAInlGJfHHp4732bpSC7OcGP8laop7WqbRhDJ9qAA9fOd14v9gicGVbrajmTLMNmNbciJxNESm915mqbTrKwF2RAShkFeW8um26F7gMQVPIyqhhEB1dvrQ88dHhxf7MaHra78BuaEyAJ3zHKr2VasvDNxC0ygaYwy17rtK8La7ndPbz1AHPHP15t98YKOZK6EB_lRBTlRbYZ-ZQ3IyvFwuguQbekjO4g1gBcBLEdh5kkzgA5WaESkwWhfTKBvHOwpC1kZV7ZgTyFW8XQY5DUAn6H3Gl_g-sjwaT1N_J2gzyWAiecTTrTt5-l3cM4Nz4WHI3d1Y08dqVKhWEFtnDD5qLqdS_LyKZaJJZ6idH" style="width: 100%;">
                        <p class="caption">긍정 리뷰 단어별 attention score</p>
                    </div>
                    <p>
                        <br><span class="highlight" style="color: rgb(0, 3, 206);">부정 리뷰에 대해서는 모델이 story, mess 단어에 집중이 된 것을 볼 수 있습니다.</span>
                    </p>
                    <div class="contentImg">
                        <img src="https://lh3.googleusercontent.com/fife/ALs6j_G-G7DqZ6e4XEYsC_kQ144BCFceMsTSSXl0vhdmowi4HFzMf49NYop0yGIzxACdBzgTTBpRMkCMVhBZiqUYdbgHv_YNn9yLEfw9Bc8ceYiKdEuy_5bkRzOX8WcSUew4xiXebpM1cPvLioQOb6EBmtShJWKi2flEm-fkSywSPgwODfM-EaOfAWTIDcedTzJLRxE7XGD70D90mEtRWTGdRF2nllrky0Ok21p8pdq4JFURxs0zFe-ZT5S_i3a29zL7NYTm0rwKISDwSrLFGV1j01Q1CL-WHSsJapOLbALWNYsgSOkYNhkAwCoTX2ZG9n8fATj8mgRpnABuHaQGh_N1h-g595kCzsscGLjeCUg48_dFeikZ3cfhzaRcMTzXlI8J0kYQ6KLtUXJ6k1u7nwGpkoYLWPH6CMUpGFbRK7mACJdZGTFNjhIDNRdDooK3IQy2ONc6n92togZ8dD0_RMuga25qVKtM9M7hp_Q2_5NFmardFIysvtI7hqQsirrD6q_6FmLX1uadom3RIZL2K8Btjir6WYK7ShN5WMCUaFOoml7d76Jv9wNHaNZakAWc8mJWYmwOw8XKW0djhfVbSF9Kx2zqZrgoKHyw_EJByNLUva0hmG6w97OxxoK50C0gYofeAn-4jSOOckF1IWe20Axq1GwH9pYfAY_yUpeZqp26Jj3nySdd5he5IuT1oZOGWiL_I75ICOVXcUrx3n7ocw2wy9cV4WPuLQi4lMHClQjmMtH2AQng2mVVjrwAWegBFS1uSr2pm-xpulr3bdliQyPv-0dsLXz9c437AeGJ2BxwtICIx0Q6GuMgn3EmlyTvyeFesKexDAkZmkUGLNNWfA6SlsUd-Zfp9dxyJWAvDd5_7gkjTi5VQkTu7uJRkdUt0fbt2unyg6N8SoZOOBmlgeOWXoXxsyrLi4SUuWvrzW4oPseDry1oZ-G4MWfIIVsvQ7mwySMCzOj2eED5DxvFaff3HuzNXPL6fH2x_VqLqKWqz4paShWQSM_UURsBI7__TaUmu4Io4p_ARuEL-G3pK37rc171cJK2TsY2O9QdnHl_p7wCnIjpIMEKdCea8ZrJEV5pOnSnOm0QDy7IuMTVhl9_yd9D8OkkYFldrdNYdf0GHtINNA8NcMkrSjwGTGN6msbTIsYOrNa6AW_r_cNMbVqik06SPDowN_K7-agyELu124hr4UoQ1dsXFEnL_v57tn2pTr-gfbrBfSqCbCibQbk8JTR1NTyeayir55mely2AlMAp4bUrpleK5BcCgJniNcGbawjzpU_2Th82Jvnpf_SwZxKRXJZDJ784XiHYlKrhtqcfIYc30eG87xUfBJydWrwFOod99xXszx1IGJaCPSwKlbzTiqxSp11gKUTblW9aFEWPklMWkxeUZen2AM5oMPymMV0z586uAFMowPPbIeGR-F94l05l0SbeJ5ULFKBv8Kgek5VE7GJGBcXFrhWxdF0dPhteOryPVu5VHdkXN2Vlw8Vh_O1j2WnwQ8Hbt6mlTtLHjguXL1e30rE3s-gsXLZzh41ZGVRjSSVY" style="width: 100%;">
                        <p class="caption">부정 리뷰 단어별 attention score</p>
                    </div>
                    


                    <p>
                        <br><br><br>지금까지 LSTM을 통한 IMDb 감성 분류 구현 코드를 살펴보았습니다.
                        학습 과정에 대한 전체 코드는 <a href="https://github.com/ljm565/sentiment-classification-LSTM" target="_blank"><span class="highlight" style="color: rgb(0, 3, 206);">GitHub</span></a>에 있으니 참고하시면 될 것 같습니다.
                        다음에는 깊은 GRU 기반 seq2seq 기계 번역 구현 코드를 살펴보겠습니다.
                    </p>


                </div> 
                <div class="tag">
                    <b>태그</b>&emsp;#LSTM&emsp;#감성분류&emsp;#IMDb
                </div>
                <div class="pageTurner">
                    <div class="pageTurnerLeft">
                        <span><a style="position: absolute; left: 0;" onclick="pjaxPage('RNN2.html');" onmouseover="colorOn(this);" onmouseout="colorOff(this);">&lang; 이전글</a>
                        <br>Sequence-to-Sequence (Seq2Seq) 모델과 Attention</span>
                    </div>
                    <div class="pageTurnerRight">
                        <span><a style="position: absolute; right: 0;" onclick="pjaxPage('RNN4.html');" onmouseover="colorOn(this);" onmouseout="colorOff(this);">다음글 &rang;</a>
                        <br>Seq2Seq 모델을 이용한 기계 번역</span>
                    </div>
                </div>
                <span id="readNum"></span>
                <div id="disqus_thread"></div>

                <script>
                    headHighlightColorChanger();
                    (function() { // DON'T EDIT BELOW THIS LINE
                    var d = document, s = d.createElement('script');
                    s.src = 'https://novicetraveler.disqus.com/embed.js';
                    s.setAttribute('data-timestamp', +new Date());
                    (d.head || d.body).appendChild(s);
                    })(); 
                </script>
                <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </article>
        </div>

        <div id="menuRelated">
            <div class="menuButton">
                <img id="menuImg" src="init/index_img/menu_black.png" onclick="openMenu(this);">
            </div>
            <div class="menu">
                <img id="menuExtension" title="메뉴를 확장합니다." src="init/index_img/extension_black.png" onclick="extendMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
            <div class="bigMenu">
                <img id="menuCompression" title="메뉴를 축소합니다." src="init/index_img/compression_black.png" onclick="compressMenu(this);">
                <div class="profile">
                </div>
                <ul class="tree">
                </ul>
                <p class="copyrights">
                    © 2022. 여행 초짜. All rights reserved.
                </p>
            </div>
        </div>

        <script>
            detectScroll();
            pushFunc();
            detectSize();
        </script>
    </body>
</html>